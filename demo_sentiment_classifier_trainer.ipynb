{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pickle as pkl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from twitter_nlp_toolkit.tweet_sentiment_classifier import tweet_sentiment_classifier\n",
        "from twitter_nlp_toolkit.file_fetcher import file_fetcher\n",
        "from zipfile import ZipFile"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-04-10T20:09:29.364Z",
          "iopub.execute_input": "2020-04-10T20:09:29.380Z",
          "iopub.status.idle": "2020-04-10T20:09:33.309Z",
          "shell.execute_reply": "2020-04-10T20:09:33.300Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunk = 1 # Fraction of data to train on - you can reduce for debugging for speed\n",
        "redownload=True\n",
        "model_path = 'Models'\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2020-04-10T20:09:34.067Z",
          "iopub.execute_input": "2020-04-10T20:09:34.083Z",
          "iopub.status.idle": "2020-04-10T20:09:34.099Z",
          "shell.execute_reply": "2020-04-10T20:09:34.107Z"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we download pre-trained models and a validation dataset. The models have been trained on the Sentiment140 dataset, taken form here: https://www.kaggle.com/kazanova/sentiment140\n",
        "\n",
        "The validation data is hand-labeled airline customer feedback taken from https://www.figure-eight.com/data-for-everyone/"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "if redownload: \n",
        "    \n",
        "    # Validation data\n",
        "    file_fetcher.download_file('https://www.dropbox.com/s/440m6x07bjg6c0h/Tweets.zipdl=1',\"Tweets.zip\")\n",
        "    \n",
        "    # Compressed model\n",
        "    # Note that this model has only been trained on 5% of the training data\n",
        "    # Update when better-trained model is available\n",
        "    file_fetcher.download_file(\"https://www.dropbox.com/s/i88eqlja56xncyx/model_test_05.zip?dl=1\",\"Models.zip\")\n",
        "    \n",
        "    # Extract all the contents of zip file in current directory\n",
        "    with ZipFile('Models.zip', 'r') as zipObj:\n",
        "        zipObj.extractall(path=model_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tweets.zip: 298kB [00:00, 1.79MB/s]\n",
            "Models.zip: 100%|##########| 1.82G/1.82G [02:00<00:00, 16.2MB/s]\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "execution": {
          "iopub.status.busy": "2020-04-10T20:09:38.486Z",
          "iopub.execute_input": "2020-04-10T20:09:38.496Z",
          "iopub.status.idle": "2020-04-10T20:12:21.744Z",
          "shell.execute_reply": "2020-04-10T20:12:21.768Z"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the validation data\n",
        "\n",
        "test_data = pd.read_csv('Tweets.zip', header=0, names=['Index', 'Sentiment', 'Sentiment_confidence',\n",
        "                                                                'Negative_reason', 'Negative_reason_confidence',\n",
        "                                                                'Airline', 'Airline_sentiment_gold', 'Handle',\n",
        "                                                                'Negative_reason_gold', 'Retweet_count', 'Text',\n",
        "                                                                'Tweet_coord', 'Time', 'Location', 'Timezone'])"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the unlabeled test data\n",
        "\n",
        "test_data['Labels'] = (test_data['Sentiment'] == 'positive') * 2\n",
        "test_data['Labels'] = test_data['Labels'] + (test_data['Sentiment'] == 'neutral') * 1\n",
        "test_data['Labels'] = test_data['Labels'] / 2\n",
        "\n",
        "test_data.set_index('Labels')\n",
        "test_data = test_data[test_data.Labels != 0.5]"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Executing this cell takes about 30s on a laptop\n",
        "\n",
        "Classifier = tweet_sentiment_classifier.SentimentAnalyzer()\n",
        "Classifier.load_models(path=model_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW model Models\\bow loaded successfully\n",
            "BoW model Models\\bow_005_1 loaded successfully\n",
            "BoW model Models\\bow_005_2 loaded successfully\n",
            "BoW model Models\\bow_005_3 loaded successfully\n",
            "Pre-trained embedding model loaded successfully\n",
            "Pre-trained embedding model loaded successfully\n",
            "Pre-trained embedding model loaded successfully\n",
            "Pre-trained embedding model loaded successfully\n",
            "LSTM model Models\\lstm loaded successfully\n",
            "LSTM model Models\\lstm_005_1 loaded successfully\n",
            "LSTM model Models\\lstm_005_2 loaded successfully\n",
            "LSTM model Models\\lstm_005_3 loaded successfully\n",
            "BoW model Models\\model_test_05 loaded successfully\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We santiy check the models: "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "Classifier.predict(['I am happy', 'I am sad', 'I am cheerful', 'I am mad'])\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": [
              "array([1., 0., 1., 0.])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We test the model on an airline customer feedback dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Executing this cell takes several minuites on a laptop\n",
        "\n",
        "predictions = Classifier.predict(test_data['Text'])\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Accuracy:  {:.3f}'.format(sklearn.metrics.accuracy_score(test_data['Labels'], predictions)))\n",
        "print('Test MCC:  {:.3f}'.format(sklearn.metrics.matthews_corrcoef(test_data['Labels'], predictions)))\n",
        "sklearn.metrics.confusion_matrix(test_data['Labels'], predictions)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.773\n",
            "Test MCC:  0.528\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": [
              "array([[6806, 2372],\n",
              "       [ 246, 2117]], dtype=int64)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have accuracy of just under 80%.\n",
        "\n",
        "\n",
        "We split our evaluation dataset into validation and testing and eliminate the worst-performing models"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "valX, testX, valY, testY = sklearn.model_selection.train_test_split(test_data['Text'], test_data['Labels'], test_size=0.5, stratify=test_data['Labels'])"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Executing this cell takes several minuites on a laptop\n",
        "\n",
        "\n",
        "Classifier.trim_models(valX, valY, threshold=0.7)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Models\\bow score: 0.801\n",
            "Model Models\\bow_005_1 score: 0.738\n",
            "Model Models\\bow_005_2 score: 0.756\n",
            "Model Models\\bow_005_3 score: 0.746\n",
            "Model Models\\glove score: 0.765\n",
            "Model Models\\glove_005_1 score: 0.724\n",
            "Model Models\\glove_005_2 score: 0.677\n",
            "Deleting model Models\\glove_005_2\n",
            "Model Models\\glove_005_3 score: 0.673\n",
            "Deleting model Models\\glove_005_3\n",
            "Model Models\\lstm score: 0.689\n",
            "Deleting model Models\\lstm\n",
            "Model Models\\lstm_005_1 score: 0.652\n",
            "Deleting model Models\\lstm_005_1\n",
            "Model Models\\lstm_005_2 score: 0.631\n",
            "Deleting model Models\\lstm_005_2\n",
            "Model Models\\lstm_005_3 score: 0.648\n",
            "Deleting model Models\\lstm_005_3\n",
            "Model Models\\model_test_05 score: 0.801\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our custom-embedding models performed poorly on this dataset and have been pruned. "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = Classifier.predict(testX)\n",
        "\n",
        "print('Test Accuracy:  {:.3f}'.format(sklearn.metrics.accuracy_score(testY, predictions)))\n",
        "print('Test MCC:  {:.3f}'.format(sklearn.metrics.matthews_corrcoef(testY, predictions)))\n",
        "sklearn.metrics.confusion_matrix(testY, predictions)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.784\n",
            "Test MCC:  0.535\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": [
              "array([[3485, 1104],\n",
              "       [ 140, 1042]], dtype=int64)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pruning our models had a minor impact on our classification performance, bringing us to an acceptible ~77%. \n",
        "\n",
        "To improve our accuracy, we can refine the models on our airline data. The early stopping procedure (enabled by default to use 20% of the training data for validation) should minimize overfitting."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "Classifier.refine(valX, valY)\n",
        "test_predictions = Classifier.predict(testX)\n",
        "\n",
        "predictions = Classifier.predict(testX)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 4616 samples, validate on 1154 samples\n",
            "Epoch 1/500\n",
            "4616/4616 [==============================] - 2s 380us/step - loss: 0.4262 - acc: 0.8234 - val_loss: 0.3077 - val_acc: 0.8839\n",
            "Epoch 2/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.3701 - acc: 0.8533 - val_loss: 0.2694 - val_acc: 0.8934\n",
            "Epoch 3/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.3255 - acc: 0.8726 - val_loss: 0.2635 - val_acc: 0.9073\n",
            "Epoch 4/500\n",
            "4616/4616 [==============================] - 1s 280us/step - loss: 0.3079 - acc: 0.8865 - val_loss: 0.2657 - val_acc: 0.9090\n",
            "Epoch 5/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2964 - acc: 0.8925 - val_loss: 0.2816 - val_acc: 0.9090\n",
            "Epoch 6/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.3146 - acc: 0.8858 - val_loss: 0.3094 - val_acc: 0.9073\n",
            "Epoch 7/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.3400 - acc: 0.8884 - val_loss: 0.3016 - val_acc: 0.9073\n",
            "Epoch 8/500\n",
            "4616/4616 [==============================] - 1s 279us/step - loss: 0.3233 - acc: 0.8856 - val_loss: 0.2893 - val_acc: 0.9090\n",
            "Epoch 9/500\n",
            "4616/4616 [==============================] - 1s 280us/step - loss: 0.3048 - acc: 0.8869 - val_loss: 0.2775 - val_acc: 0.9107\n",
            "Epoch 10/500\n",
            "4616/4616 [==============================] - 1s 279us/step - loss: 0.2916 - acc: 0.8880 - val_loss: 0.2588 - val_acc: 0.9125\n",
            "Epoch 11/500\n",
            "4616/4616 [==============================] - 1s 280us/step - loss: 0.2842 - acc: 0.8923 - val_loss: 0.2453 - val_acc: 0.9168\n",
            "Epoch 12/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2855 - acc: 0.8941 - val_loss: 0.2436 - val_acc: 0.9194\n",
            "Epoch 13/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2710 - acc: 0.8973 - val_loss: 0.2348 - val_acc: 0.9229\n",
            "Epoch 14/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2670 - acc: 0.8967 - val_loss: 0.2255 - val_acc: 0.9237\n",
            "Epoch 15/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2685 - acc: 0.8947 - val_loss: 0.2247 - val_acc: 0.9229\n",
            "Epoch 16/500\n",
            "4616/4616 [==============================] - 1s 279us/step - loss: 0.2724 - acc: 0.8982 - val_loss: 0.2239 - val_acc: 0.9211\n",
            "Epoch 17/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2726 - acc: 0.8997 - val_loss: 0.2227 - val_acc: 0.9211\n",
            "Epoch 18/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2647 - acc: 0.8997 - val_loss: 0.2213 - val_acc: 0.9203\n",
            "Epoch 19/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.2651 - acc: 0.9025 - val_loss: 0.2195 - val_acc: 0.9203\n",
            "Epoch 20/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2625 - acc: 0.9006 - val_loss: 0.2171 - val_acc: 0.9211\n",
            "Epoch 21/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2609 - acc: 0.9036 - val_loss: 0.2145 - val_acc: 0.9229\n",
            "Epoch 22/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2538 - acc: 0.9032 - val_loss: 0.2126 - val_acc: 0.9237\n",
            "Epoch 23/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2558 - acc: 0.9025 - val_loss: 0.2168 - val_acc: 0.9229\n",
            "Epoch 24/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2479 - acc: 0.9012 - val_loss: 0.2139 - val_acc: 0.9220\n",
            "Epoch 25/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2505 - acc: 0.9040 - val_loss: 0.2126 - val_acc: 0.9220\n",
            "Epoch 26/500\n",
            "4616/4616 [==============================] - 1s 279us/step - loss: 0.2463 - acc: 0.9064 - val_loss: 0.2176 - val_acc: 0.9220\n",
            "Epoch 27/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2483 - acc: 0.9051 - val_loss: 0.2161 - val_acc: 0.9229\n",
            "Epoch 28/500\n",
            "4616/4616 [==============================] - 1s 279us/step - loss: 0.2437 - acc: 0.9079 - val_loss: 0.2172 - val_acc: 0.9229\n",
            "Epoch 29/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2474 - acc: 0.9064 - val_loss: 0.2227 - val_acc: 0.9246\n",
            "Epoch 30/500\n",
            "4616/4616 [==============================] - 1s 280us/step - loss: 0.2501 - acc: 0.9042 - val_loss: 0.2290 - val_acc: 0.9237\n",
            "Epoch 31/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2462 - acc: 0.9021 - val_loss: 0.2278 - val_acc: 0.9237\n",
            "Epoch 32/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2446 - acc: 0.9068 - val_loss: 0.2267 - val_acc: 0.9263\n",
            "Epoch 33/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.2300 - acc: 0.9073 - val_loss: 0.2257 - val_acc: 0.9263\n",
            "Epoch 34/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2374 - acc: 0.9053 - val_loss: 0.2248 - val_acc: 0.9272\n",
            "Epoch 35/500\n",
            "4616/4616 [==============================] - 1s 282us/step - loss: 0.2487 - acc: 0.9040 - val_loss: 0.2240 - val_acc: 0.9263\n",
            "Epoch 36/500\n",
            "4616/4616 [==============================] - 1s 279us/step - loss: 0.2458 - acc: 0.9075 - val_loss: 0.2232 - val_acc: 0.9272\n",
            "Epoch 37/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2314 - acc: 0.9058 - val_loss: 0.2224 - val_acc: 0.9272\n",
            "Epoch 38/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.2383 - acc: 0.9097 - val_loss: 0.2215 - val_acc: 0.9272\n",
            "Epoch 39/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2332 - acc: 0.9079 - val_loss: 0.2207 - val_acc: 0.9272\n",
            "Epoch 40/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2266 - acc: 0.9107 - val_loss: 0.2198 - val_acc: 0.9272\n",
            "Epoch 41/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2405 - acc: 0.9068 - val_loss: 0.2114 - val_acc: 0.9272\n",
            "Epoch 42/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2323 - acc: 0.9066 - val_loss: 0.2103 - val_acc: 0.9272\n",
            "Epoch 43/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2320 - acc: 0.9075 - val_loss: 0.2094 - val_acc: 0.9272\n",
            "Epoch 44/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.2209 - acc: 0.9125 - val_loss: 0.2087 - val_acc: 0.9289\n",
            "Epoch 45/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2269 - acc: 0.9136 - val_loss: 0.2079 - val_acc: 0.9289\n",
            "Epoch 46/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2229 - acc: 0.9107 - val_loss: 0.2073 - val_acc: 0.9298\n",
            "Epoch 47/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2285 - acc: 0.9131 - val_loss: 0.2064 - val_acc: 0.9307\n",
            "Epoch 48/500\n",
            "4616/4616 [==============================] - 1s 280us/step - loss: 0.2235 - acc: 0.9120 - val_loss: 0.2056 - val_acc: 0.9307\n",
            "Epoch 49/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2285 - acc: 0.9110 - val_loss: 0.2048 - val_acc: 0.9307\n",
            "Epoch 50/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2253 - acc: 0.9097 - val_loss: 0.2043 - val_acc: 0.9307\n",
            "Epoch 51/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2172 - acc: 0.9127 - val_loss: 0.2032 - val_acc: 0.9307\n",
            "Epoch 52/500\n",
            "4616/4616 [==============================] - 1s 279us/step - loss: 0.2179 - acc: 0.9084 - val_loss: 0.2029 - val_acc: 0.9315\n",
            "Epoch 53/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2176 - acc: 0.9144 - val_loss: 0.2028 - val_acc: 0.9324\n",
            "Epoch 54/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2159 - acc: 0.9131 - val_loss: 0.2027 - val_acc: 0.9324\n",
            "Epoch 55/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2137 - acc: 0.9120 - val_loss: 0.1958 - val_acc: 0.9324\n",
            "Epoch 56/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2123 - acc: 0.9133 - val_loss: 0.1951 - val_acc: 0.9315\n",
            "Epoch 57/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2152 - acc: 0.9138 - val_loss: 0.1960 - val_acc: 0.9324\n",
            "Epoch 58/500\n",
            "4616/4616 [==============================] - 1s 279us/step - loss: 0.2111 - acc: 0.9123 - val_loss: 0.2008 - val_acc: 0.9324\n",
            "Epoch 59/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2149 - acc: 0.9097 - val_loss: 0.2001 - val_acc: 0.9324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/500\n",
            "4616/4616 [==============================] - 1s 289us/step - loss: 0.2058 - acc: 0.9168 - val_loss: 0.1993 - val_acc: 0.9333\n",
            "Epoch 61/500\n",
            "4616/4616 [==============================] - 1s 281us/step - loss: 0.2069 - acc: 0.9153 - val_loss: 0.1987 - val_acc: 0.9315\n",
            "Epoch 62/500\n",
            "4616/4616 [==============================] - 1s 284us/step - loss: 0.2174 - acc: 0.9144 - val_loss: 0.1981 - val_acc: 0.9315\n",
            "Epoch 63/500\n",
            "4616/4616 [==============================] - 1s 282us/step - loss: 0.2217 - acc: 0.9146 - val_loss: 0.1977 - val_acc: 0.9315\n",
            "Epoch 64/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2126 - acc: 0.9157 - val_loss: 0.1975 - val_acc: 0.9315\n",
            "Epoch 65/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2047 - acc: 0.9133 - val_loss: 0.1974 - val_acc: 0.9324\n",
            "Epoch 66/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.2142 - acc: 0.9170 - val_loss: 0.1972 - val_acc: 0.9324\n",
            "Epoch 67/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.2112 - acc: 0.9155 - val_loss: 0.1971 - val_acc: 0.9324\n",
            "Epoch 68/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.2125 - acc: 0.9179 - val_loss: 0.1975 - val_acc: 0.9324\n",
            "Epoch 69/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.2046 - acc: 0.9153 - val_loss: 0.2037 - val_acc: 0.9333\n",
            "Epoch 70/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.2019 - acc: 0.9157 - val_loss: 0.2032 - val_acc: 0.9333\n",
            "Epoch 71/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.2035 - acc: 0.9185 - val_loss: 0.2028 - val_acc: 0.9341\n",
            "Epoch 72/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2073 - acc: 0.9201 - val_loss: 0.2025 - val_acc: 0.9359\n",
            "Epoch 73/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1974 - acc: 0.9159 - val_loss: 0.2022 - val_acc: 0.9350\n",
            "Epoch 74/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.2157 - acc: 0.9131 - val_loss: 0.2019 - val_acc: 0.9341\n",
            "Epoch 75/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2024 - acc: 0.9146 - val_loss: 0.2017 - val_acc: 0.9341\n",
            "Epoch 76/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1962 - acc: 0.9149 - val_loss: 0.2016 - val_acc: 0.9341\n",
            "Epoch 77/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.2000 - acc: 0.9162 - val_loss: 0.2018 - val_acc: 0.9333\n",
            "Epoch 78/500\n",
            "4616/4616 [==============================] - 1s 271us/step - loss: 0.1984 - acc: 0.9201 - val_loss: 0.2025 - val_acc: 0.9359\n",
            "Epoch 79/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2046 - acc: 0.9168 - val_loss: 0.1975 - val_acc: 0.9341\n",
            "Epoch 80/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1982 - acc: 0.9159 - val_loss: 0.2028 - val_acc: 0.9333\n",
            "Epoch 81/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2050 - acc: 0.9166 - val_loss: 0.2023 - val_acc: 0.9333\n",
            "Epoch 82/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1994 - acc: 0.9190 - val_loss: 0.2020 - val_acc: 0.9333\n",
            "Epoch 83/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2024 - acc: 0.9188 - val_loss: 0.2017 - val_acc: 0.9315\n",
            "Epoch 84/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1947 - acc: 0.9168 - val_loss: 0.2014 - val_acc: 0.9315\n",
            "Epoch 85/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1961 - acc: 0.9203 - val_loss: 0.2011 - val_acc: 0.9333\n",
            "Epoch 86/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1996 - acc: 0.9179 - val_loss: 0.2009 - val_acc: 0.9341\n",
            "Epoch 87/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.1965 - acc: 0.9162 - val_loss: 0.2008 - val_acc: 0.9350\n",
            "Epoch 88/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1876 - acc: 0.9220 - val_loss: 0.2017 - val_acc: 0.9350\n",
            "Epoch 89/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.1897 - acc: 0.9235 - val_loss: 0.2077 - val_acc: 0.9341\n",
            "Epoch 90/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1909 - acc: 0.9240 - val_loss: 0.2072 - val_acc: 0.9367\n",
            "Epoch 91/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.1905 - acc: 0.9196 - val_loss: 0.1999 - val_acc: 0.9376\n",
            "Epoch 92/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1908 - acc: 0.9220 - val_loss: 0.1992 - val_acc: 0.9376\n",
            "Epoch 93/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1914 - acc: 0.9229 - val_loss: 0.1979 - val_acc: 0.9367\n",
            "Epoch 94/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1838 - acc: 0.9255 - val_loss: 0.1976 - val_acc: 0.9376\n",
            "Epoch 95/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1859 - acc: 0.9214 - val_loss: 0.1973 - val_acc: 0.9376\n",
            "Epoch 96/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1991 - acc: 0.9207 - val_loss: 0.1970 - val_acc: 0.9367\n",
            "Epoch 97/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.1854 - acc: 0.9211 - val_loss: 0.1970 - val_acc: 0.9350\n",
            "Epoch 98/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1831 - acc: 0.9253 - val_loss: 0.2000 - val_acc: 0.9324\n",
            "Epoch 99/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1955 - acc: 0.9216 - val_loss: 0.2051 - val_acc: 0.9333\n",
            "Epoch 100/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.1845 - acc: 0.9235 - val_loss: 0.2054 - val_acc: 0.9333\n",
            "Epoch 101/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1890 - acc: 0.9235 - val_loss: 0.2055 - val_acc: 0.9324\n",
            "Epoch 102/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1955 - acc: 0.9201 - val_loss: 0.2055 - val_acc: 0.9324\n",
            "Epoch 103/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1840 - acc: 0.9220 - val_loss: 0.2053 - val_acc: 0.9324\n",
            "Epoch 104/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1749 - acc: 0.9255 - val_loss: 0.2044 - val_acc: 0.9333\n",
            "Epoch 105/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.1806 - acc: 0.9211 - val_loss: 0.2034 - val_acc: 0.9333\n",
            "Epoch 106/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1817 - acc: 0.9218 - val_loss: 0.1944 - val_acc: 0.9333\n",
            "Epoch 107/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1886 - acc: 0.9244 - val_loss: 0.1944 - val_acc: 0.9341\n",
            "Epoch 108/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1850 - acc: 0.9250 - val_loss: 0.1949 - val_acc: 0.9359\n",
            "Epoch 109/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1854 - acc: 0.9224 - val_loss: 0.1881 - val_acc: 0.9359\n",
            "Epoch 110/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1873 - acc: 0.9229 - val_loss: 0.1891 - val_acc: 0.9359\n",
            "Epoch 111/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.1961 - acc: 0.9183 - val_loss: 0.1945 - val_acc: 0.9341\n",
            "Epoch 112/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.1798 - acc: 0.9276 - val_loss: 0.1940 - val_acc: 0.9341\n",
            "Epoch 113/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1811 - acc: 0.9255 - val_loss: 0.1938 - val_acc: 0.9333\n",
            "Epoch 114/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.1806 - acc: 0.9244 - val_loss: 0.1949 - val_acc: 0.9315\n",
            "Epoch 115/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1827 - acc: 0.9250 - val_loss: 0.2026 - val_acc: 0.9315\n",
            "Epoch 116/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.1754 - acc: 0.9287 - val_loss: 0.2024 - val_acc: 0.9315\n",
            "Epoch 117/500\n",
            "4616/4616 [==============================] - 1s 301us/step - loss: 0.1835 - acc: 0.9237 - val_loss: 0.2023 - val_acc: 0.9315\n",
            "Epoch 118/500\n",
            "4616/4616 [==============================] - 1s 280us/step - loss: 0.1738 - acc: 0.9279 - val_loss: 0.2022 - val_acc: 0.9324\n",
            "Epoch 119/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1764 - acc: 0.9218 - val_loss: 0.2021 - val_acc: 0.9324\n",
            "Epoch 120/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.1817 - acc: 0.9222 - val_loss: 0.2020 - val_acc: 0.9324\n",
            "Epoch 121/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.1759 - acc: 0.9216 - val_loss: 0.2019 - val_acc: 0.9315\n",
            "Epoch 122/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1819 - acc: 0.9261 - val_loss: 0.2018 - val_acc: 0.9324\n",
            "Epoch 123/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1785 - acc: 0.9244 - val_loss: 0.2017 - val_acc: 0.9333\n",
            "Epoch 124/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1882 - acc: 0.9255 - val_loss: 0.2016 - val_acc: 0.9359\n",
            "Epoch 125/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.1708 - acc: 0.9268 - val_loss: 0.2015 - val_acc: 0.9359\n",
            "Epoch 126/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1725 - acc: 0.9237 - val_loss: 0.2015 - val_acc: 0.9359\n",
            "Epoch 127/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1751 - acc: 0.9261 - val_loss: 0.2011 - val_acc: 0.9359\n",
            "Epoch 128/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1695 - acc: 0.9289 - val_loss: 0.2007 - val_acc: 0.9367\n",
            "Epoch 129/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.1654 - acc: 0.9318 - val_loss: 0.2003 - val_acc: 0.9367\n",
            "Epoch 130/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1719 - acc: 0.9270 - val_loss: 0.1999 - val_acc: 0.9367\n",
            "Epoch 131/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1702 - acc: 0.9320 - val_loss: 0.1996 - val_acc: 0.9367\n",
            "Epoch 132/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.1690 - acc: 0.9281 - val_loss: 0.1994 - val_acc: 0.9376\n",
            "Epoch 133/500\n",
            "4616/4616 [==============================] - 1s 271us/step - loss: 0.1719 - acc: 0.9276 - val_loss: 0.1993 - val_acc: 0.9376\n",
            "Epoch 134/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.1667 - acc: 0.9300 - val_loss: 0.1993 - val_acc: 0.9376\n",
            "Epoch 135/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.1817 - acc: 0.9237 - val_loss: 0.1994 - val_acc: 0.9376\n",
            "Epoch 136/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.1694 - acc: 0.9302 - val_loss: 0.1995 - val_acc: 0.9376\n",
            "Epoch 137/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1634 - acc: 0.9300 - val_loss: 0.1996 - val_acc: 0.9367\n",
            "Epoch 138/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1713 - acc: 0.9285 - val_loss: 0.1997 - val_acc: 0.9367\n",
            "Epoch 139/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1677 - acc: 0.9274 - val_loss: 0.1998 - val_acc: 0.9367\n",
            "Epoch 140/500\n",
            "4616/4616 [==============================] - 1s 279us/step - loss: 0.1796 - acc: 0.9289 - val_loss: 0.1990 - val_acc: 0.9367\n",
            "Epoch 141/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.1722 - acc: 0.9292 - val_loss: 0.1982 - val_acc: 0.9367\n",
            "Epoch 142/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1713 - acc: 0.9266 - val_loss: 0.1977 - val_acc: 0.9376\n",
            "Epoch 143/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1604 - acc: 0.9315 - val_loss: 0.1972 - val_acc: 0.9385\n",
            "Epoch 144/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1647 - acc: 0.9268 - val_loss: 0.1969 - val_acc: 0.9385\n",
            "Epoch 145/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1652 - acc: 0.9320 - val_loss: 0.1967 - val_acc: 0.9393\n",
            "Epoch 146/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1631 - acc: 0.9300 - val_loss: 0.1965 - val_acc: 0.9393\n",
            "Epoch 147/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1619 - acc: 0.9296 - val_loss: 0.1965 - val_acc: 0.9393\n",
            "Epoch 148/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1703 - acc: 0.9296 - val_loss: 0.1965 - val_acc: 0.9393\n",
            "Epoch 149/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1773 - acc: 0.9309 - val_loss: 0.1967 - val_acc: 0.9385\n",
            "Epoch 150/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1712 - acc: 0.9294 - val_loss: 0.1971 - val_acc: 0.9367\n",
            "Epoch 151/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.1629 - acc: 0.9370 - val_loss: 0.1977 - val_acc: 0.9367\n",
            "Epoch 152/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1579 - acc: 0.9313 - val_loss: 0.1986 - val_acc: 0.9367\n",
            "Epoch 153/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1678 - acc: 0.9315 - val_loss: 0.1999 - val_acc: 0.9367\n",
            "Epoch 154/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1601 - acc: 0.9344 - val_loss: 0.2067 - val_acc: 0.9367\n",
            "Epoch 155/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1642 - acc: 0.9328 - val_loss: 0.2068 - val_acc: 0.9367\n",
            "Epoch 156/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.1619 - acc: 0.9318 - val_loss: 0.2067 - val_acc: 0.9376\n",
            "Epoch 157/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1588 - acc: 0.9333 - val_loss: 0.2066 - val_acc: 0.9385\n",
            "Epoch 158/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.1553 - acc: 0.9318 - val_loss: 0.1983 - val_acc: 0.9393\n",
            "Epoch 159/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1581 - acc: 0.9315 - val_loss: 0.1971 - val_acc: 0.9393\n",
            "Epoch 00159: early stopping\n",
            "Train on 4616 samples, validate on 1154 samples\n",
            "Epoch 1/500\n",
            "4616/4616 [==============================] - 2s 380us/step - loss: 0.4446 - acc: 0.8037 - val_loss: 0.3085 - val_acc: 0.8882\n",
            "Epoch 2/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.3713 - acc: 0.8514 - val_loss: 0.2730 - val_acc: 0.9029\n",
            "Epoch 3/500\n",
            "4616/4616 [==============================] - 1s 279us/step - loss: 0.3332 - acc: 0.8826 - val_loss: 0.3139 - val_acc: 0.9038\n",
            "Epoch 4/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.3472 - acc: 0.8837 - val_loss: 0.3193 - val_acc: 0.9029\n",
            "Epoch 5/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.3773 - acc: 0.8795 - val_loss: 0.3182 - val_acc: 0.9012\n",
            "Epoch 6/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.3753 - acc: 0.8819 - val_loss: 0.2989 - val_acc: 0.9012\n",
            "Epoch 7/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.3392 - acc: 0.8798 - val_loss: 0.2650 - val_acc: 0.9047\n",
            "Epoch 8/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.3114 - acc: 0.8832 - val_loss: 0.2624 - val_acc: 0.9047\n",
            "Epoch 9/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.3084 - acc: 0.8854 - val_loss: 0.2537 - val_acc: 0.9055\n",
            "Epoch 10/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2919 - acc: 0.8893 - val_loss: 0.2554 - val_acc: 0.9073\n",
            "Epoch 11/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2885 - acc: 0.8915 - val_loss: 0.2560 - val_acc: 0.9116\n",
            "Epoch 12/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2903 - acc: 0.8912 - val_loss: 0.2550 - val_acc: 0.9125\n",
            "Epoch 13/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2936 - acc: 0.8906 - val_loss: 0.2525 - val_acc: 0.9125\n",
            "Epoch 14/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2849 - acc: 0.8960 - val_loss: 0.2483 - val_acc: 0.9133\n",
            "Epoch 15/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2905 - acc: 0.8956 - val_loss: 0.2427 - val_acc: 0.9133\n",
            "Epoch 16/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2761 - acc: 0.9021 - val_loss: 0.2365 - val_acc: 0.9151\n",
            "Epoch 17/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2797 - acc: 0.8960 - val_loss: 0.2312 - val_acc: 0.9159\n",
            "Epoch 18/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2753 - acc: 0.8995 - val_loss: 0.2434 - val_acc: 0.9168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2719 - acc: 0.8958 - val_loss: 0.2394 - val_acc: 0.9168\n",
            "Epoch 20/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2880 - acc: 0.8964 - val_loss: 0.2390 - val_acc: 0.9177\n",
            "Epoch 21/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2630 - acc: 0.8980 - val_loss: 0.2578 - val_acc: 0.9185\n",
            "Epoch 22/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2876 - acc: 0.8980 - val_loss: 0.2783 - val_acc: 0.9185\n",
            "Epoch 23/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.3093 - acc: 0.8995 - val_loss: 0.2859 - val_acc: 0.9194\n",
            "Epoch 24/500\n",
            "4616/4616 [==============================] - 1s 279us/step - loss: 0.2888 - acc: 0.9008 - val_loss: 0.2928 - val_acc: 0.9194\n",
            "Epoch 25/500\n",
            "4616/4616 [==============================] - 1s 280us/step - loss: 0.2745 - acc: 0.8995 - val_loss: 0.2714 - val_acc: 0.9194\n",
            "Epoch 26/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2752 - acc: 0.8995 - val_loss: 0.2402 - val_acc: 0.9203\n",
            "Epoch 27/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2554 - acc: 0.9012 - val_loss: 0.2386 - val_acc: 0.9203\n",
            "Epoch 28/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2617 - acc: 0.9079 - val_loss: 0.2407 - val_acc: 0.9211\n",
            "Epoch 29/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2666 - acc: 0.8993 - val_loss: 0.2350 - val_acc: 0.9220\n",
            "Epoch 30/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2639 - acc: 0.9040 - val_loss: 0.2383 - val_acc: 0.9255\n",
            "Epoch 31/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2584 - acc: 0.9014 - val_loss: 0.2409 - val_acc: 0.9229\n",
            "Epoch 32/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2539 - acc: 0.9055 - val_loss: 0.2417 - val_acc: 0.9237\n",
            "Epoch 33/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2651 - acc: 0.8997 - val_loss: 0.2325 - val_acc: 0.9220\n",
            "Epoch 34/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.2579 - acc: 0.9051 - val_loss: 0.2294 - val_acc: 0.9237\n",
            "Epoch 35/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2517 - acc: 0.9019 - val_loss: 0.2264 - val_acc: 0.9281\n",
            "Epoch 36/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2530 - acc: 0.9047 - val_loss: 0.2241 - val_acc: 0.9263\n",
            "Epoch 37/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2476 - acc: 0.9064 - val_loss: 0.2221 - val_acc: 0.9237\n",
            "Epoch 38/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2516 - acc: 0.9019 - val_loss: 0.2211 - val_acc: 0.9229\n",
            "Epoch 39/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2493 - acc: 0.9029 - val_loss: 0.2210 - val_acc: 0.9203\n",
            "Epoch 40/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2535 - acc: 0.9038 - val_loss: 0.2220 - val_acc: 0.9194\n",
            "Epoch 41/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2538 - acc: 0.9034 - val_loss: 0.2250 - val_acc: 0.9203\n",
            "Epoch 42/500\n",
            "4616/4616 [==============================] - 1s 279us/step - loss: 0.2749 - acc: 0.8982 - val_loss: 0.2436 - val_acc: 0.9194\n",
            "Epoch 43/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2603 - acc: 0.9027 - val_loss: 0.2502 - val_acc: 0.9211\n",
            "Epoch 44/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2372 - acc: 0.9071 - val_loss: 0.2494 - val_acc: 0.9220\n",
            "Epoch 45/500\n",
            "4616/4616 [==============================] - 1s 279us/step - loss: 0.2470 - acc: 0.9090 - val_loss: 0.2477 - val_acc: 0.9246\n",
            "Epoch 46/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2589 - acc: 0.9058 - val_loss: 0.2448 - val_acc: 0.9263\n",
            "Epoch 47/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2433 - acc: 0.9075 - val_loss: 0.2417 - val_acc: 0.9289\n",
            "Epoch 48/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2628 - acc: 0.9094 - val_loss: 0.2158 - val_acc: 0.9281\n",
            "Epoch 49/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2429 - acc: 0.9105 - val_loss: 0.2199 - val_acc: 0.9298\n",
            "Epoch 50/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2375 - acc: 0.9092 - val_loss: 0.2203 - val_acc: 0.9307\n",
            "Epoch 51/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2428 - acc: 0.9058 - val_loss: 0.2224 - val_acc: 0.9272\n",
            "Epoch 52/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2507 - acc: 0.9081 - val_loss: 0.2241 - val_acc: 0.9263\n",
            "Epoch 53/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2561 - acc: 0.9058 - val_loss: 0.2244 - val_acc: 0.9263\n",
            "Epoch 54/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2446 - acc: 0.9144 - val_loss: 0.2233 - val_acc: 0.9255\n",
            "Epoch 55/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2466 - acc: 0.9090 - val_loss: 0.2252 - val_acc: 0.9263\n",
            "Epoch 56/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2472 - acc: 0.9116 - val_loss: 0.2258 - val_acc: 0.9289\n",
            "Epoch 57/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2400 - acc: 0.9114 - val_loss: 0.2251 - val_acc: 0.9315\n",
            "Epoch 58/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2306 - acc: 0.9146 - val_loss: 0.2158 - val_acc: 0.9315\n",
            "Epoch 59/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2365 - acc: 0.9110 - val_loss: 0.2129 - val_acc: 0.9324\n",
            "Epoch 60/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2278 - acc: 0.9112 - val_loss: 0.2117 - val_acc: 0.9289\n",
            "Epoch 61/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.2251 - acc: 0.9123 - val_loss: 0.2199 - val_acc: 0.9281\n",
            "Epoch 62/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2278 - acc: 0.9086 - val_loss: 0.2204 - val_acc: 0.9281\n",
            "Epoch 63/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2216 - acc: 0.9107 - val_loss: 0.2301 - val_acc: 0.9246\n",
            "Epoch 64/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2345 - acc: 0.9081 - val_loss: 0.2316 - val_acc: 0.9246\n",
            "Epoch 65/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2282 - acc: 0.9092 - val_loss: 0.2325 - val_acc: 0.9246\n",
            "Epoch 66/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2291 - acc: 0.9079 - val_loss: 0.2327 - val_acc: 0.9246\n",
            "Epoch 67/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2308 - acc: 0.9110 - val_loss: 0.2315 - val_acc: 0.9246\n",
            "Epoch 68/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2309 - acc: 0.9077 - val_loss: 0.2285 - val_acc: 0.9263\n",
            "Epoch 69/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2324 - acc: 0.9084 - val_loss: 0.2262 - val_acc: 0.9272\n",
            "Epoch 70/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2253 - acc: 0.9133 - val_loss: 0.2176 - val_acc: 0.9298\n",
            "Epoch 71/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2162 - acc: 0.9114 - val_loss: 0.2189 - val_acc: 0.9307\n",
            "Epoch 72/500\n",
            "4616/4616 [==============================] - 1s 282us/step - loss: 0.2181 - acc: 0.9129 - val_loss: 0.2254 - val_acc: 0.9333\n",
            "Epoch 73/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2232 - acc: 0.9144 - val_loss: 0.2252 - val_acc: 0.9350\n",
            "Epoch 74/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.2281 - acc: 0.9107 - val_loss: 0.2250 - val_acc: 0.9341\n",
            "Epoch 75/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2198 - acc: 0.9131 - val_loss: 0.2245 - val_acc: 0.9333\n",
            "Epoch 76/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2184 - acc: 0.9136 - val_loss: 0.2240 - val_acc: 0.9324\n",
            "Epoch 77/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2269 - acc: 0.9144 - val_loss: 0.2318 - val_acc: 0.9324\n",
            "Epoch 78/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2192 - acc: 0.9153 - val_loss: 0.2311 - val_acc: 0.9324\n",
            "Epoch 79/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2167 - acc: 0.9133 - val_loss: 0.2314 - val_acc: 0.9324\n",
            "Epoch 80/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2208 - acc: 0.9131 - val_loss: 0.2337 - val_acc: 0.9315\n",
            "Epoch 81/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2221 - acc: 0.9142 - val_loss: 0.2513 - val_acc: 0.9307\n",
            "Epoch 82/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.2172 - acc: 0.9112 - val_loss: 0.2534 - val_acc: 0.9315\n",
            "Epoch 83/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2260 - acc: 0.9146 - val_loss: 0.2476 - val_acc: 0.9324\n",
            "Epoch 84/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2243 - acc: 0.9175 - val_loss: 0.2479 - val_acc: 0.9307\n",
            "Epoch 85/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2151 - acc: 0.9153 - val_loss: 0.2548 - val_acc: 0.9315\n",
            "Epoch 86/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2080 - acc: 0.9192 - val_loss: 0.2539 - val_acc: 0.9315\n",
            "Epoch 87/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2093 - acc: 0.9159 - val_loss: 0.2387 - val_acc: 0.9307\n",
            "Epoch 88/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2171 - acc: 0.9203 - val_loss: 0.2356 - val_acc: 0.9298\n",
            "Epoch 89/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2192 - acc: 0.9159 - val_loss: 0.2331 - val_acc: 0.9315\n",
            "Epoch 90/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2101 - acc: 0.9157 - val_loss: 0.2226 - val_acc: 0.9324\n",
            "Epoch 91/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2051 - acc: 0.9185 - val_loss: 0.2215 - val_acc: 0.9350\n",
            "Epoch 92/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.2121 - acc: 0.9190 - val_loss: 0.2212 - val_acc: 0.9350\n",
            "Epoch 93/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2097 - acc: 0.9188 - val_loss: 0.2209 - val_acc: 0.9350\n",
            "Epoch 94/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.2065 - acc: 0.9190 - val_loss: 0.2209 - val_acc: 0.9350\n",
            "Epoch 95/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2127 - acc: 0.9114 - val_loss: 0.2213 - val_acc: 0.9350\n",
            "Epoch 96/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2148 - acc: 0.9175 - val_loss: 0.2250 - val_acc: 0.9324\n",
            "Epoch 97/500\n",
            "4616/4616 [==============================] - 1s 280us/step - loss: 0.2129 - acc: 0.9146 - val_loss: 0.2393 - val_acc: 0.9307\n",
            "Epoch 98/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2114 - acc: 0.9172 - val_loss: 0.2400 - val_acc: 0.9298\n",
            "Epoch 99/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2115 - acc: 0.9168 - val_loss: 0.2413 - val_acc: 0.9307\n",
            "Epoch 100/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2197 - acc: 0.9136 - val_loss: 0.2218 - val_acc: 0.9307\n",
            "Epoch 101/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2016 - acc: 0.9192 - val_loss: 0.2190 - val_acc: 0.9333\n",
            "Epoch 102/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2066 - acc: 0.9190 - val_loss: 0.2199 - val_acc: 0.9333\n",
            "Epoch 103/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2068 - acc: 0.9185 - val_loss: 0.2214 - val_acc: 0.9376\n",
            "Epoch 104/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2114 - acc: 0.9192 - val_loss: 0.2218 - val_acc: 0.9359\n",
            "Epoch 105/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.2089 - acc: 0.9179 - val_loss: 0.2215 - val_acc: 0.9341\n",
            "Epoch 106/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2082 - acc: 0.9181 - val_loss: 0.2142 - val_acc: 0.9333\n",
            "Epoch 107/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2081 - acc: 0.9190 - val_loss: 0.2111 - val_acc: 0.9350\n",
            "Epoch 108/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2105 - acc: 0.9194 - val_loss: 0.2097 - val_acc: 0.9333\n",
            "Epoch 109/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2040 - acc: 0.9194 - val_loss: 0.2090 - val_acc: 0.9324\n",
            "Epoch 110/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2044 - acc: 0.9194 - val_loss: 0.2092 - val_acc: 0.9315\n",
            "Epoch 111/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2060 - acc: 0.9198 - val_loss: 0.2099 - val_acc: 0.9324\n",
            "Epoch 112/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2052 - acc: 0.9194 - val_loss: 0.2115 - val_acc: 0.9324\n",
            "Epoch 113/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1970 - acc: 0.9164 - val_loss: 0.2165 - val_acc: 0.9324\n",
            "Epoch 114/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2124 - acc: 0.9142 - val_loss: 0.2322 - val_acc: 0.9315\n",
            "Epoch 115/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2028 - acc: 0.9151 - val_loss: 0.2494 - val_acc: 0.9333\n",
            "Epoch 116/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2102 - acc: 0.9131 - val_loss: 0.2568 - val_acc: 0.9324\n",
            "Epoch 117/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.2078 - acc: 0.9175 - val_loss: 0.2561 - val_acc: 0.9341\n",
            "Epoch 118/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2052 - acc: 0.9131 - val_loss: 0.2552 - val_acc: 0.9359\n",
            "Epoch 119/500\n",
            "4616/4616 [==============================] - 1s 279us/step - loss: 0.2061 - acc: 0.9151 - val_loss: 0.2482 - val_acc: 0.9385\n",
            "Epoch 120/500\n",
            "4616/4616 [==============================] - 1s 280us/step - loss: 0.2186 - acc: 0.9181 - val_loss: 0.2355 - val_acc: 0.9367\n",
            "Epoch 121/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1999 - acc: 0.9185 - val_loss: 0.2340 - val_acc: 0.9359\n",
            "Epoch 122/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2005 - acc: 0.9207 - val_loss: 0.2249 - val_acc: 0.9350\n",
            "Epoch 123/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2041 - acc: 0.9157 - val_loss: 0.2239 - val_acc: 0.9341\n",
            "Epoch 124/500\n",
            "4616/4616 [==============================] - 1s 282us/step - loss: 0.2042 - acc: 0.9144 - val_loss: 0.2235 - val_acc: 0.9341\n",
            "Epoch 125/500\n",
            "4616/4616 [==============================] - 1s 278us/step - loss: 0.2025 - acc: 0.9153 - val_loss: 0.2229 - val_acc: 0.9350\n",
            "Epoch 126/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2054 - acc: 0.9192 - val_loss: 0.2224 - val_acc: 0.9359\n",
            "Epoch 127/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.1975 - acc: 0.9168 - val_loss: 0.2223 - val_acc: 0.9367\n",
            "Epoch 128/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.1952 - acc: 0.9168 - val_loss: 0.2235 - val_acc: 0.9367\n",
            "Epoch 129/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1989 - acc: 0.9185 - val_loss: 0.2322 - val_acc: 0.9367\n",
            "Epoch 130/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1868 - acc: 0.9209 - val_loss: 0.2337 - val_acc: 0.9359\n",
            "Epoch 131/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1958 - acc: 0.9207 - val_loss: 0.2351 - val_acc: 0.9350\n",
            "Epoch 132/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2038 - acc: 0.9181 - val_loss: 0.2343 - val_acc: 0.9341\n",
            "Epoch 133/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.2030 - acc: 0.9216 - val_loss: 0.2344 - val_acc: 0.9341\n",
            "Epoch 134/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1992 - acc: 0.9201 - val_loss: 0.2352 - val_acc: 0.9350\n",
            "Epoch 135/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.2082 - acc: 0.9177 - val_loss: 0.2337 - val_acc: 0.9350\n",
            "Epoch 136/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1910 - acc: 0.9214 - val_loss: 0.2329 - val_acc: 0.9350\n",
            "Epoch 137/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.1901 - acc: 0.9172 - val_loss: 0.2320 - val_acc: 0.9359\n",
            "Epoch 138/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.1876 - acc: 0.9220 - val_loss: 0.2256 - val_acc: 0.9359\n",
            "Epoch 139/500\n",
            "4616/4616 [==============================] - 1s 272us/step - loss: 0.1924 - acc: 0.9201 - val_loss: 0.2307 - val_acc: 0.9359\n",
            "Epoch 140/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1892 - acc: 0.9209 - val_loss: 0.2225 - val_acc: 0.9359\n",
            "Epoch 141/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1902 - acc: 0.9198 - val_loss: 0.2229 - val_acc: 0.9359\n",
            "Epoch 142/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.1876 - acc: 0.9218 - val_loss: 0.2303 - val_acc: 0.9359\n",
            "Epoch 143/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1947 - acc: 0.9198 - val_loss: 0.2310 - val_acc: 0.9350\n",
            "Epoch 144/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.1905 - acc: 0.9183 - val_loss: 0.2397 - val_acc: 0.9350\n",
            "Epoch 145/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.1932 - acc: 0.9192 - val_loss: 0.2481 - val_acc: 0.9359\n",
            "Epoch 146/500\n",
            "4616/4616 [==============================] - 1s 277us/step - loss: 0.1844 - acc: 0.9205 - val_loss: 0.2487 - val_acc: 0.9367\n",
            "Epoch 147/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.1900 - acc: 0.9237 - val_loss: 0.2499 - val_acc: 0.9359\n",
            "Epoch 148/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1887 - acc: 0.9246 - val_loss: 0.2586 - val_acc: 0.9350\n",
            "Epoch 149/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1912 - acc: 0.9224 - val_loss: 0.2598 - val_acc: 0.9350\n",
            "Epoch 150/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1963 - acc: 0.9203 - val_loss: 0.2661 - val_acc: 0.9350\n",
            "Epoch 151/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1935 - acc: 0.9224 - val_loss: 0.2660 - val_acc: 0.9359\n",
            "Epoch 152/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1830 - acc: 0.9211 - val_loss: 0.2658 - val_acc: 0.9359\n",
            "Epoch 153/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.1863 - acc: 0.9207 - val_loss: 0.2503 - val_acc: 0.9376\n",
            "Epoch 154/500\n",
            "4616/4616 [==============================] - 1s 273us/step - loss: 0.1984 - acc: 0.9194 - val_loss: 0.2187 - val_acc: 0.9324\n",
            "Epoch 155/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.1888 - acc: 0.9201 - val_loss: 0.2193 - val_acc: 0.9341\n",
            "Epoch 156/500\n",
            "4616/4616 [==============================] - 1s 275us/step - loss: 0.1934 - acc: 0.9233 - val_loss: 0.2223 - val_acc: 0.9333\n",
            "Epoch 157/500\n",
            "4616/4616 [==============================] - 1s 274us/step - loss: 0.1927 - acc: 0.9233 - val_loss: 0.2248 - val_acc: 0.9315\n",
            "Epoch 158/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.2015 - acc: 0.9218 - val_loss: 0.2258 - val_acc: 0.9333\n",
            "Epoch 159/500\n",
            "4616/4616 [==============================] - 1s 276us/step - loss: 0.1979 - acc: 0.9233 - val_loss: 0.2173 - val_acc: 0.9359\n",
            "Epoch 00159: early stopping\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Test Accuracy:  {:.3f}'.format(sklearn.metrics.accuracy_score(testY, predictions)))\n",
        "print('Test MCC:  {:.3f}'.format(sklearn.metrics.matthews_corrcoef(testY, predictions)))\n",
        "sklearn.metrics.confusion_matrix(testY, predictions)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy:  0.897\n",
            "Test MCC:  0.656\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": [
              "array([[4511,   78],\n",
              "       [ 519,  663]], dtype=int64)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have accuracies of nearly 90%! "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "Classifier.evaluate(testX, testY)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Models\\bow score: 0.891\n",
            "Model Models\\bow_005_1 score: 0.891\n",
            "Model Models\\bow_005_2 score: 0.892\n",
            "Model Models\\bow_005_3 score: 0.889\n",
            "Model Models\\glove score: 0.883\n",
            "Model Models\\glove_005_1 score: 0.879\n",
            "Model Models\\model_test_05 score: 0.891\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": [
              "{'ensembled': 0.896551724137931,\n",
              " 'Models\\\\bow': 0.8911800381216427,\n",
              " 'Models\\\\bow_005_1': 0.8910067579275689,\n",
              " 'Models\\\\bow_005_2': 0.8920464390920118,\n",
              " 'Models\\\\bow_005_3': 0.8894472361809045,\n",
              " 'Models\\\\glove': 0.8826893086120257,\n",
              " 'Models\\\\glove_005_1': 0.8790504245364755,\n",
              " 'Models\\\\model_test_05': 0.8911800381216427}"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.22.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}