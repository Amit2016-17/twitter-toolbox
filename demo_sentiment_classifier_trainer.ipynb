{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from twitter_nlp_toolkit.tweet_sentiment_classifier import tweet_sentiment_classifier\n",
    "from twitter_nlp_toolkit.file_fetcher import file_fetcher\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 1 # Fraction of data to train on - you can reduce for debugging for speed\n",
    "redownload=False\n",
    "model_path = 'Models'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we download pre-trained models and a validation dataset. The models have been trained on the Sentiment140 dataset, taken form here: https://www.kaggle.com/kazanova/sentiment140\n",
    "\n",
    "The validation data is hand-labeled airline customer feedback taken from https://www.figure-eight.com/data-for-everyone/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "if redownload: \n",
    "    downloader = file_fetcher.downloader(using_notebook=True)\n",
    "    # Validation data\n",
    "    downloader.download_file('https://www.dropbox.com/s/440m6x07bjg6c0h/Tweets.zip?dl=1',\"Tweets.zip\")\n",
    "    \n",
    "    # Compressed model\n",
    "    # Note that this model has only been trained on 5% of the training data\n",
    "    # Update when better-trained model is available\n",
    "    downloader.download_file(\"https://www.dropbox.com/s/i88eqlja56xncyx/model_test_05.zip?dl=1\",\"Models.zip\")\n",
    "    \n",
    "    # Extract all the contents of zip file in current directory\n",
    "    with ZipFile('Models.zip', 'r') as zipObj:\n",
    "        zipObj.extractall(path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation data\n",
    "\n",
    "test_data = pd.read_csv('Tweets.zip', header=0, names=['Index', 'Sentiment', 'Sentiment_confidence',\n",
    "                                                                'Negative_reason', 'Negative_reason_confidence',\n",
    "                                                                'Airline', 'Airline_sentiment_gold', 'Handle',\n",
    "                                                                'Negative_reason_gold', 'Retweet_count', 'Text',\n",
    "                                                                'Tweet_coord', 'Time', 'Location', 'Timezone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unlabeled test data\n",
    "\n",
    "test_data['Labels'] = (test_data['Sentiment'] == 'positive') * 2\n",
    "test_data['Labels'] = test_data['Labels'] + (test_data['Sentiment'] == 'neutral') * 1\n",
    "test_data['Labels'] = test_data['Labels'] / 2\n",
    "\n",
    "test_data.set_index('Labels')\n",
    "test_data = test_data[test_data.Labels != 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW model Models\\bow loaded successfully\n",
      "BoW model Models\\bow_005_1 loaded successfully\n",
      "BoW model Models\\bow_005_2 loaded successfully\n",
      "BoW model Models\\bow_005_3 loaded successfully\n",
      "Pre-trained embedding model loaded successfully\n",
      "Pre-trained embedding model loaded successfully\n",
      "Pre-trained embedding model loaded successfully\n",
      "Pre-trained embedding model loaded successfully\n",
      "LSTM model Models\\lstm loaded successfully\n",
      "LSTM model Models\\lstm_005_1 loaded successfully\n",
      "LSTM model Models\\lstm_005_2 loaded successfully\n",
      "LSTM model Models\\lstm_005_3 loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Executing this cell takes about 30s on a laptop\n",
    "\n",
    "Classifier = tweet_sentiment_classifier.SentimentAnalyzer()\n",
    "Classifier.load_models(path=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We santiy check the models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier.predict(['I am happy', 'I am sad', 'I am cheerful', 'I am mad'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the model on an airline customer feedback dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing this cell takes several minuites on a laptop\n",
    "\n",
    "predictions = Classifier.predict(test_data['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.759\n",
      "Test MCC:  0.512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6634, 2544],\n",
       "       [ 235, 2128]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test Accuracy:  {:.3f}'.format(sklearn.metrics.accuracy_score(test_data['Labels'], predictions)))\n",
    "print('Test MCC:  {:.3f}'.format(sklearn.metrics.matthews_corrcoef(test_data['Labels'], predictions)))\n",
    "sklearn.metrics.confusion_matrix(test_data['Labels'], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have accuracy of just under 80%.\n",
    "\n",
    "\n",
    "We split our evaluation dataset into validation and testing and eliminate the worst-performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valX, testX, valY, testY = sklearn.model_selection.train_test_split(test_data['Text'], test_data['Labels'], test_size=0.5, stratify=test_data['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Models\\bow score: 0.801\n",
      "Model Models\\bow_005_1 score: 0.741\n",
      "Model Models\\bow_005_2 score: 0.759\n",
      "Model Models\\bow_005_3 score: 0.750\n",
      "Model Models\\glove score: 0.771\n",
      "Model Models\\glove_005_1 score: 0.726\n",
      "Model Models\\glove_005_2 score: 0.673\n",
      "Deleting model Models\\glove_005_2\n",
      "Model Models\\glove_005_3 score: 0.679\n",
      "Deleting model Models\\glove_005_3\n",
      "Model Models\\lstm score: 0.686\n",
      "Deleting model Models\\lstm\n",
      "Model Models\\lstm_005_1 score: 0.653\n",
      "Deleting model Models\\lstm_005_1\n",
      "Model Models\\lstm_005_2 score: 0.642\n",
      "Deleting model Models\\lstm_005_2\n",
      "Model Models\\lstm_005_3 score: 0.648\n",
      "Deleting model Models\\lstm_005_3\n"
     ]
    }
   ],
   "source": [
    "# Executing this cell takes several minuites on a laptop\n",
    "\n",
    "\n",
    "Classifier.trim_models(valX, valY, threshold=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our custom-embedding models performed poorly on this dataset and have been pruned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.773\n",
      "Test MCC:  0.517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3425, 1164],\n",
       "       [ 147, 1035]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = Classifier.predict(testX)\n",
    "\n",
    "print('Test Accuracy:  {:.3f}'.format(sklearn.metrics.accuracy_score(testY, predictions)))\n",
    "print('Test MCC:  {:.3f}'.format(sklearn.metrics.matthews_corrcoef(testY, predictions)))\n",
    "sklearn.metrics.confusion_matrix(testY, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning our models had a minor impact on our classification performance, bringing us to an acceptible ~77%. \n",
    "\n",
    "To improve our accuracy, we can refine the models on our airline data. The early stopping procedure (enabled by default to use 20% of the training data for validation) should minimize overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4616 samples, validate on 1154 samples\n",
      "Epoch 1/500\n",
      "4616/4616 [==============================] - 2s 528us/step - loss: 0.4158 - acc: 0.8217 - val_loss: 0.3132 - val_acc: 0.8648\n",
      "Epoch 2/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.3568 - acc: 0.8546 - val_loss: 0.2758 - val_acc: 0.8873\n",
      "Epoch 3/500\n",
      "4616/4616 [==============================] - 2s 377us/step - loss: 0.3079 - acc: 0.8795 - val_loss: 0.2531 - val_acc: 0.8986\n",
      "Epoch 4/500\n",
      "4616/4616 [==============================] - 2s 365us/step - loss: 0.2955 - acc: 0.8871 - val_loss: 0.2548 - val_acc: 0.8995\n",
      "Epoch 5/500\n",
      "4616/4616 [==============================] - 2s 382us/step - loss: 0.2895 - acc: 0.8954 - val_loss: 0.2557 - val_acc: 0.8995\n",
      "Epoch 6/500\n",
      "4616/4616 [==============================] - 2s 349us/step - loss: 0.2989 - acc: 0.8941 - val_loss: 0.2595 - val_acc: 0.9012\n",
      "Epoch 7/500\n",
      "4616/4616 [==============================] - 2s 350us/step - loss: 0.3065 - acc: 0.9019 - val_loss: 0.2640 - val_acc: 0.8934\n",
      "Epoch 8/500\n",
      "4616/4616 [==============================] - 2s 352us/step - loss: 0.3042 - acc: 0.8945 - val_loss: 0.2719 - val_acc: 0.8943\n",
      "Epoch 9/500\n",
      "4616/4616 [==============================] - 2s 340us/step - loss: 0.3033 - acc: 0.8977 - val_loss: 0.2684 - val_acc: 0.8934\n",
      "Epoch 10/500\n",
      "4616/4616 [==============================] - 2s 343us/step - loss: 0.3001 - acc: 0.8973 - val_loss: 0.2538 - val_acc: 0.8977\n",
      "Epoch 11/500\n",
      "4616/4616 [==============================] - 2s 353us/step - loss: 0.2904 - acc: 0.8997 - val_loss: 0.2474 - val_acc: 0.9012\n",
      "Epoch 12/500\n",
      "4616/4616 [==============================] - 2s 362us/step - loss: 0.2827 - acc: 0.9023 - val_loss: 0.2420 - val_acc: 0.9047\n",
      "Epoch 13/500\n",
      "4616/4616 [==============================] - 2s 355us/step - loss: 0.2661 - acc: 0.9055 - val_loss: 0.2304 - val_acc: 0.9047\n",
      "Epoch 14/500\n",
      "4616/4616 [==============================] - 2s 366us/step - loss: 0.2600 - acc: 0.9055 - val_loss: 0.2258 - val_acc: 0.9116\n",
      "Epoch 15/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.2551 - acc: 0.9071 - val_loss: 0.2230 - val_acc: 0.9125\n",
      "Epoch 16/500\n",
      "4616/4616 [==============================] - 2s 364us/step - loss: 0.2616 - acc: 0.9040 - val_loss: 0.2209 - val_acc: 0.9142\n",
      "Epoch 17/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.2555 - acc: 0.9060 - val_loss: 0.2187 - val_acc: 0.9159\n",
      "Epoch 18/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.2465 - acc: 0.9088 - val_loss: 0.2162 - val_acc: 0.9177\n",
      "Epoch 19/500\n",
      "4616/4616 [==============================] - 2s 364us/step - loss: 0.2517 - acc: 0.9105 - val_loss: 0.2135 - val_acc: 0.9142\n",
      "Epoch 20/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.2376 - acc: 0.9125 - val_loss: 0.2114 - val_acc: 0.9151\n",
      "Epoch 21/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.2359 - acc: 0.9103 - val_loss: 0.2092 - val_acc: 0.9151\n",
      "Epoch 22/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.2348 - acc: 0.9144 - val_loss: 0.2079 - val_acc: 0.9151\n",
      "Epoch 23/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.2319 - acc: 0.9123 - val_loss: 0.2140 - val_acc: 0.9151\n",
      "Epoch 24/500\n",
      "4616/4616 [==============================] - 2s 361us/step - loss: 0.2394 - acc: 0.9125 - val_loss: 0.2202 - val_acc: 0.9151\n",
      "Epoch 25/500\n",
      "4616/4616 [==============================] - 2s 359us/step - loss: 0.2374 - acc: 0.9066 - val_loss: 0.2265 - val_acc: 0.9159\n",
      "Epoch 26/500\n",
      "4616/4616 [==============================] - 2s 361us/step - loss: 0.2403 - acc: 0.9099 - val_loss: 0.2248 - val_acc: 0.9159\n",
      "Epoch 27/500\n",
      "4616/4616 [==============================] - 2s 351us/step - loss: 0.2479 - acc: 0.9136 - val_loss: 0.2165 - val_acc: 0.9168\n",
      "Epoch 28/500\n",
      "4616/4616 [==============================] - 2s 355us/step - loss: 0.2334 - acc: 0.9164 - val_loss: 0.2071 - val_acc: 0.9177\n",
      "Epoch 29/500\n",
      "4616/4616 [==============================] - 2s 374us/step - loss: 0.2348 - acc: 0.9114 - val_loss: 0.2074 - val_acc: 0.9159\n",
      "Epoch 30/500\n",
      "4616/4616 [==============================] - 2s 351us/step - loss: 0.2383 - acc: 0.9116 - val_loss: 0.2085 - val_acc: 0.9185\n",
      "Epoch 31/500\n",
      "4616/4616 [==============================] - 2s 353us/step - loss: 0.2303 - acc: 0.9103 - val_loss: 0.2099 - val_acc: 0.9185\n",
      "Epoch 32/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.2333 - acc: 0.9162 - val_loss: 0.2109 - val_acc: 0.9177\n",
      "Epoch 33/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.2310 - acc: 0.9151 - val_loss: 0.2114 - val_acc: 0.9185\n",
      "Epoch 34/500\n",
      "4616/4616 [==============================] - 2s 365us/step - loss: 0.2294 - acc: 0.9123 - val_loss: 0.2113 - val_acc: 0.9185\n",
      "Epoch 35/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.2278 - acc: 0.9168 - val_loss: 0.2108 - val_acc: 0.9185\n",
      "Epoch 36/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.2293 - acc: 0.9125 - val_loss: 0.2100 - val_acc: 0.9194\n",
      "Epoch 37/500\n",
      "4616/4616 [==============================] - 2s 372us/step - loss: 0.2316 - acc: 0.9155 - val_loss: 0.2091 - val_acc: 0.9194\n",
      "Epoch 38/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.2238 - acc: 0.9138 - val_loss: 0.1996 - val_acc: 0.9177\n",
      "Epoch 39/500\n",
      "4616/4616 [==============================] - 2s 362us/step - loss: 0.2154 - acc: 0.9166 - val_loss: 0.1981 - val_acc: 0.9203\n",
      "Epoch 40/500\n",
      "4616/4616 [==============================] - 2s 363us/step - loss: 0.2197 - acc: 0.9136 - val_loss: 0.1970 - val_acc: 0.9194\n",
      "Epoch 41/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.2145 - acc: 0.9157 - val_loss: 0.1964 - val_acc: 0.9211\n",
      "Epoch 42/500\n",
      "4616/4616 [==============================] - 2s 355us/step - loss: 0.2119 - acc: 0.9172 - val_loss: 0.1963 - val_acc: 0.9194\n",
      "Epoch 43/500\n",
      "4616/4616 [==============================] - 2s 356us/step - loss: 0.2300 - acc: 0.9127 - val_loss: 0.1969 - val_acc: 0.9203\n",
      "Epoch 44/500\n",
      "4616/4616 [==============================] - 2s 372us/step - loss: 0.2213 - acc: 0.9120 - val_loss: 0.2008 - val_acc: 0.9203\n",
      "Epoch 45/500\n",
      "4616/4616 [==============================] - 2s 362us/step - loss: 0.2149 - acc: 0.9164 - val_loss: 0.2070 - val_acc: 0.9203\n",
      "Epoch 46/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.2219 - acc: 0.9142 - val_loss: 0.2065 - val_acc: 0.9203\n",
      "Epoch 47/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.2225 - acc: 0.9153 - val_loss: 0.2059 - val_acc: 0.9203\n",
      "Epoch 48/500\n",
      "4616/4616 [==============================] - 2s 361us/step - loss: 0.2248 - acc: 0.9172 - val_loss: 0.2052 - val_acc: 0.9203\n",
      "Epoch 49/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.2189 - acc: 0.9138 - val_loss: 0.2042 - val_acc: 0.9203\n",
      "Epoch 50/500\n",
      "4616/4616 [==============================] - 2s 356us/step - loss: 0.2159 - acc: 0.9175 - val_loss: 0.1948 - val_acc: 0.9194\n",
      "Epoch 51/500\n",
      "4616/4616 [==============================] - 2s 352us/step - loss: 0.2105 - acc: 0.9183 - val_loss: 0.1932 - val_acc: 0.9203\n",
      "Epoch 52/500\n",
      "4616/4616 [==============================] - 2s 355us/step - loss: 0.2074 - acc: 0.9198 - val_loss: 0.1924 - val_acc: 0.9220\n",
      "Epoch 53/500\n",
      "4616/4616 [==============================] - 2s 369us/step - loss: 0.2170 - acc: 0.9153 - val_loss: 0.1920 - val_acc: 0.9229\n",
      "Epoch 54/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.2086 - acc: 0.9207 - val_loss: 0.1925 - val_acc: 0.9229\n",
      "Epoch 55/500\n",
      "4616/4616 [==============================] - 2s 355us/step - loss: 0.2152 - acc: 0.9162 - val_loss: 0.1988 - val_acc: 0.9211\n",
      "Epoch 56/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.2120 - acc: 0.9188 - val_loss: 0.1980 - val_acc: 0.9211\n",
      "Epoch 57/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.2084 - acc: 0.9192 - val_loss: 0.1972 - val_acc: 0.9220\n",
      "Epoch 58/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.2175 - acc: 0.9181 - val_loss: 0.1964 - val_acc: 0.9220\n",
      "Epoch 59/500\n",
      "4616/4616 [==============================] - 2s 356us/step - loss: 0.2078 - acc: 0.9192 - val_loss: 0.1958 - val_acc: 0.9220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.2076 - acc: 0.9218 - val_loss: 0.1958 - val_acc: 0.9229\n",
      "Epoch 61/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.2102 - acc: 0.9188 - val_loss: 0.2030 - val_acc: 0.9229\n",
      "Epoch 62/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.2198 - acc: 0.9153 - val_loss: 0.2032 - val_acc: 0.9220\n",
      "Epoch 63/500\n",
      "4616/4616 [==============================] - 2s 355us/step - loss: 0.2046 - acc: 0.9190 - val_loss: 0.2094 - val_acc: 0.9220\n",
      "Epoch 64/500\n",
      "4616/4616 [==============================] - 2s 351us/step - loss: 0.2061 - acc: 0.9203 - val_loss: 0.2084 - val_acc: 0.9229\n",
      "Epoch 65/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.2066 - acc: 0.9205 - val_loss: 0.2078 - val_acc: 0.9229\n",
      "Epoch 66/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.2040 - acc: 0.9175 - val_loss: 0.2072 - val_acc: 0.9229\n",
      "Epoch 67/500\n",
      "4616/4616 [==============================] - 2s 355us/step - loss: 0.2031 - acc: 0.9211 - val_loss: 0.2067 - val_acc: 0.9246\n",
      "Epoch 68/500\n",
      "4616/4616 [==============================] - 2s 347us/step - loss: 0.2046 - acc: 0.9220 - val_loss: 0.2062 - val_acc: 0.9246\n",
      "Epoch 69/500\n",
      "4616/4616 [==============================] - 2s 359us/step - loss: 0.2062 - acc: 0.9194 - val_loss: 0.2056 - val_acc: 0.9263\n",
      "Epoch 70/500\n",
      "4616/4616 [==============================] - 2s 355us/step - loss: 0.2064 - acc: 0.9233 - val_loss: 0.2052 - val_acc: 0.9255\n",
      "Epoch 71/500\n",
      "4616/4616 [==============================] - 2s 359us/step - loss: 0.2052 - acc: 0.9201 - val_loss: 0.2048 - val_acc: 0.9237\n",
      "Epoch 72/500\n",
      "4616/4616 [==============================] - 2s 345us/step - loss: 0.2060 - acc: 0.9203 - val_loss: 0.2063 - val_acc: 0.9246\n",
      "Epoch 73/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.1960 - acc: 0.9211 - val_loss: 0.2078 - val_acc: 0.9237\n",
      "Epoch 74/500\n",
      "4616/4616 [==============================] - 2s 362us/step - loss: 0.2038 - acc: 0.9224 - val_loss: 0.2092 - val_acc: 0.9246\n",
      "Epoch 75/500\n",
      "4616/4616 [==============================] - 2s 346us/step - loss: 0.2018 - acc: 0.9246 - val_loss: 0.2024 - val_acc: 0.9237\n",
      "Epoch 76/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.2005 - acc: 0.9183 - val_loss: 0.1948 - val_acc: 0.9229\n",
      "Epoch 77/500\n",
      "4616/4616 [==============================] - 2s 356us/step - loss: 0.2015 - acc: 0.9207 - val_loss: 0.1955 - val_acc: 0.9229\n",
      "Epoch 78/500\n",
      "4616/4616 [==============================] - 2s 356us/step - loss: 0.1995 - acc: 0.9229 - val_loss: 0.1964 - val_acc: 0.9237\n",
      "Epoch 79/500\n",
      "4616/4616 [==============================] - 2s 376us/step - loss: 0.2024 - acc: 0.9172 - val_loss: 0.1972 - val_acc: 0.9220\n",
      "Epoch 80/500\n",
      "4616/4616 [==============================] - 2s 369us/step - loss: 0.2033 - acc: 0.9198 - val_loss: 0.1906 - val_acc: 0.9211\n",
      "Epoch 81/500\n",
      "4616/4616 [==============================] - 2s 369us/step - loss: 0.2074 - acc: 0.9201 - val_loss: 0.1908 - val_acc: 0.9211\n",
      "Epoch 82/500\n",
      "4616/4616 [==============================] - 2s 356us/step - loss: 0.2070 - acc: 0.9248 - val_loss: 0.1919 - val_acc: 0.9203\n",
      "Epoch 83/500\n",
      "4616/4616 [==============================] - 2s 336us/step - loss: 0.2026 - acc: 0.9198 - val_loss: 0.1981 - val_acc: 0.9194\n",
      "Epoch 84/500\n",
      "4616/4616 [==============================] - 2s 369us/step - loss: 0.2055 - acc: 0.9242 - val_loss: 0.1977 - val_acc: 0.9203\n",
      "Epoch 85/500\n",
      "4616/4616 [==============================] - 2s 368us/step - loss: 0.2029 - acc: 0.9196 - val_loss: 0.1973 - val_acc: 0.9194\n",
      "Epoch 86/500\n",
      "4616/4616 [==============================] - 2s 363us/step - loss: 0.2032 - acc: 0.9246 - val_loss: 0.1967 - val_acc: 0.9203\n",
      "Epoch 87/500\n",
      "4616/4616 [==============================] - 2s 393us/step - loss: 0.2050 - acc: 0.9240 - val_loss: 0.1962 - val_acc: 0.9203\n",
      "Epoch 88/500\n",
      "4616/4616 [==============================] - 2s 365us/step - loss: 0.2016 - acc: 0.9183 - val_loss: 0.1956 - val_acc: 0.9203\n",
      "Epoch 89/500\n",
      "4616/4616 [==============================] - 2s 364us/step - loss: 0.2094 - acc: 0.9218 - val_loss: 0.1951 - val_acc: 0.9203\n",
      "Epoch 90/500\n",
      "4616/4616 [==============================] - 2s 370us/step - loss: 0.2046 - acc: 0.9205 - val_loss: 0.1948 - val_acc: 0.9203\n",
      "Epoch 91/500\n",
      "4616/4616 [==============================] - 2s 385us/step - loss: 0.2049 - acc: 0.9207 - val_loss: 0.1949 - val_acc: 0.9220\n",
      "Epoch 92/500\n",
      "4616/4616 [==============================] - 2s 400us/step - loss: 0.2086 - acc: 0.9214 - val_loss: 0.2020 - val_acc: 0.9220\n",
      "Epoch 93/500\n",
      "4616/4616 [==============================] - 2s 377us/step - loss: 0.1959 - acc: 0.9207 - val_loss: 0.2014 - val_acc: 0.9229\n",
      "Epoch 94/500\n",
      "4616/4616 [==============================] - 2s 392us/step - loss: 0.1988 - acc: 0.9233 - val_loss: 0.2031 - val_acc: 0.9246\n",
      "Epoch 95/500\n",
      "4616/4616 [==============================] - 2s 370us/step - loss: 0.2085 - acc: 0.9231 - val_loss: 0.2069 - val_acc: 0.9255\n",
      "Epoch 96/500\n",
      "4616/4616 [==============================] - 2s 364us/step - loss: 0.1978 - acc: 0.9257 - val_loss: 0.2059 - val_acc: 0.9263\n",
      "Epoch 97/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.1942 - acc: 0.9220 - val_loss: 0.2048 - val_acc: 0.9255\n",
      "Epoch 98/500\n",
      "4616/4616 [==============================] - 2s 363us/step - loss: 0.2020 - acc: 0.9231 - val_loss: 0.2037 - val_acc: 0.9255\n",
      "Epoch 99/500\n",
      "4616/4616 [==============================] - 2s 359us/step - loss: 0.2042 - acc: 0.9227 - val_loss: 0.2027 - val_acc: 0.9246\n",
      "Epoch 100/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.1958 - acc: 0.9205 - val_loss: 0.2019 - val_acc: 0.9246\n",
      "Epoch 101/500\n",
      "4616/4616 [==============================] - 2s 353us/step - loss: 0.1938 - acc: 0.9248 - val_loss: 0.2012 - val_acc: 0.9246\n",
      "Epoch 102/500\n",
      "4616/4616 [==============================] - 2s 361us/step - loss: 0.1955 - acc: 0.9220 - val_loss: 0.2007 - val_acc: 0.9246\n",
      "Epoch 103/500\n",
      "4616/4616 [==============================] - 2s 344us/step - loss: 0.1872 - acc: 0.9227 - val_loss: 0.2001 - val_acc: 0.9255\n",
      "Epoch 104/500\n",
      "4616/4616 [==============================] - 2s 351us/step - loss: 0.1916 - acc: 0.9248 - val_loss: 0.1996 - val_acc: 0.9263\n",
      "Epoch 105/500\n",
      "4616/4616 [==============================] - 2s 370us/step - loss: 0.1952 - acc: 0.9229 - val_loss: 0.1990 - val_acc: 0.9255\n",
      "Epoch 106/500\n",
      "4616/4616 [==============================] - 2s 369us/step - loss: 0.1959 - acc: 0.9201 - val_loss: 0.1985 - val_acc: 0.9263\n",
      "Epoch 107/500\n",
      "4616/4616 [==============================] - 2s 371us/step - loss: 0.1973 - acc: 0.9240 - val_loss: 0.1980 - val_acc: 0.9255\n",
      "Epoch 108/500\n",
      "4616/4616 [==============================] - 2s 372us/step - loss: 0.2039 - acc: 0.9231 - val_loss: 0.1978 - val_acc: 0.9272\n",
      "Epoch 109/500\n",
      "4616/4616 [==============================] - 2s 386us/step - loss: 0.1954 - acc: 0.9164 - val_loss: 0.1975 - val_acc: 0.9272\n",
      "Epoch 110/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.1904 - acc: 0.9240 - val_loss: 0.1976 - val_acc: 0.9281\n",
      "Epoch 111/500\n",
      "4616/4616 [==============================] - 2s 370us/step - loss: 0.1903 - acc: 0.9240 - val_loss: 0.1973 - val_acc: 0.9281\n",
      "Epoch 112/500\n",
      "4616/4616 [==============================] - 2s 385us/step - loss: 0.1944 - acc: 0.9220 - val_loss: 0.1965 - val_acc: 0.9281\n",
      "Epoch 113/500\n",
      "4616/4616 [==============================] - 2s 369us/step - loss: 0.1986 - acc: 0.9216 - val_loss: 0.1960 - val_acc: 0.9281\n",
      "Epoch 114/500\n",
      "4616/4616 [==============================] - 2s 371us/step - loss: 0.1913 - acc: 0.9233 - val_loss: 0.1957 - val_acc: 0.9281\n",
      "Epoch 115/500\n",
      "4616/4616 [==============================] - 2s 370us/step - loss: 0.1901 - acc: 0.9281 - val_loss: 0.1956 - val_acc: 0.9281\n",
      "Epoch 116/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.1864 - acc: 0.9253 - val_loss: 0.1955 - val_acc: 0.9298\n",
      "Epoch 117/500\n",
      "4616/4616 [==============================] - 2s 369us/step - loss: 0.1905 - acc: 0.9250 - val_loss: 0.1955 - val_acc: 0.9289\n",
      "Epoch 118/500\n",
      "4616/4616 [==============================] - 2s 369us/step - loss: 0.1931 - acc: 0.9203 - val_loss: 0.1956 - val_acc: 0.9289\n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4616/4616 [==============================] - 2s 381us/step - loss: 0.1867 - acc: 0.9276 - val_loss: 0.1958 - val_acc: 0.9298\n",
      "Epoch 120/500\n",
      "4616/4616 [==============================] - 2s 375us/step - loss: 0.1925 - acc: 0.9218 - val_loss: 0.1959 - val_acc: 0.9281\n",
      "Epoch 121/500\n",
      "4616/4616 [==============================] - 2s 380us/step - loss: 0.1919 - acc: 0.9274 - val_loss: 0.1962 - val_acc: 0.9281\n",
      "Epoch 122/500\n",
      "4616/4616 [==============================] - 2s 379us/step - loss: 0.1924 - acc: 0.9244 - val_loss: 0.1966 - val_acc: 0.9272\n",
      "Epoch 123/500\n",
      "4616/4616 [==============================] - 2s 389us/step - loss: 0.1902 - acc: 0.9261 - val_loss: 0.1929 - val_acc: 0.9272\n",
      "Epoch 124/500\n",
      "4616/4616 [==============================] - 2s 376us/step - loss: 0.1891 - acc: 0.9276 - val_loss: 0.1906 - val_acc: 0.9255\n",
      "Epoch 125/500\n",
      "4616/4616 [==============================] - 2s 372us/step - loss: 0.1884 - acc: 0.9253 - val_loss: 0.1905 - val_acc: 0.9255\n",
      "Epoch 126/500\n",
      "4616/4616 [==============================] - 2s 377us/step - loss: 0.1877 - acc: 0.9281 - val_loss: 0.1907 - val_acc: 0.9255\n",
      "Epoch 127/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.1840 - acc: 0.9261 - val_loss: 0.1910 - val_acc: 0.9255\n",
      "Epoch 128/500\n",
      "4616/4616 [==============================] - 2s 363us/step - loss: 0.1881 - acc: 0.9266 - val_loss: 0.1915 - val_acc: 0.9263\n",
      "Epoch 129/500\n",
      "4616/4616 [==============================] - 2s 366us/step - loss: 0.1846 - acc: 0.9276 - val_loss: 0.1925 - val_acc: 0.9255\n",
      "Epoch 130/500\n",
      "4616/4616 [==============================] - 2s 377us/step - loss: 0.1871 - acc: 0.9227 - val_loss: 0.1987 - val_acc: 0.9255\n",
      "Epoch 131/500\n",
      "4616/4616 [==============================] - 2s 371us/step - loss: 0.1843 - acc: 0.9233 - val_loss: 0.1988 - val_acc: 0.9255\n",
      "Epoch 132/500\n",
      "4616/4616 [==============================] - 2s 370us/step - loss: 0.1872 - acc: 0.9279 - val_loss: 0.1987 - val_acc: 0.9255\n",
      "Epoch 133/500\n",
      "4616/4616 [==============================] - 2s 372us/step - loss: 0.1846 - acc: 0.9272 - val_loss: 0.1985 - val_acc: 0.9255\n",
      "Epoch 134/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.1860 - acc: 0.9285 - val_loss: 0.1982 - val_acc: 0.9255\n",
      "Epoch 135/500\n",
      "4616/4616 [==============================] - 2s 370us/step - loss: 0.1778 - acc: 0.9274 - val_loss: 0.1978 - val_acc: 0.9263\n",
      "Epoch 136/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.1827 - acc: 0.9259 - val_loss: 0.1973 - val_acc: 0.9272\n",
      "Epoch 137/500\n",
      "4616/4616 [==============================] - 2s 365us/step - loss: 0.1910 - acc: 0.9244 - val_loss: 0.1969 - val_acc: 0.9289\n",
      "Epoch 138/500\n",
      "4616/4616 [==============================] - 2s 364us/step - loss: 0.1789 - acc: 0.9294 - val_loss: 0.1964 - val_acc: 0.9289\n",
      "Epoch 139/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.1798 - acc: 0.9272 - val_loss: 0.1960 - val_acc: 0.9289\n",
      "Epoch 140/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.1863 - acc: 0.9276 - val_loss: 0.1958 - val_acc: 0.9298\n",
      "Epoch 141/500\n",
      "4616/4616 [==============================] - 2s 364us/step - loss: 0.1764 - acc: 0.9289 - val_loss: 0.1955 - val_acc: 0.9307\n",
      "Epoch 142/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1829 - acc: 0.9209 - val_loss: 0.1954 - val_acc: 0.9307\n",
      "Epoch 143/500\n",
      "4616/4616 [==============================] - 2s 364us/step - loss: 0.1909 - acc: 0.9261 - val_loss: 0.1949 - val_acc: 0.9307\n",
      "Epoch 144/500\n",
      "4616/4616 [==============================] - 2s 368us/step - loss: 0.1856 - acc: 0.9259 - val_loss: 0.1943 - val_acc: 0.9298\n",
      "Epoch 145/500\n",
      "4616/4616 [==============================] - 2s 366us/step - loss: 0.1774 - acc: 0.9253 - val_loss: 0.1938 - val_acc: 0.9298\n",
      "Epoch 146/500\n",
      "4616/4616 [==============================] - 2s 382us/step - loss: 0.1829 - acc: 0.9266 - val_loss: 0.1932 - val_acc: 0.9298\n",
      "Epoch 147/500\n",
      "4616/4616 [==============================] - 2s 386us/step - loss: 0.1795 - acc: 0.9259 - val_loss: 0.1927 - val_acc: 0.9298\n",
      "Epoch 148/500\n",
      "4616/4616 [==============================] - 2s 384us/step - loss: 0.1778 - acc: 0.9281 - val_loss: 0.1908 - val_acc: 0.9298\n",
      "Epoch 149/500\n",
      "4616/4616 [==============================] - 2s 362us/step - loss: 0.1771 - acc: 0.9298 - val_loss: 0.1899 - val_acc: 0.9307\n",
      "Epoch 150/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.1781 - acc: 0.9315 - val_loss: 0.1896 - val_acc: 0.9324\n",
      "Epoch 151/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.1822 - acc: 0.9272 - val_loss: 0.1895 - val_acc: 0.9307\n",
      "Epoch 152/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1784 - acc: 0.9292 - val_loss: 0.1896 - val_acc: 0.9298\n",
      "Epoch 153/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.1766 - acc: 0.9274 - val_loss: 0.1897 - val_acc: 0.9298\n",
      "Epoch 154/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.1823 - acc: 0.9294 - val_loss: 0.1900 - val_acc: 0.9298\n",
      "Epoch 155/500\n",
      "4616/4616 [==============================] - 2s 383us/step - loss: 0.1810 - acc: 0.9268 - val_loss: 0.1905 - val_acc: 0.9315\n",
      "Epoch 156/500\n",
      "4616/4616 [==============================] - 2s 377us/step - loss: 0.1858 - acc: 0.9279 - val_loss: 0.1912 - val_acc: 0.9298\n",
      "Epoch 157/500\n",
      "4616/4616 [==============================] - 2s 362us/step - loss: 0.1765 - acc: 0.9311 - val_loss: 0.1922 - val_acc: 0.9289\n",
      "Epoch 158/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.1748 - acc: 0.9302 - val_loss: 0.1933 - val_acc: 0.9281\n",
      "Epoch 159/500\n",
      "4616/4616 [==============================] - 2s 361us/step - loss: 0.1714 - acc: 0.9279 - val_loss: 0.1947 - val_acc: 0.9263\n",
      "Epoch 160/500\n",
      "4616/4616 [==============================] - 2s 382us/step - loss: 0.1851 - acc: 0.9289 - val_loss: 0.1960 - val_acc: 0.9263\n",
      "Epoch 161/500\n",
      "4616/4616 [==============================] - 2s 379us/step - loss: 0.1753 - acc: 0.9324 - val_loss: 0.1970 - val_acc: 0.9255\n",
      "Epoch 162/500\n",
      "4616/4616 [==============================] - 2s 375us/step - loss: 0.1747 - acc: 0.9305 - val_loss: 0.1976 - val_acc: 0.9255\n",
      "Epoch 163/500\n",
      "4616/4616 [==============================] - 2s 393us/step - loss: 0.1787 - acc: 0.9315 - val_loss: 0.1982 - val_acc: 0.9272\n",
      "Epoch 164/500\n",
      "4616/4616 [==============================] - 2s 377us/step - loss: 0.1743 - acc: 0.9261 - val_loss: 0.1980 - val_acc: 0.9272\n",
      "Epoch 165/500\n",
      "4616/4616 [==============================] - 2s 362us/step - loss: 0.1713 - acc: 0.9292 - val_loss: 0.1969 - val_acc: 0.9272\n",
      "Epoch 166/500\n",
      "4616/4616 [==============================] - 2s 384us/step - loss: 0.1747 - acc: 0.9289 - val_loss: 0.1951 - val_acc: 0.9272\n",
      "Epoch 167/500\n",
      "4616/4616 [==============================] - 2s 387us/step - loss: 0.1774 - acc: 0.9328 - val_loss: 0.1934 - val_acc: 0.9272\n",
      "Epoch 168/500\n",
      "4616/4616 [==============================] - 2s 368us/step - loss: 0.1722 - acc: 0.9311 - val_loss: 0.1917 - val_acc: 0.9272\n",
      "Epoch 169/500\n",
      "4616/4616 [==============================] - 2s 371us/step - loss: 0.1741 - acc: 0.9315 - val_loss: 0.1904 - val_acc: 0.9289\n",
      "Epoch 170/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.1703 - acc: 0.9331 - val_loss: 0.1894 - val_acc: 0.9298\n",
      "Epoch 171/500\n",
      "4616/4616 [==============================] - 2s 391us/step - loss: 0.1791 - acc: 0.9292 - val_loss: 0.1886 - val_acc: 0.9298\n",
      "Epoch 172/500\n",
      "4616/4616 [==============================] - 2s 397us/step - loss: 0.1732 - acc: 0.9307 - val_loss: 0.1880 - val_acc: 0.9307\n",
      "Epoch 173/500\n",
      "4616/4616 [==============================] - 2s 370us/step - loss: 0.1741 - acc: 0.9311 - val_loss: 0.1876 - val_acc: 0.9315\n",
      "Epoch 174/500\n",
      "4616/4616 [==============================] - 2s 352us/step - loss: 0.1711 - acc: 0.9300 - val_loss: 0.1875 - val_acc: 0.9307\n",
      "Epoch 175/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.1621 - acc: 0.9361 - val_loss: 0.1876 - val_acc: 0.9307\n",
      "Epoch 176/500\n",
      "4616/4616 [==============================] - 2s 353us/step - loss: 0.1668 - acc: 0.9326 - val_loss: 0.1880 - val_acc: 0.9307\n",
      "Epoch 177/500\n",
      "4616/4616 [==============================] - 2s 382us/step - loss: 0.1688 - acc: 0.9266 - val_loss: 0.1890 - val_acc: 0.9298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1684 - acc: 0.9333 - val_loss: 0.1901 - val_acc: 0.9298\n",
      "Epoch 179/500\n",
      "4616/4616 [==============================] - 2s 389us/step - loss: 0.1681 - acc: 0.9287 - val_loss: 0.1917 - val_acc: 0.9281\n",
      "Epoch 180/500\n",
      "4616/4616 [==============================] - 2s 386us/step - loss: 0.1702 - acc: 0.9322 - val_loss: 0.1934 - val_acc: 0.9289\n",
      "Epoch 181/500\n",
      "4616/4616 [==============================] - 2s 391us/step - loss: 0.1670 - acc: 0.9328 - val_loss: 0.1998 - val_acc: 0.9289\n",
      "Epoch 182/500\n",
      "4616/4616 [==============================] - 2s 406us/step - loss: 0.1755 - acc: 0.9298 - val_loss: 0.1916 - val_acc: 0.9298\n",
      "Epoch 183/500\n",
      "4616/4616 [==============================] - 2s 377us/step - loss: 0.1645 - acc: 0.9344 - val_loss: 0.1899 - val_acc: 0.9298\n",
      "Epoch 184/500\n",
      "4616/4616 [==============================] - 2s 351us/step - loss: 0.1625 - acc: 0.9337 - val_loss: 0.1888 - val_acc: 0.9298\n",
      "Epoch 185/500\n",
      "4616/4616 [==============================] - 2s 349us/step - loss: 0.1683 - acc: 0.9331 - val_loss: 0.1880 - val_acc: 0.9289\n",
      "Epoch 186/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.1653 - acc: 0.9357 - val_loss: 0.1874 - val_acc: 0.9298\n",
      "Epoch 187/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.1643 - acc: 0.9318 - val_loss: 0.1870 - val_acc: 0.9307\n",
      "Epoch 188/500\n",
      "4616/4616 [==============================] - 2s 361us/step - loss: 0.1703 - acc: 0.9285 - val_loss: 0.1869 - val_acc: 0.9307\n",
      "Epoch 189/500\n",
      "4616/4616 [==============================] - 2s 361us/step - loss: 0.1662 - acc: 0.9326 - val_loss: 0.1870 - val_acc: 0.9315\n",
      "Epoch 190/500\n",
      "4616/4616 [==============================] - 2s 355us/step - loss: 0.1648 - acc: 0.9331 - val_loss: 0.1873 - val_acc: 0.9315\n",
      "Epoch 191/500\n",
      "4616/4616 [==============================] - 2s 372us/step - loss: 0.1675 - acc: 0.9296 - val_loss: 0.1877 - val_acc: 0.9307\n",
      "Epoch 192/500\n",
      "4616/4616 [==============================] - 2s 342us/step - loss: 0.1631 - acc: 0.9328 - val_loss: 0.1882 - val_acc: 0.9298\n",
      "Epoch 193/500\n",
      "4616/4616 [==============================] - 2s 344us/step - loss: 0.1661 - acc: 0.9315 - val_loss: 0.1887 - val_acc: 0.9307\n",
      "Epoch 194/500\n",
      "4616/4616 [==============================] - 2s 337us/step - loss: 0.1725 - acc: 0.9315 - val_loss: 0.1889 - val_acc: 0.9315\n",
      "Epoch 195/500\n",
      "4616/4616 [==============================] - 2s 340us/step - loss: 0.1648 - acc: 0.9300 - val_loss: 0.1893 - val_acc: 0.9315\n",
      "Epoch 196/500\n",
      "4616/4616 [==============================] - 2s 381us/step - loss: 0.1650 - acc: 0.9296 - val_loss: 0.1895 - val_acc: 0.9315\n",
      "Epoch 197/500\n",
      "4616/4616 [==============================] - 2s 348us/step - loss: 0.1641 - acc: 0.9346 - val_loss: 0.1882 - val_acc: 0.9324\n",
      "Epoch 198/500\n",
      "4616/4616 [==============================] - 2s 346us/step - loss: 0.1685 - acc: 0.9309 - val_loss: 0.1873 - val_acc: 0.9315\n",
      "Epoch 199/500\n",
      "4616/4616 [==============================] - 2s 372us/step - loss: 0.1611 - acc: 0.9331 - val_loss: 0.1865 - val_acc: 0.9307\n",
      "Epoch 200/500\n",
      "4616/4616 [==============================] - 2s 342us/step - loss: 0.1596 - acc: 0.9348 - val_loss: 0.1855 - val_acc: 0.9315\n",
      "Epoch 201/500\n",
      "4616/4616 [==============================] - 2s 348us/step - loss: 0.1665 - acc: 0.9354 - val_loss: 0.1849 - val_acc: 0.9315\n",
      "Epoch 202/500\n",
      "4616/4616 [==============================] - 2s 339us/step - loss: 0.1652 - acc: 0.9315 - val_loss: 0.1842 - val_acc: 0.9324\n",
      "Epoch 203/500\n",
      "4616/4616 [==============================] - 2s 340us/step - loss: 0.1655 - acc: 0.9324 - val_loss: 0.1837 - val_acc: 0.9333\n",
      "Epoch 204/500\n",
      "4616/4616 [==============================] - 2s 365us/step - loss: 0.1570 - acc: 0.9339 - val_loss: 0.1835 - val_acc: 0.9333\n",
      "Epoch 205/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.1621 - acc: 0.9341 - val_loss: 0.1834 - val_acc: 0.9333\n",
      "Epoch 206/500\n",
      "4616/4616 [==============================] - 2s 362us/step - loss: 0.1595 - acc: 0.9350 - val_loss: 0.1834 - val_acc: 0.9333\n",
      "Epoch 207/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.1589 - acc: 0.9328 - val_loss: 0.1838 - val_acc: 0.9333\n",
      "Epoch 208/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1650 - acc: 0.9315 - val_loss: 0.1844 - val_acc: 0.9333\n",
      "Epoch 209/500\n",
      "4616/4616 [==============================] - 2s 372us/step - loss: 0.1612 - acc: 0.9380 - val_loss: 0.1855 - val_acc: 0.9324\n",
      "Epoch 210/500\n",
      "4616/4616 [==============================] - 2s 351us/step - loss: 0.1700 - acc: 0.9370 - val_loss: 0.1873 - val_acc: 0.9315\n",
      "Epoch 211/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.1661 - acc: 0.9359 - val_loss: 0.1844 - val_acc: 0.9333\n",
      "Epoch 212/500\n",
      "4616/4616 [==============================] - 2s 383us/step - loss: 0.1600 - acc: 0.9315 - val_loss: 0.1841 - val_acc: 0.9341\n",
      "Epoch 213/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.1571 - acc: 0.9365 - val_loss: 0.1847 - val_acc: 0.9341\n",
      "Epoch 214/500\n",
      "4616/4616 [==============================] - 2s 384us/step - loss: 0.1607 - acc: 0.9396 - val_loss: 0.1855 - val_acc: 0.9324\n",
      "Epoch 215/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.1690 - acc: 0.9326 - val_loss: 0.1785 - val_acc: 0.9341\n",
      "Epoch 216/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1675 - acc: 0.9346 - val_loss: 0.1789 - val_acc: 0.9324\n",
      "Epoch 217/500\n",
      "4616/4616 [==============================] - 2s 340us/step - loss: 0.1646 - acc: 0.9372 - val_loss: 0.1796 - val_acc: 0.9324\n",
      "Epoch 218/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.1641 - acc: 0.9335 - val_loss: 0.1803 - val_acc: 0.9298\n",
      "Epoch 219/500\n",
      "4616/4616 [==============================] - 2s 389us/step - loss: 0.1712 - acc: 0.9318 - val_loss: 0.1811 - val_acc: 0.9298\n",
      "Epoch 220/500\n",
      "4616/4616 [==============================] - 2s 366us/step - loss: 0.1613 - acc: 0.9352 - val_loss: 0.1819 - val_acc: 0.9307\n",
      "Epoch 221/500\n",
      "4616/4616 [==============================] - 2s 383us/step - loss: 0.1634 - acc: 0.9361 - val_loss: 0.1829 - val_acc: 0.9307\n",
      "Epoch 222/500\n",
      "4616/4616 [==============================] - 2s 387us/step - loss: 0.1670 - acc: 0.9357 - val_loss: 0.1911 - val_acc: 0.9307\n",
      "Epoch 223/500\n",
      "4616/4616 [==============================] - 2s 385us/step - loss: 0.1648 - acc: 0.9339 - val_loss: 0.1911 - val_acc: 0.9315\n",
      "Epoch 224/500\n",
      "4616/4616 [==============================] - 2s 363us/step - loss: 0.1636 - acc: 0.9354 - val_loss: 0.1912 - val_acc: 0.9307\n",
      "Epoch 225/500\n",
      "4616/4616 [==============================] - 2s 361us/step - loss: 0.1661 - acc: 0.9324 - val_loss: 0.1912 - val_acc: 0.9298\n",
      "Epoch 226/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.1589 - acc: 0.9341 - val_loss: 0.1917 - val_acc: 0.9298\n",
      "Epoch 227/500\n",
      "4616/4616 [==============================] - 2s 359us/step - loss: 0.1650 - acc: 0.9344 - val_loss: 0.1917 - val_acc: 0.9289\n",
      "Epoch 228/500\n",
      "4616/4616 [==============================] - 2s 414us/step - loss: 0.1716 - acc: 0.9296 - val_loss: 0.1915 - val_acc: 0.9289\n",
      "Epoch 229/500\n",
      "4616/4616 [==============================] - 2s 369us/step - loss: 0.1635 - acc: 0.9331 - val_loss: 0.1900 - val_acc: 0.9307\n",
      "Epoch 230/500\n",
      "4616/4616 [==============================] - 2s 384us/step - loss: 0.1615 - acc: 0.9354 - val_loss: 0.1876 - val_acc: 0.9289\n",
      "Epoch 231/500\n",
      "4616/4616 [==============================] - 2s 390us/step - loss: 0.1587 - acc: 0.9372 - val_loss: 0.1854 - val_acc: 0.9298\n",
      "Epoch 232/500\n",
      "4616/4616 [==============================] - 2s 362us/step - loss: 0.1607 - acc: 0.9331 - val_loss: 0.1834 - val_acc: 0.9315\n",
      "Epoch 233/500\n",
      "4616/4616 [==============================] - 2s 348us/step - loss: 0.1580 - acc: 0.9363 - val_loss: 0.1819 - val_acc: 0.9341\n",
      "Epoch 234/500\n",
      "4616/4616 [==============================] - 2s 356us/step - loss: 0.1621 - acc: 0.9346 - val_loss: 0.1809 - val_acc: 0.9341\n",
      "Epoch 235/500\n",
      "4616/4616 [==============================] - 2s 351us/step - loss: 0.1718 - acc: 0.9322 - val_loss: 0.1807 - val_acc: 0.9333\n",
      "Epoch 236/500\n",
      "4616/4616 [==============================] - 2s 341us/step - loss: 0.1666 - acc: 0.9346 - val_loss: 0.1807 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/500\n",
      "4616/4616 [==============================] - 2s 345us/step - loss: 0.1646 - acc: 0.9346 - val_loss: 0.1804 - val_acc: 0.9333\n",
      "Epoch 238/500\n",
      "4616/4616 [==============================] - 2s 344us/step - loss: 0.1682 - acc: 0.9367 - val_loss: 0.1805 - val_acc: 0.9324\n",
      "Epoch 239/500\n",
      "4616/4616 [==============================] - 2s 346us/step - loss: 0.1627 - acc: 0.9335 - val_loss: 0.1812 - val_acc: 0.9315\n",
      "Epoch 240/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.1576 - acc: 0.9370 - val_loss: 0.1821 - val_acc: 0.9315\n",
      "Epoch 241/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.1566 - acc: 0.9374 - val_loss: 0.1803 - val_acc: 0.9333\n",
      "Epoch 242/500\n",
      "4616/4616 [==============================] - 2s 383us/step - loss: 0.1584 - acc: 0.9402 - val_loss: 0.1805 - val_acc: 0.9350\n",
      "Epoch 243/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.1617 - acc: 0.9387 - val_loss: 0.1815 - val_acc: 0.9359\n",
      "Epoch 244/500\n",
      "4616/4616 [==============================] - 2s 359us/step - loss: 0.1525 - acc: 0.9370 - val_loss: 0.1616 - val_acc: 0.9350\n",
      "Epoch 245/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.1651 - acc: 0.9367 - val_loss: 0.1596 - val_acc: 0.9359\n",
      "Epoch 246/500\n",
      "4616/4616 [==============================] - 2s 356us/step - loss: 0.1642 - acc: 0.9376 - val_loss: 0.1621 - val_acc: 0.9341\n",
      "Epoch 247/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.1596 - acc: 0.9367 - val_loss: 0.1762 - val_acc: 0.9333\n",
      "Epoch 248/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.1631 - acc: 0.9370 - val_loss: 0.1768 - val_acc: 0.9324\n",
      "Epoch 249/500\n",
      "4616/4616 [==============================] - 2s 359us/step - loss: 0.1605 - acc: 0.9380 - val_loss: 0.1779 - val_acc: 0.9324\n",
      "Epoch 250/500\n",
      "4616/4616 [==============================] - 2s 355us/step - loss: 0.1651 - acc: 0.9370 - val_loss: 0.1798 - val_acc: 0.9298\n",
      "Epoch 251/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.1559 - acc: 0.9372 - val_loss: 0.1837 - val_acc: 0.9272\n",
      "Epoch 252/500\n",
      "4616/4616 [==============================] - 2s 362us/step - loss: 0.1537 - acc: 0.9370 - val_loss: 0.1937 - val_acc: 0.9263\n",
      "Epoch 253/500\n",
      "4616/4616 [==============================] - 2s 351us/step - loss: 0.1610 - acc: 0.9404 - val_loss: 0.2038 - val_acc: 0.9246\n",
      "Epoch 254/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1540 - acc: 0.9385 - val_loss: 0.2051 - val_acc: 0.9220\n",
      "Epoch 255/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1604 - acc: 0.9341 - val_loss: 0.2058 - val_acc: 0.9246\n",
      "Epoch 256/500\n",
      "4616/4616 [==============================] - 2s 369us/step - loss: 0.1517 - acc: 0.9385 - val_loss: 0.2060 - val_acc: 0.9272\n",
      "Epoch 257/500\n",
      "4616/4616 [==============================] - 2s 370us/step - loss: 0.1588 - acc: 0.9346 - val_loss: 0.2130 - val_acc: 0.9263\n",
      "Epoch 258/500\n",
      "4616/4616 [==============================] - 2s 370us/step - loss: 0.1603 - acc: 0.9383 - val_loss: 0.2096 - val_acc: 0.9289\n",
      "Epoch 259/500\n",
      "4616/4616 [==============================] - 2s 355us/step - loss: 0.1573 - acc: 0.9337 - val_loss: 0.1975 - val_acc: 0.9307\n",
      "Epoch 260/500\n",
      "4616/4616 [==============================] - 2s 371us/step - loss: 0.1532 - acc: 0.9354 - val_loss: 0.1862 - val_acc: 0.9307\n",
      "Epoch 261/500\n",
      "4616/4616 [==============================] - 2s 368us/step - loss: 0.1527 - acc: 0.9385 - val_loss: 0.1822 - val_acc: 0.9341\n",
      "Epoch 262/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.1467 - acc: 0.9398 - val_loss: 0.1804 - val_acc: 0.9367\n",
      "Epoch 263/500\n",
      "4616/4616 [==============================] - 2s 351us/step - loss: 0.1581 - acc: 0.9400 - val_loss: 0.1792 - val_acc: 0.9376\n",
      "Epoch 264/500\n",
      "4616/4616 [==============================] - 2s 356us/step - loss: 0.1598 - acc: 0.9370 - val_loss: 0.1787 - val_acc: 0.9385\n",
      "Epoch 265/500\n",
      "4616/4616 [==============================] - 2s 364us/step - loss: 0.1565 - acc: 0.9419 - val_loss: 0.1787 - val_acc: 0.9385\n",
      "Epoch 266/500\n",
      "4616/4616 [==============================] - 2s 385us/step - loss: 0.1551 - acc: 0.9387 - val_loss: 0.1791 - val_acc: 0.9385\n",
      "Epoch 267/500\n",
      "4616/4616 [==============================] - 2s 371us/step - loss: 0.1535 - acc: 0.9372 - val_loss: 0.1798 - val_acc: 0.9376\n",
      "Epoch 268/500\n",
      "4616/4616 [==============================] - 2s 369us/step - loss: 0.1561 - acc: 0.9378 - val_loss: 0.1808 - val_acc: 0.9350\n",
      "Epoch 269/500\n",
      "4616/4616 [==============================] - 2s 365us/step - loss: 0.1513 - acc: 0.9383 - val_loss: 0.1820 - val_acc: 0.9341\n",
      "Epoch 270/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1495 - acc: 0.9378 - val_loss: 0.1840 - val_acc: 0.9307\n",
      "Epoch 271/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1523 - acc: 0.9385 - val_loss: 0.1944 - val_acc: 0.9298\n",
      "Epoch 272/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1552 - acc: 0.9328 - val_loss: 0.1959 - val_acc: 0.9307\n",
      "Epoch 273/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1477 - acc: 0.9372 - val_loss: 0.1971 - val_acc: 0.9298\n",
      "Epoch 274/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1557 - acc: 0.9365 - val_loss: 0.1981 - val_acc: 0.9298\n",
      "Epoch 275/500\n",
      "4616/4616 [==============================] - 2s 355us/step - loss: 0.1560 - acc: 0.9404 - val_loss: 0.1983 - val_acc: 0.9307\n",
      "Epoch 276/500\n",
      "4616/4616 [==============================] - 2s 362us/step - loss: 0.1486 - acc: 0.9383 - val_loss: 0.1981 - val_acc: 0.9307\n",
      "Epoch 277/500\n",
      "4616/4616 [==============================] - 2s 356us/step - loss: 0.1413 - acc: 0.9435 - val_loss: 0.1977 - val_acc: 0.9307\n",
      "Epoch 278/500\n",
      "4616/4616 [==============================] - 2s 361us/step - loss: 0.1514 - acc: 0.9391 - val_loss: 0.1967 - val_acc: 0.9315\n",
      "Epoch 279/500\n",
      "4616/4616 [==============================] - 2s 364us/step - loss: 0.1472 - acc: 0.9404 - val_loss: 0.1955 - val_acc: 0.9324\n",
      "Epoch 280/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1528 - acc: 0.9389 - val_loss: 0.1944 - val_acc: 0.9333\n",
      "Epoch 281/500\n",
      "4616/4616 [==============================] - 2s 359us/step - loss: 0.1457 - acc: 0.9443 - val_loss: 0.1924 - val_acc: 0.9324\n",
      "Epoch 282/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.1520 - acc: 0.9402 - val_loss: 0.1835 - val_acc: 0.9341\n",
      "Epoch 283/500\n",
      "4616/4616 [==============================] - 2s 359us/step - loss: 0.1465 - acc: 0.9393 - val_loss: 0.1813 - val_acc: 0.9359\n",
      "Epoch 284/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1445 - acc: 0.9385 - val_loss: 0.1802 - val_acc: 0.9367\n",
      "Epoch 285/500\n",
      "4616/4616 [==============================] - 2s 372us/step - loss: 0.1541 - acc: 0.9419 - val_loss: 0.1798 - val_acc: 0.9367\n",
      "Epoch 286/500\n",
      "4616/4616 [==============================] - 2s 359us/step - loss: 0.1395 - acc: 0.9417 - val_loss: 0.1799 - val_acc: 0.9359\n",
      "Epoch 287/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.1430 - acc: 0.9419 - val_loss: 0.1807 - val_acc: 0.9359\n",
      "Epoch 288/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.1426 - acc: 0.9428 - val_loss: 0.1895 - val_acc: 0.9359\n",
      "Epoch 289/500\n",
      "4616/4616 [==============================] - 2s 359us/step - loss: 0.1471 - acc: 0.9396 - val_loss: 0.1903 - val_acc: 0.9350\n",
      "Epoch 290/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.1435 - acc: 0.9439 - val_loss: 0.1914 - val_acc: 0.9350\n",
      "Epoch 291/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.1405 - acc: 0.9424 - val_loss: 0.1919 - val_acc: 0.9341\n",
      "Epoch 292/500\n",
      "4616/4616 [==============================] - 2s 358us/step - loss: 0.1521 - acc: 0.9424 - val_loss: 0.1925 - val_acc: 0.9350\n",
      "Epoch 293/500\n",
      "4616/4616 [==============================] - 2s 353us/step - loss: 0.1436 - acc: 0.9415 - val_loss: 0.1932 - val_acc: 0.9341\n",
      "Epoch 294/500\n",
      "4616/4616 [==============================] - 2s 355us/step - loss: 0.1457 - acc: 0.9426 - val_loss: 0.1939 - val_acc: 0.9341\n",
      "Epoch 295/500\n",
      "4616/4616 [==============================] - 2s 359us/step - loss: 0.1462 - acc: 0.9396 - val_loss: 0.1946 - val_acc: 0.9341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00295: early stopping\n",
      "Train on 4616 samples, validate on 1154 samples\n",
      "Epoch 1/500\n",
      "4616/4616 [==============================] - 3s 542us/step - loss: 0.4413 - acc: 0.8000 - val_loss: 0.2977 - val_acc: 0.8761\n",
      "Epoch 2/500\n",
      "4616/4616 [==============================] - 2s 385us/step - loss: 0.3585 - acc: 0.8618 - val_loss: 0.2551 - val_acc: 0.8943\n",
      "Epoch 3/500\n",
      "4616/4616 [==============================] - 2s 389us/step - loss: 0.3168 - acc: 0.8819 - val_loss: 0.2661 - val_acc: 0.8925\n",
      "Epoch 4/500\n",
      "4616/4616 [==============================] - 2s 392us/step - loss: 0.3290 - acc: 0.8899 - val_loss: 0.3107 - val_acc: 0.8917\n",
      "Epoch 5/500\n",
      "4616/4616 [==============================] - 2s 400us/step - loss: 0.3737 - acc: 0.8897 - val_loss: 0.3259 - val_acc: 0.8865\n",
      "Epoch 6/500\n",
      "4616/4616 [==============================] - 2s 403us/step - loss: 0.3720 - acc: 0.8865 - val_loss: 0.2918 - val_acc: 0.8873\n",
      "Epoch 7/500\n",
      "4616/4616 [==============================] - 2s 415us/step - loss: 0.3662 - acc: 0.8899 - val_loss: 0.2614 - val_acc: 0.8917\n",
      "Epoch 8/500\n",
      "4616/4616 [==============================] - 2s 389us/step - loss: 0.3060 - acc: 0.8910 - val_loss: 0.2468 - val_acc: 0.8960\n",
      "Epoch 9/500\n",
      "4616/4616 [==============================] - 2s 385us/step - loss: 0.2838 - acc: 0.8923 - val_loss: 0.2457 - val_acc: 0.8977\n",
      "Epoch 10/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.2832 - acc: 0.8958 - val_loss: 0.2474 - val_acc: 0.9012\n",
      "Epoch 11/500\n",
      "4616/4616 [==============================] - 2s 374us/step - loss: 0.2831 - acc: 0.8938 - val_loss: 0.2484 - val_acc: 0.9029\n",
      "Epoch 12/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.2845 - acc: 0.8990 - val_loss: 0.2477 - val_acc: 0.9038\n",
      "Epoch 13/500\n",
      "4616/4616 [==============================] - 2s 349us/step - loss: 0.2866 - acc: 0.8973 - val_loss: 0.2446 - val_acc: 0.9073\n",
      "Epoch 14/500\n",
      "4616/4616 [==============================] - 2s 351us/step - loss: 0.2745 - acc: 0.9010 - val_loss: 0.2398 - val_acc: 0.9090\n",
      "Epoch 15/500\n",
      "4616/4616 [==============================] - 2s 362us/step - loss: 0.2815 - acc: 0.9042 - val_loss: 0.2331 - val_acc: 0.9099\n",
      "Epoch 16/500\n",
      "4616/4616 [==============================] - 2s 368us/step - loss: 0.2785 - acc: 0.9068 - val_loss: 0.2258 - val_acc: 0.9116\n",
      "Epoch 17/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.2606 - acc: 0.9036 - val_loss: 0.2184 - val_acc: 0.9125\n",
      "Epoch 18/500\n",
      "4616/4616 [==============================] - 2s 349us/step - loss: 0.2606 - acc: 0.9051 - val_loss: 0.2124 - val_acc: 0.9116\n",
      "Epoch 19/500\n",
      "4616/4616 [==============================] - 2s 349us/step - loss: 0.2586 - acc: 0.9101 - val_loss: 0.2089 - val_acc: 0.9125\n",
      "Epoch 20/500\n",
      "4616/4616 [==============================] - 2s 351us/step - loss: 0.2482 - acc: 0.9062 - val_loss: 0.2161 - val_acc: 0.9142\n",
      "Epoch 21/500\n",
      "4616/4616 [==============================] - 2s 348us/step - loss: 0.2603 - acc: 0.9079 - val_loss: 0.2166 - val_acc: 0.9142\n",
      "Epoch 22/500\n",
      "4616/4616 [==============================] - 2s 350us/step - loss: 0.2857 - acc: 0.9081 - val_loss: 0.2345 - val_acc: 0.9151\n",
      "Epoch 23/500\n",
      "4616/4616 [==============================] - 2s 362us/step - loss: 0.2684 - acc: 0.9032 - val_loss: 0.2379 - val_acc: 0.9151\n",
      "Epoch 24/500\n",
      "4616/4616 [==============================] - 2s 356us/step - loss: 0.2631 - acc: 0.9064 - val_loss: 0.2453 - val_acc: 0.9159\n",
      "Epoch 25/500\n",
      "4616/4616 [==============================] - 2s 363us/step - loss: 0.2780 - acc: 0.9040 - val_loss: 0.2345 - val_acc: 0.9159\n",
      "Epoch 26/500\n",
      "4616/4616 [==============================] - 2s 376us/step - loss: 0.2845 - acc: 0.9073 - val_loss: 0.2292 - val_acc: 0.9177\n",
      "Epoch 27/500\n",
      "4616/4616 [==============================] - 2s 382us/step - loss: 0.2628 - acc: 0.9066 - val_loss: 0.2096 - val_acc: 0.9194\n",
      "Epoch 28/500\n",
      "4616/4616 [==============================] - 2s 380us/step - loss: 0.2634 - acc: 0.9090 - val_loss: 0.2048 - val_acc: 0.9194\n",
      "Epoch 29/500\n",
      "4616/4616 [==============================] - 2s 381us/step - loss: 0.2525 - acc: 0.9062 - val_loss: 0.2027 - val_acc: 0.9194\n",
      "Epoch 30/500\n",
      "4616/4616 [==============================] - 2s 383us/step - loss: 0.2340 - acc: 0.9116 - val_loss: 0.2018 - val_acc: 0.9194\n",
      "Epoch 31/500\n",
      "4616/4616 [==============================] - 2s 389us/step - loss: 0.2382 - acc: 0.9123 - val_loss: 0.1939 - val_acc: 0.9185\n",
      "Epoch 32/500\n",
      "4616/4616 [==============================] - 2s 383us/step - loss: 0.2393 - acc: 0.9084 - val_loss: 0.1932 - val_acc: 0.9194\n",
      "Epoch 33/500\n",
      "4616/4616 [==============================] - 2s 383us/step - loss: 0.2446 - acc: 0.9140 - val_loss: 0.1929 - val_acc: 0.9203\n",
      "Epoch 34/500\n",
      "4616/4616 [==============================] - 2s 382us/step - loss: 0.2364 - acc: 0.9105 - val_loss: 0.1925 - val_acc: 0.9194\n",
      "Epoch 35/500\n",
      "4616/4616 [==============================] - 2s 372us/step - loss: 0.2518 - acc: 0.9127 - val_loss: 0.1924 - val_acc: 0.9203\n",
      "Epoch 36/500\n",
      "4616/4616 [==============================] - 2s 372us/step - loss: 0.2362 - acc: 0.9131 - val_loss: 0.1923 - val_acc: 0.9194\n",
      "Epoch 37/500\n",
      "4616/4616 [==============================] - 2s 365us/step - loss: 0.2281 - acc: 0.9142 - val_loss: 0.1927 - val_acc: 0.9203\n",
      "Epoch 38/500\n",
      "4616/4616 [==============================] - 2s 368us/step - loss: 0.2279 - acc: 0.9125 - val_loss: 0.1929 - val_acc: 0.9194\n",
      "Epoch 39/500\n",
      "4616/4616 [==============================] - 2s 377us/step - loss: 0.2366 - acc: 0.9131 - val_loss: 0.1929 - val_acc: 0.9203\n",
      "Epoch 40/500\n",
      "4616/4616 [==============================] - 2s 371us/step - loss: 0.2216 - acc: 0.9149 - val_loss: 0.1928 - val_acc: 0.9194\n",
      "Epoch 41/500\n",
      "4616/4616 [==============================] - 2s 366us/step - loss: 0.2169 - acc: 0.9179 - val_loss: 0.1926 - val_acc: 0.9194\n",
      "Epoch 42/500\n",
      "4616/4616 [==============================] - 2s 391us/step - loss: 0.2132 - acc: 0.9170 - val_loss: 0.1923 - val_acc: 0.9194\n",
      "Epoch 43/500\n",
      "4616/4616 [==============================] - 2s 379us/step - loss: 0.2209 - acc: 0.9181 - val_loss: 0.1918 - val_acc: 0.9194\n",
      "Epoch 44/500\n",
      "4616/4616 [==============================] - 2s 381us/step - loss: 0.2352 - acc: 0.9170 - val_loss: 0.1906 - val_acc: 0.9185\n",
      "Epoch 45/500\n",
      "4616/4616 [==============================] - 2s 405us/step - loss: 0.2243 - acc: 0.9168 - val_loss: 0.1892 - val_acc: 0.9203\n",
      "Epoch 46/500\n",
      "4616/4616 [==============================] - 2s 393us/step - loss: 0.2378 - acc: 0.9110 - val_loss: 0.1880 - val_acc: 0.9194\n",
      "Epoch 47/500\n",
      "4616/4616 [==============================] - 2s 392us/step - loss: 0.2226 - acc: 0.9127 - val_loss: 0.1869 - val_acc: 0.9194\n",
      "Epoch 48/500\n",
      "4616/4616 [==============================] - 2s 394us/step - loss: 0.2295 - acc: 0.9146 - val_loss: 0.1859 - val_acc: 0.9203\n",
      "Epoch 49/500\n",
      "4616/4616 [==============================] - 2s 411us/step - loss: 0.2252 - acc: 0.9201 - val_loss: 0.1846 - val_acc: 0.9211\n",
      "Epoch 50/500\n",
      "4616/4616 [==============================] - 2s 363us/step - loss: 0.2132 - acc: 0.9162 - val_loss: 0.1836 - val_acc: 0.9220\n",
      "Epoch 51/500\n",
      "4616/4616 [==============================] - 2s 374us/step - loss: 0.2185 - acc: 0.9190 - val_loss: 0.1831 - val_acc: 0.9229\n",
      "Epoch 52/500\n",
      "4616/4616 [==============================] - 2s 384us/step - loss: 0.2162 - acc: 0.9162 - val_loss: 0.1905 - val_acc: 0.9229\n",
      "Epoch 53/500\n",
      "4616/4616 [==============================] - 2s 402us/step - loss: 0.2126 - acc: 0.9179 - val_loss: 0.1900 - val_acc: 0.9229\n",
      "Epoch 54/500\n",
      "4616/4616 [==============================] - 2s 386us/step - loss: 0.2087 - acc: 0.9179 - val_loss: 0.1897 - val_acc: 0.9229\n",
      "Epoch 55/500\n",
      "4616/4616 [==============================] - 2s 356us/step - loss: 0.2055 - acc: 0.9170 - val_loss: 0.1894 - val_acc: 0.9229\n",
      "Epoch 56/500\n",
      "4616/4616 [==============================] - 2s 355us/step - loss: 0.2255 - acc: 0.9214 - val_loss: 0.1894 - val_acc: 0.9237\n",
      "Epoch 57/500\n",
      "4616/4616 [==============================] - 2s 351us/step - loss: 0.2207 - acc: 0.9185 - val_loss: 0.1890 - val_acc: 0.9237\n",
      "Epoch 58/500\n",
      "4616/4616 [==============================] - 2s 394us/step - loss: 0.2144 - acc: 0.9205 - val_loss: 0.1886 - val_acc: 0.9246\n",
      "Epoch 59/500\n",
      "4616/4616 [==============================] - 2s 351us/step - loss: 0.2023 - acc: 0.9190 - val_loss: 0.1888 - val_acc: 0.9237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/500\n",
      "4616/4616 [==============================] - 2s 371us/step - loss: 0.2109 - acc: 0.9166 - val_loss: 0.1901 - val_acc: 0.9246\n",
      "Epoch 61/500\n",
      "4616/4616 [==============================] - 2s 370us/step - loss: 0.2051 - acc: 0.9203 - val_loss: 0.1983 - val_acc: 0.9255\n",
      "Epoch 62/500\n",
      "4616/4616 [==============================] - 2s 394us/step - loss: 0.2089 - acc: 0.9229 - val_loss: 0.1989 - val_acc: 0.9237\n",
      "Epoch 63/500\n",
      "4616/4616 [==============================] - 2s 392us/step - loss: 0.2074 - acc: 0.9229 - val_loss: 0.1998 - val_acc: 0.9246\n",
      "Epoch 64/500\n",
      "4616/4616 [==============================] - 2s 418us/step - loss: 0.2052 - acc: 0.9190 - val_loss: 0.2007 - val_acc: 0.9237\n",
      "Epoch 65/500\n",
      "4616/4616 [==============================] - 2s 411us/step - loss: 0.2057 - acc: 0.9227 - val_loss: 0.2015 - val_acc: 0.9237\n",
      "Epoch 66/500\n",
      "4616/4616 [==============================] - 2s 386us/step - loss: 0.2085 - acc: 0.9192 - val_loss: 0.2023 - val_acc: 0.9229\n",
      "Epoch 67/500\n",
      "4616/4616 [==============================] - 2s 417us/step - loss: 0.2060 - acc: 0.9190 - val_loss: 0.2025 - val_acc: 0.9229\n",
      "Epoch 68/500\n",
      "4616/4616 [==============================] - 2s 395us/step - loss: 0.2040 - acc: 0.9196 - val_loss: 0.2029 - val_acc: 0.9237\n",
      "Epoch 69/500\n",
      "4616/4616 [==============================] - 2s 391us/step - loss: 0.2117 - acc: 0.9177 - val_loss: 0.2090 - val_acc: 0.9246\n",
      "Epoch 70/500\n",
      "4616/4616 [==============================] - 2s 412us/step - loss: 0.2024 - acc: 0.9179 - val_loss: 0.2079 - val_acc: 0.9246\n",
      "Epoch 71/500\n",
      "4616/4616 [==============================] - 2s 412us/step - loss: 0.1956 - acc: 0.9201 - val_loss: 0.2067 - val_acc: 0.9237\n",
      "Epoch 72/500\n",
      "4616/4616 [==============================] - 2s 393us/step - loss: 0.2107 - acc: 0.9177 - val_loss: 0.2050 - val_acc: 0.9246\n",
      "Epoch 73/500\n",
      "4616/4616 [==============================] - 2s 411us/step - loss: 0.2061 - acc: 0.9242 - val_loss: 0.1988 - val_acc: 0.9255\n",
      "Epoch 74/500\n",
      "4616/4616 [==============================] - 2s 379us/step - loss: 0.2013 - acc: 0.9242 - val_loss: 0.1963 - val_acc: 0.9246\n",
      "Epoch 75/500\n",
      "4616/4616 [==============================] - 2s 376us/step - loss: 0.2046 - acc: 0.9214 - val_loss: 0.2033 - val_acc: 0.9246\n",
      "Epoch 76/500\n",
      "4616/4616 [==============================] - 2s 364us/step - loss: 0.1993 - acc: 0.9231 - val_loss: 0.1963 - val_acc: 0.9246\n",
      "Epoch 77/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.2015 - acc: 0.9211 - val_loss: 0.1962 - val_acc: 0.9255\n",
      "Epoch 78/500\n",
      "4616/4616 [==============================] - 2s 398us/step - loss: 0.1961 - acc: 0.9235 - val_loss: 0.2039 - val_acc: 0.9246\n",
      "Epoch 79/500\n",
      "4616/4616 [==============================] - 2s 393us/step - loss: 0.1974 - acc: 0.9218 - val_loss: 0.1853 - val_acc: 0.9246\n",
      "Epoch 80/500\n",
      "4616/4616 [==============================] - 2s 395us/step - loss: 0.1913 - acc: 0.9216 - val_loss: 0.1755 - val_acc: 0.9246\n",
      "Epoch 81/500\n",
      "4616/4616 [==============================] - 2s 375us/step - loss: 0.1971 - acc: 0.9205 - val_loss: 0.1735 - val_acc: 0.9246\n",
      "Epoch 82/500\n",
      "4616/4616 [==============================] - 2s 377us/step - loss: 0.1948 - acc: 0.9235 - val_loss: 0.1730 - val_acc: 0.9255\n",
      "Epoch 83/500\n",
      "4616/4616 [==============================] - 2s 372us/step - loss: 0.1941 - acc: 0.9257 - val_loss: 0.1733 - val_acc: 0.9255\n",
      "Epoch 84/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.1957 - acc: 0.9263 - val_loss: 0.1746 - val_acc: 0.9255\n",
      "Epoch 85/500\n",
      "4616/4616 [==============================] - 2s 354us/step - loss: 0.1927 - acc: 0.9194 - val_loss: 0.1786 - val_acc: 0.9255\n",
      "Epoch 86/500\n",
      "4616/4616 [==============================] - 2s 369us/step - loss: 0.1858 - acc: 0.9270 - val_loss: 0.2003 - val_acc: 0.9246\n",
      "Epoch 87/500\n",
      "4616/4616 [==============================] - 2s 364us/step - loss: 0.1956 - acc: 0.9220 - val_loss: 0.2170 - val_acc: 0.9229\n",
      "Epoch 88/500\n",
      "4616/4616 [==============================] - 2s 381us/step - loss: 0.1908 - acc: 0.9240 - val_loss: 0.2251 - val_acc: 0.9246\n",
      "Epoch 89/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.1937 - acc: 0.9259 - val_loss: 0.2257 - val_acc: 0.9246\n",
      "Epoch 90/500\n",
      "4616/4616 [==============================] - 2s 386us/step - loss: 0.1895 - acc: 0.9246 - val_loss: 0.2242 - val_acc: 0.9246\n",
      "Epoch 91/500\n",
      "4616/4616 [==============================] - 2s 378us/step - loss: 0.1940 - acc: 0.9235 - val_loss: 0.2209 - val_acc: 0.9255\n",
      "Epoch 92/500\n",
      "4616/4616 [==============================] - 2s 357us/step - loss: 0.1908 - acc: 0.9231 - val_loss: 0.2109 - val_acc: 0.9272\n",
      "Epoch 93/500\n",
      "4616/4616 [==============================] - 2s 356us/step - loss: 0.1945 - acc: 0.9257 - val_loss: 0.1923 - val_acc: 0.9298\n",
      "Epoch 94/500\n",
      "4616/4616 [==============================] - 2s 367us/step - loss: 0.1885 - acc: 0.9237 - val_loss: 0.1869 - val_acc: 0.9307\n",
      "Epoch 95/500\n",
      "4616/4616 [==============================] - 2s 364us/step - loss: 0.1898 - acc: 0.9253 - val_loss: 0.1857 - val_acc: 0.9307\n",
      "Epoch 96/500\n",
      "4616/4616 [==============================] - 2s 384us/step - loss: 0.1823 - acc: 0.9268 - val_loss: 0.1861 - val_acc: 0.9307\n",
      "Epoch 97/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.1944 - acc: 0.9261 - val_loss: 0.1963 - val_acc: 0.9289\n",
      "Epoch 98/500\n",
      "4616/4616 [==============================] - 2s 381us/step - loss: 0.1779 - acc: 0.9248 - val_loss: 0.1987 - val_acc: 0.9298\n",
      "Epoch 99/500\n",
      "4616/4616 [==============================] - 2s 404us/step - loss: 0.1914 - acc: 0.9255 - val_loss: 0.2133 - val_acc: 0.9272\n",
      "Epoch 100/500\n",
      "4616/4616 [==============================] - 2s 388us/step - loss: 0.1800 - acc: 0.9294 - val_loss: 0.2288 - val_acc: 0.9255\n",
      "Epoch 101/500\n",
      "4616/4616 [==============================] - 2s 364us/step - loss: 0.1783 - acc: 0.9263 - val_loss: 0.2387 - val_acc: 0.9246\n",
      "Epoch 102/500\n",
      "4616/4616 [==============================] - 2s 370us/step - loss: 0.1769 - acc: 0.9272 - val_loss: 0.2397 - val_acc: 0.9263\n",
      "Epoch 103/500\n",
      "4616/4616 [==============================] - 2s 408us/step - loss: 0.2005 - acc: 0.9289 - val_loss: 0.2382 - val_acc: 0.9246\n",
      "Epoch 104/500\n",
      "4616/4616 [==============================] - 2s 406us/step - loss: 0.1800 - acc: 0.9287 - val_loss: 0.2094 - val_acc: 0.9263\n",
      "Epoch 105/500\n",
      "4616/4616 [==============================] - 3s 580us/step - loss: 0.1809 - acc: 0.9250 - val_loss: 0.1963 - val_acc: 0.9272\n",
      "Epoch 106/500\n",
      "4616/4616 [==============================] - 2s 461us/step - loss: 0.1823 - acc: 0.9266 - val_loss: 0.1945 - val_acc: 0.9272\n",
      "Epoch 107/500\n",
      "4616/4616 [==============================] - 2s 443us/step - loss: 0.1780 - acc: 0.9270 - val_loss: 0.1940 - val_acc: 0.9272\n",
      "Epoch 108/500\n",
      "4616/4616 [==============================] - 2s 454us/step - loss: 0.1717 - acc: 0.9287 - val_loss: 0.1947 - val_acc: 0.9246\n",
      "Epoch 109/500\n",
      "4616/4616 [==============================] - 2s 401us/step - loss: 0.1772 - acc: 0.9253 - val_loss: 0.2047 - val_acc: 0.9246\n",
      "Epoch 110/500\n",
      "4616/4616 [==============================] - 2s 385us/step - loss: 0.1823 - acc: 0.9279 - val_loss: 0.2070 - val_acc: 0.9246\n",
      "Epoch 111/500\n",
      "4616/4616 [==============================] - 2s 372us/step - loss: 0.1799 - acc: 0.9270 - val_loss: 0.2119 - val_acc: 0.9237\n",
      "Epoch 112/500\n",
      "4616/4616 [==============================] - 2s 369us/step - loss: 0.1821 - acc: 0.9311 - val_loss: 0.2385 - val_acc: 0.9237\n",
      "Epoch 113/500\n",
      "4616/4616 [==============================] - 2s 380us/step - loss: 0.1699 - acc: 0.9279 - val_loss: 0.2389 - val_acc: 0.9237\n",
      "Epoch 114/500\n",
      "4616/4616 [==============================] - 2s 385us/step - loss: 0.1819 - acc: 0.9259 - val_loss: 0.2388 - val_acc: 0.9237\n",
      "Epoch 115/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.1766 - acc: 0.9307 - val_loss: 0.2299 - val_acc: 0.9263\n",
      "Epoch 116/500\n",
      "4616/4616 [==============================] - 2s 393us/step - loss: 0.1700 - acc: 0.9315 - val_loss: 0.2091 - val_acc: 0.9281\n",
      "Epoch 117/500\n",
      "4616/4616 [==============================] - 2s 400us/step - loss: 0.1687 - acc: 0.9294 - val_loss: 0.2042 - val_acc: 0.9298\n",
      "Epoch 118/500\n",
      "4616/4616 [==============================] - 2s 385us/step - loss: 0.1684 - acc: 0.9294 - val_loss: 0.2023 - val_acc: 0.9315\n",
      "Epoch 119/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4616/4616 [==============================] - 2s 381us/step - loss: 0.1672 - acc: 0.9328 - val_loss: 0.2022 - val_acc: 0.9315\n",
      "Epoch 120/500\n",
      "4616/4616 [==============================] - 2s 387us/step - loss: 0.1711 - acc: 0.9307 - val_loss: 0.2034 - val_acc: 0.9307\n",
      "Epoch 121/500\n",
      "4616/4616 [==============================] - 2s 378us/step - loss: 0.1734 - acc: 0.9279 - val_loss: 0.2140 - val_acc: 0.9307\n",
      "Epoch 122/500\n",
      "4616/4616 [==============================] - 2s 381us/step - loss: 0.1635 - acc: 0.9324 - val_loss: 0.2275 - val_acc: 0.9289\n",
      "Epoch 123/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.1871 - acc: 0.9276 - val_loss: 0.2415 - val_acc: 0.9281\n",
      "Epoch 124/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.1692 - acc: 0.9302 - val_loss: 0.2512 - val_acc: 0.9263\n",
      "Epoch 125/500\n",
      "4616/4616 [==============================] - 2s 378us/step - loss: 0.1766 - acc: 0.9298 - val_loss: 0.2516 - val_acc: 0.9255\n",
      "Epoch 126/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.1801 - acc: 0.9300 - val_loss: 0.1964 - val_acc: 0.9333\n",
      "Epoch 127/500\n",
      "4616/4616 [==============================] - 2s 400us/step - loss: 0.1675 - acc: 0.9344 - val_loss: 0.1933 - val_acc: 0.9324\n",
      "Epoch 128/500\n",
      "4616/4616 [==============================] - 2s 386us/step - loss: 0.1700 - acc: 0.9298 - val_loss: 0.1887 - val_acc: 0.9324\n",
      "Epoch 129/500\n",
      "4616/4616 [==============================] - 2s 373us/step - loss: 0.1808 - acc: 0.9296 - val_loss: 0.1912 - val_acc: 0.9324\n",
      "Epoch 130/500\n",
      "4616/4616 [==============================] - 2s 383us/step - loss: 0.1731 - acc: 0.9341 - val_loss: 0.1932 - val_acc: 0.9315\n",
      "Epoch 131/500\n",
      "4616/4616 [==============================] - 2s 360us/step - loss: 0.1794 - acc: 0.9335 - val_loss: 0.1946 - val_acc: 0.9315\n",
      "Epoch 132/500\n",
      "4616/4616 [==============================] - 2s 362us/step - loss: 0.1799 - acc: 0.9333 - val_loss: 0.2036 - val_acc: 0.9255\n",
      "Epoch 00132: early stopping\n"
     ]
    }
   ],
   "source": [
    "Classifier.refine(valX, valY)\n",
    "test_predictions = Classifier.predict(testX)\n",
    "\n",
    "predictions = Classifier.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.895\n",
      "Test MCC:  0.650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4506,   83],\n",
       "       [ 523,  659]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test Accuracy:  {:.3f}'.format(sklearn.metrics.accuracy_score(testY, predictions)))\n",
    "print('Test MCC:  {:.3f}'.format(sklearn.metrics.matthews_corrcoef(testY, predictions)))\n",
    "sklearn.metrics.confusion_matrix(testY, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have accuracies of nearly 90%! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Models\\bow score: 0.891\n",
      "Model Models\\bow_005_1 score: 0.889\n",
      "Model Models\\bow_005_2 score: 0.889\n",
      "Model Models\\bow_005_3 score: 0.888\n",
      "Model Models\\glove score: 0.888\n",
      "Model Models\\glove_005_1 score: 0.881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ensembled': 0.8949922023912666,\n",
       " 'Models\\\\bow': 0.8910067579275689,\n",
       " 'Models\\\\bow_005_1': 0.8891006757927569,\n",
       " 'Models\\\\bow_005_2': 0.8885808352105354,\n",
       " 'Models\\\\bow_005_3': 0.8882342748223878,\n",
       " 'Models\\\\glove': 0.8877144342401664,\n",
       " 'Models\\\\glove_005_1': 0.8809565066712874}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier.evaluate(testX, testY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.21.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
