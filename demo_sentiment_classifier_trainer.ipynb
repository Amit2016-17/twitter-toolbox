{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from twitter_nlp_toolkit.twit_module import twit_module\n",
    "from twitter_nlp_toolkit.file_fetcher import file_fetcher\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 1 # Fraction of data to train on\n",
    "model_name = 'model_test_05'\n",
    "redownload=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we download some training and validation data.\n",
    "\n",
    "The training data is the semi-supervised Sentiment140 dataset, taken form here: https://www.kaggle.com/kazanova/sentiment140\n",
    "\n",
    "The validation data is hand-labeled airline customer feedback taken from https://www.figure-eight.com/data-for-everyone/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "if redownload: \n",
    "    downloader = file_fetcher.downloader(using_notebook=True)\n",
    "    # Validation data\n",
    "    downloader.download_file('https://www.dropbox.com/s/440m6x07bjg6c0h/Tweets.zip?dl=1',\"Tweets.zip\")\n",
    "    \n",
    "    # Compressed model\n",
    "    # Note that this model has only been trained on 5% of the training data\n",
    "    # Update when better-trained model is available\n",
    "    downloader.download_file(\"https://www.dropbox.com/s/i88eqlja56xncyx/model_test_05.zip?dl=1\",\"model_test_05.zip\")\n",
    "    \n",
    "    # Extract all the contents of zip file in current directory\n",
    "    with ZipFile(model_name + '.zip', 'r') as zipObj:\n",
    "        zipObj.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation data\n",
    "\n",
    "test_data = pd.read_csv('Tweets.zip', header=0, names=['Index', 'Sentiment', 'Sentiment_confidence',\n",
    "                                                                'Negative_reason', 'Negative_reason_confidence',\n",
    "                                                                'Airline', 'Airline_sentiment_gold', 'Handle',\n",
    "                                                                'Negative_reason_gold', 'Retweet_count', 'Text',\n",
    "                                                                'Tweet_coord', 'Time', 'Location', 'Timezone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unlabeled test data\n",
    "\n",
    "test_data['Labels'] = (test_data['Sentiment'] == 'positive') * 2\n",
    "test_data['Labels'] = test_data['Labels'] + (test_data['Sentiment'] == 'neutral') * 1\n",
    "test_data['Labels'] = test_data['Labels'] / 2\n",
    "\n",
    "test_data.set_index('Labels')\n",
    "test_data = test_data[test_data.Labels != 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW model loaded successfully\n",
      "LSTM model loaded successfully\n",
      "Pre-trained embedding model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Executing this cell takes about 30s on a laptop\n",
    "\n",
    "Classifier = twit_module.SentimentAnalyzer()\n",
    "Classifier.load_models(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We santiy check the models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifier.predict(['I am happy', 'I am sad', 'I am cheerful', 'I am mad'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executing this cell takes several minuites on a laptop\n",
    "\n",
    "predictions = Classifier.predict(test_data['Text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the model on an airline customer feedback dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.785\n",
      "Test MCC:  0.538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6974, 2204],\n",
       "       [ 273, 2090]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test Accuracy:  {:.3f}'.format(sklearn.metrics.accuracy_score(test_data['Labels'], predictions)))\n",
    "print('Test MCC:  {:.3f}'.format(sklearn.metrics.matthews_corrcoef(test_data['Labels'], predictions)))\n",
    "sklearn.metrics.confusion_matrix(test_data['Labels'], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have accuracy of just under 80%.\n",
    "\n",
    "To improve our accuracy, we can refine the model on our airline data. The early stopping procedure (enabled by default to use 10% of the training data for validation) should prevent overfitting. We withold 20% for our own validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = sklearn.model_selection.train_test_split(test_data['Text'], test_data['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7789 samples, validate on 866 samples\n",
      "Epoch 1/250\n",
      "7789/7789 [==============================] - 4s 498us/step - loss: 0.4143 - acc: 0.8264 - val_loss: 0.3403 - val_acc: 0.8568\n",
      "Epoch 2/250\n",
      "7789/7789 [==============================] - 3s 370us/step - loss: 0.3577 - acc: 0.8595 - val_loss: 0.3025 - val_acc: 0.8776\n",
      "Epoch 3/250\n",
      "7789/7789 [==============================] - 3s 375us/step - loss: 0.3196 - acc: 0.8796 - val_loss: 0.2820 - val_acc: 0.8811\n",
      "Epoch 4/250\n",
      "7789/7789 [==============================] - 3s 387us/step - loss: 0.3018 - acc: 0.8873 - val_loss: 0.2852 - val_acc: 0.8891\n",
      "Epoch 5/250\n",
      "7789/7789 [==============================] - 3s 371us/step - loss: 0.2981 - acc: 0.8955 - val_loss: 0.3008 - val_acc: 0.8834\n",
      "Epoch 6/250\n",
      "7789/7789 [==============================] - 3s 385us/step - loss: 0.3098 - acc: 0.8919 - val_loss: 0.2996 - val_acc: 0.8834\n",
      "Epoch 7/250\n",
      "7789/7789 [==============================] - 3s 399us/step - loss: 0.2970 - acc: 0.8943 - val_loss: 0.2873 - val_acc: 0.8845\n",
      "Epoch 8/250\n",
      "7789/7789 [==============================] - 3s 382us/step - loss: 0.2931 - acc: 0.8936 - val_loss: 0.2844 - val_acc: 0.8845\n",
      "Epoch 9/250\n",
      "7789/7789 [==============================] - 3s 384us/step - loss: 0.2873 - acc: 0.8964 - val_loss: 0.2822 - val_acc: 0.8845\n",
      "Epoch 10/250\n",
      "7789/7789 [==============================] - 3s 386us/step - loss: 0.2812 - acc: 0.8952 - val_loss: 0.2686 - val_acc: 0.8845\n",
      "Epoch 11/250\n",
      "7789/7789 [==============================] - 3s 375us/step - loss: 0.2810 - acc: 0.8952 - val_loss: 0.2659 - val_acc: 0.8857\n",
      "Epoch 12/250\n",
      "7789/7789 [==============================] - 3s 375us/step - loss: 0.2813 - acc: 0.8956 - val_loss: 0.2638 - val_acc: 0.8903\n",
      "Epoch 13/250\n",
      "7789/7789 [==============================] - 3s 383us/step - loss: 0.2728 - acc: 0.9008 - val_loss: 0.2621 - val_acc: 0.8949\n",
      "Epoch 14/250\n",
      "7789/7789 [==============================] - 3s 390us/step - loss: 0.2724 - acc: 0.8968 - val_loss: 0.2605 - val_acc: 0.8938\n",
      "Epoch 15/250\n",
      "7789/7789 [==============================] - 3s 382us/step - loss: 0.2738 - acc: 0.8972 - val_loss: 0.2590 - val_acc: 0.8961\n",
      "Epoch 16/250\n",
      "7789/7789 [==============================] - 3s 381us/step - loss: 0.2724 - acc: 0.8999 - val_loss: 0.2575 - val_acc: 0.8972\n",
      "Epoch 17/250\n",
      "7789/7789 [==============================] - 3s 390us/step - loss: 0.2692 - acc: 0.8995 - val_loss: 0.2560 - val_acc: 0.8961\n",
      "Epoch 18/250\n",
      "7789/7789 [==============================] - 3s 382us/step - loss: 0.2642 - acc: 0.9022 - val_loss: 0.2543 - val_acc: 0.8961\n",
      "Epoch 19/250\n",
      "7789/7789 [==============================] - 3s 398us/step - loss: 0.2607 - acc: 0.9035 - val_loss: 0.2527 - val_acc: 0.8972\n",
      "Epoch 20/250\n",
      "7789/7789 [==============================] - 3s 386us/step - loss: 0.2529 - acc: 0.9037 - val_loss: 0.2510 - val_acc: 0.8972\n",
      "Epoch 21/250\n",
      "7789/7789 [==============================] - 3s 406us/step - loss: 0.2639 - acc: 0.9023 - val_loss: 0.2493 - val_acc: 0.8995\n",
      "Epoch 22/250\n",
      "7789/7789 [==============================] - 3s 369us/step - loss: 0.2568 - acc: 0.9008 - val_loss: 0.2477 - val_acc: 0.9007\n",
      "Epoch 23/250\n",
      "7789/7789 [==============================] - 3s 373us/step - loss: 0.2559 - acc: 0.9032 - val_loss: 0.2462 - val_acc: 0.9018\n",
      "Epoch 24/250\n",
      "7789/7789 [==============================] - 3s 377us/step - loss: 0.2544 - acc: 0.9063 - val_loss: 0.2448 - val_acc: 0.9018\n",
      "Epoch 25/250\n",
      "7789/7789 [==============================] - 3s 373us/step - loss: 0.2490 - acc: 0.9033 - val_loss: 0.2436 - val_acc: 0.9018\n",
      "Epoch 26/250\n",
      "7789/7789 [==============================] - 3s 372us/step - loss: 0.2465 - acc: 0.9055 - val_loss: 0.2428 - val_acc: 0.8995\n",
      "Epoch 27/250\n",
      "7789/7789 [==============================] - 3s 372us/step - loss: 0.2481 - acc: 0.9035 - val_loss: 0.2424 - val_acc: 0.9007\n",
      "Epoch 28/250\n",
      "7789/7789 [==============================] - 3s 371us/step - loss: 0.2487 - acc: 0.9097 - val_loss: 0.2426 - val_acc: 0.9007\n",
      "Epoch 29/250\n",
      "7789/7789 [==============================] - 3s 372us/step - loss: 0.2461 - acc: 0.9054 - val_loss: 0.2458 - val_acc: 0.9018\n",
      "Epoch 30/250\n",
      "7789/7789 [==============================] - 3s 371us/step - loss: 0.2454 - acc: 0.9090 - val_loss: 0.2534 - val_acc: 0.9018\n",
      "Epoch 31/250\n",
      "7789/7789 [==============================] - 3s 371us/step - loss: 0.2470 - acc: 0.9067 - val_loss: 0.2536 - val_acc: 0.9030\n",
      "Epoch 32/250\n",
      "7789/7789 [==============================] - 3s 372us/step - loss: 0.2398 - acc: 0.9103 - val_loss: 0.2529 - val_acc: 0.9030\n",
      "Epoch 33/250\n",
      "7789/7789 [==============================] - 3s 375us/step - loss: 0.2474 - acc: 0.9106 - val_loss: 0.2521 - val_acc: 0.9042\n",
      "Epoch 34/250\n",
      "7789/7789 [==============================] - 3s 373us/step - loss: 0.2391 - acc: 0.9082 - val_loss: 0.2510 - val_acc: 0.9042\n",
      "Epoch 35/250\n",
      "7789/7789 [==============================] - 3s 378us/step - loss: 0.2400 - acc: 0.9074 - val_loss: 0.2499 - val_acc: 0.9042\n",
      "Epoch 36/250\n",
      "7789/7789 [==============================] - 3s 374us/step - loss: 0.2368 - acc: 0.9086 - val_loss: 0.2490 - val_acc: 0.9042\n",
      "Epoch 37/250\n",
      "7789/7789 [==============================] - 3s 399us/step - loss: 0.2381 - acc: 0.9100 - val_loss: 0.2483 - val_acc: 0.9042\n",
      "Epoch 38/250\n",
      "7789/7789 [==============================] - 7s 870us/step - loss: 0.2364 - acc: 0.9088 - val_loss: 0.2476 - val_acc: 0.9042\n",
      "Epoch 39/250\n",
      "7789/7789 [==============================] - 10s 1ms/step - loss: 0.2382 - acc: 0.9127 - val_loss: 0.2478 - val_acc: 0.9042\n",
      "Epoch 40/250\n",
      "7789/7789 [==============================] - 11s 1ms/step - loss: 0.2309 - acc: 0.9112 - val_loss: 0.2563 - val_acc: 0.9042\n",
      "Epoch 41/250\n",
      "7789/7789 [==============================] - 11s 1ms/step - loss: 0.2355 - acc: 0.9094 - val_loss: 0.2555 - val_acc: 0.9053\n",
      "Epoch 42/250\n",
      "7789/7789 [==============================] - 11s 1ms/step - loss: 0.2347 - acc: 0.9118 - val_loss: 0.2549 - val_acc: 0.9030\n",
      "Epoch 43/250\n",
      "7789/7789 [==============================] - 5s 654us/step - loss: 0.2336 - acc: 0.9105 - val_loss: 0.2543 - val_acc: 0.9030\n",
      "Epoch 44/250\n",
      "7789/7789 [==============================] - 4s 542us/step - loss: 0.2280 - acc: 0.9155 - val_loss: 0.2538 - val_acc: 0.9042\n",
      "Epoch 45/250\n",
      "7789/7789 [==============================] - 4s 525us/step - loss: 0.2302 - acc: 0.9140 - val_loss: 0.2533 - val_acc: 0.9030\n",
      "Epoch 46/250\n",
      "7789/7789 [==============================] - 4s 508us/step - loss: 0.2287 - acc: 0.9112 - val_loss: 0.2527 - val_acc: 0.9042\n",
      "Epoch 47/250\n",
      "7789/7789 [==============================] - 4s 488us/step - loss: 0.2333 - acc: 0.9114 - val_loss: 0.2517 - val_acc: 0.9053\n",
      "Epoch 48/250\n",
      "7789/7789 [==============================] - 4s 473us/step - loss: 0.2276 - acc: 0.9137 - val_loss: 0.2510 - val_acc: 0.9042\n",
      "Epoch 49/250\n",
      "7789/7789 [==============================] - 4s 467us/step - loss: 0.2249 - acc: 0.9139 - val_loss: 0.2417 - val_acc: 0.9042\n",
      "Epoch 50/250\n",
      "7789/7789 [==============================] - 4s 457us/step - loss: 0.2257 - acc: 0.9132 - val_loss: 0.2390 - val_acc: 0.9042\n",
      "Epoch 51/250\n",
      "7789/7789 [==============================] - 3s 443us/step - loss: 0.2157 - acc: 0.9135 - val_loss: 0.2379 - val_acc: 0.9030\n",
      "Epoch 52/250\n",
      "7789/7789 [==============================] - 3s 438us/step - loss: 0.2270 - acc: 0.9145 - val_loss: 0.2372 - val_acc: 0.9018\n",
      "Epoch 53/250\n",
      "7789/7789 [==============================] - 3s 434us/step - loss: 0.2216 - acc: 0.9177 - val_loss: 0.2367 - val_acc: 0.9018\n",
      "Epoch 54/250\n",
      "7789/7789 [==============================] - 3s 426us/step - loss: 0.2233 - acc: 0.9149 - val_loss: 0.2365 - val_acc: 0.9018\n",
      "Epoch 55/250\n",
      "7789/7789 [==============================] - 3s 427us/step - loss: 0.2234 - acc: 0.9160 - val_loss: 0.2366 - val_acc: 0.9018\n",
      "Epoch 56/250\n",
      "7789/7789 [==============================] - 4s 451us/step - loss: 0.2166 - acc: 0.9173 - val_loss: 0.2384 - val_acc: 0.9030\n",
      "Epoch 57/250\n",
      "7789/7789 [==============================] - 4s 454us/step - loss: 0.2212 - acc: 0.9176 - val_loss: 0.2468 - val_acc: 0.9042\n",
      "Epoch 58/250\n",
      "7789/7789 [==============================] - 3s 441us/step - loss: 0.2214 - acc: 0.9174 - val_loss: 0.2471 - val_acc: 0.9042\n",
      "Epoch 59/250\n",
      "7789/7789 [==============================] - 3s 416us/step - loss: 0.2206 - acc: 0.9154 - val_loss: 0.2468 - val_acc: 0.9053\n",
      "Epoch 60/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7789/7789 [==============================] - 3s 403us/step - loss: 0.2135 - acc: 0.9187 - val_loss: 0.2466 - val_acc: 0.9065\n",
      "Epoch 61/250\n",
      "7789/7789 [==============================] - 3s 425us/step - loss: 0.2205 - acc: 0.9182 - val_loss: 0.2467 - val_acc: 0.9065\n",
      "Epoch 62/250\n",
      "7789/7789 [==============================] - 3s 440us/step - loss: 0.2093 - acc: 0.9139 - val_loss: 0.2473 - val_acc: 0.9065\n",
      "Epoch 63/250\n",
      "7789/7789 [==============================] - 3s 425us/step - loss: 0.2171 - acc: 0.9149 - val_loss: 0.2485 - val_acc: 0.9065\n",
      "Epoch 64/250\n",
      "7789/7789 [==============================] - 3s 394us/step - loss: 0.2183 - acc: 0.9172 - val_loss: 0.2574 - val_acc: 0.9065\n",
      "Epoch 65/250\n",
      "7789/7789 [==============================] - 3s 383us/step - loss: 0.2175 - acc: 0.9199 - val_loss: 0.2572 - val_acc: 0.9065\n",
      "Epoch 66/250\n",
      "7789/7789 [==============================] - 3s 380us/step - loss: 0.2139 - acc: 0.9176 - val_loss: 0.2572 - val_acc: 0.9076\n",
      "Epoch 67/250\n",
      "7789/7789 [==============================] - 3s 397us/step - loss: 0.2119 - acc: 0.9185 - val_loss: 0.2571 - val_acc: 0.9099\n",
      "Epoch 68/250\n",
      "7789/7789 [==============================] - 3s 382us/step - loss: 0.2146 - acc: 0.9171 - val_loss: 0.2571 - val_acc: 0.9099\n",
      "Epoch 69/250\n",
      "7789/7789 [==============================] - 3s 381us/step - loss: 0.2183 - acc: 0.9158 - val_loss: 0.2569 - val_acc: 0.9099\n",
      "Epoch 70/250\n",
      "7789/7789 [==============================] - 3s 389us/step - loss: 0.2131 - acc: 0.9173 - val_loss: 0.2569 - val_acc: 0.9111\n",
      "Epoch 71/250\n",
      "7789/7789 [==============================] - 3s 383us/step - loss: 0.2119 - acc: 0.9196 - val_loss: 0.2571 - val_acc: 0.9122\n",
      "Epoch 72/250\n",
      "7789/7789 [==============================] - 3s 390us/step - loss: 0.2159 - acc: 0.9190 - val_loss: 0.2569 - val_acc: 0.9099\n",
      "Epoch 73/250\n",
      "7789/7789 [==============================] - 3s 384us/step - loss: 0.2031 - acc: 0.9208 - val_loss: 0.2563 - val_acc: 0.9076\n",
      "Epoch 74/250\n",
      "7789/7789 [==============================] - 3s 400us/step - loss: 0.2121 - acc: 0.9205 - val_loss: 0.2560 - val_acc: 0.9088\n",
      "Epoch 75/250\n",
      "7789/7789 [==============================] - 3s 408us/step - loss: 0.2013 - acc: 0.9217 - val_loss: 0.2559 - val_acc: 0.9111\n",
      "Epoch 76/250\n",
      "7789/7789 [==============================] - 3s 392us/step - loss: 0.2152 - acc: 0.9181 - val_loss: 0.2552 - val_acc: 0.9111\n",
      "Epoch 77/250\n",
      "7789/7789 [==============================] - 3s 390us/step - loss: 0.2054 - acc: 0.9172 - val_loss: 0.2544 - val_acc: 0.9099\n",
      "Epoch 78/250\n",
      "7789/7789 [==============================] - 3s 378us/step - loss: 0.2063 - acc: 0.9203 - val_loss: 0.2535 - val_acc: 0.9088\n",
      "Epoch 79/250\n",
      "7789/7789 [==============================] - 3s 381us/step - loss: 0.1995 - acc: 0.9222 - val_loss: 0.2530 - val_acc: 0.9111\n",
      "Epoch 80/250\n",
      "7789/7789 [==============================] - 3s 375us/step - loss: 0.2016 - acc: 0.9218 - val_loss: 0.2526 - val_acc: 0.9122\n",
      "Epoch 81/250\n",
      "7789/7789 [==============================] - 3s 379us/step - loss: 0.2082 - acc: 0.9191 - val_loss: 0.2522 - val_acc: 0.9122\n",
      "Epoch 82/250\n",
      "7789/7789 [==============================] - 3s 381us/step - loss: 0.2055 - acc: 0.9187 - val_loss: 0.2522 - val_acc: 0.9111\n",
      "Epoch 83/250\n",
      "7789/7789 [==============================] - 3s 386us/step - loss: 0.2054 - acc: 0.9207 - val_loss: 0.2530 - val_acc: 0.9111\n",
      "Epoch 84/250\n",
      "7789/7789 [==============================] - 3s 380us/step - loss: 0.2065 - acc: 0.9187 - val_loss: 0.2635 - val_acc: 0.9099\n",
      "Epoch 85/250\n",
      "7789/7789 [==============================] - 3s 382us/step - loss: 0.1984 - acc: 0.9186 - val_loss: 0.2545 - val_acc: 0.9111\n",
      "Epoch 86/250\n",
      "7789/7789 [==============================] - 4s 456us/step - loss: 0.1998 - acc: 0.9232 - val_loss: 0.2539 - val_acc: 0.9122\n",
      "Epoch 87/250\n",
      "7789/7789 [==============================] - 3s 396us/step - loss: 0.2058 - acc: 0.9210 - val_loss: 0.2584 - val_acc: 0.9122\n",
      "Epoch 88/250\n",
      "7789/7789 [==============================] - 3s 385us/step - loss: 0.1974 - acc: 0.9222 - val_loss: 0.2626 - val_acc: 0.9122\n",
      "Epoch 89/250\n",
      "7789/7789 [==============================] - 3s 396us/step - loss: 0.1956 - acc: 0.9210 - val_loss: 0.2625 - val_acc: 0.9122\n",
      "Epoch 90/250\n",
      "7789/7789 [==============================] - 3s 374us/step - loss: 0.2022 - acc: 0.9216 - val_loss: 0.2624 - val_acc: 0.9134\n",
      "Epoch 91/250\n",
      "7789/7789 [==============================] - 3s 375us/step - loss: 0.2034 - acc: 0.9231 - val_loss: 0.2623 - val_acc: 0.9145\n",
      "Epoch 92/250\n",
      "7789/7789 [==============================] - 3s 378us/step - loss: 0.2045 - acc: 0.9189 - val_loss: 0.2620 - val_acc: 0.9145\n",
      "Epoch 93/250\n",
      "7789/7789 [==============================] - 3s 373us/step - loss: 0.2006 - acc: 0.9208 - val_loss: 0.2618 - val_acc: 0.9134\n",
      "Epoch 94/250\n",
      "7789/7789 [==============================] - 3s 371us/step - loss: 0.1910 - acc: 0.9204 - val_loss: 0.2539 - val_acc: 0.9145\n",
      "Epoch 95/250\n",
      "7789/7789 [==============================] - 3s 373us/step - loss: 0.1982 - acc: 0.9219 - val_loss: 0.2525 - val_acc: 0.9134\n",
      "Epoch 96/250\n",
      "7789/7789 [==============================] - 3s 371us/step - loss: 0.2021 - acc: 0.9223 - val_loss: 0.2525 - val_acc: 0.9134\n",
      "Epoch 97/250\n",
      "7789/7789 [==============================] - 3s 375us/step - loss: 0.2020 - acc: 0.9221 - val_loss: 0.2559 - val_acc: 0.9134\n",
      "Epoch 98/250\n",
      "7789/7789 [==============================] - 3s 372us/step - loss: 0.1932 - acc: 0.9231 - val_loss: 0.2515 - val_acc: 0.9134\n",
      "Epoch 99/250\n",
      "7789/7789 [==============================] - 3s 369us/step - loss: 0.1946 - acc: 0.9226 - val_loss: 0.2513 - val_acc: 0.9134\n",
      "Epoch 100/250\n",
      "7789/7789 [==============================] - 3s 370us/step - loss: 0.1931 - acc: 0.9237 - val_loss: 0.2514 - val_acc: 0.9134\n",
      "Epoch 101/250\n",
      "7789/7789 [==============================] - 3s 372us/step - loss: 0.2013 - acc: 0.9214 - val_loss: 0.2528 - val_acc: 0.9145\n",
      "Epoch 102/250\n",
      "7789/7789 [==============================] - 3s 372us/step - loss: 0.1921 - acc: 0.9246 - val_loss: 0.2574 - val_acc: 0.9169\n",
      "Epoch 103/250\n",
      "7789/7789 [==============================] - 3s 373us/step - loss: 0.1946 - acc: 0.9226 - val_loss: 0.2522 - val_acc: 0.9157\n",
      "Epoch 104/250\n",
      "7789/7789 [==============================] - 3s 378us/step - loss: 0.1989 - acc: 0.9213 - val_loss: 0.2507 - val_acc: 0.9157\n",
      "Epoch 00104: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\strix\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7789 samples, validate on 866 samples\n",
      "Epoch 1/250\n",
      "7789/7789 [==============================] - 7s 872us/step - loss: 1.0653 - acc: 0.7816 - val_loss: 0.7429 - val_acc: 0.8176\n",
      "Epoch 2/250\n",
      "7789/7789 [==============================] - 5s 705us/step - loss: 0.9035 - acc: 0.8049 - val_loss: 0.6763 - val_acc: 0.8268\n",
      "Epoch 3/250\n",
      "7789/7789 [==============================] - 5s 654us/step - loss: 0.8031 - acc: 0.8199 - val_loss: 0.6567 - val_acc: 0.8303\n",
      "Epoch 4/250\n",
      "7789/7789 [==============================] - 5s 623us/step - loss: 0.7269 - acc: 0.8299 - val_loss: 0.6093 - val_acc: 0.8441\n",
      "Epoch 5/250\n",
      "7789/7789 [==============================] - 5s 604us/step - loss: 0.6822 - acc: 0.8439 - val_loss: 0.5754 - val_acc: 0.8522\n",
      "Epoch 6/250\n",
      "7789/7789 [==============================] - 5s 585us/step - loss: 0.6096 - acc: 0.8482 - val_loss: 0.5351 - val_acc: 0.8545\n",
      "Epoch 7/250\n",
      "7789/7789 [==============================] - 4s 574us/step - loss: 0.5395 - acc: 0.8611 - val_loss: 0.5099 - val_acc: 0.8568\n",
      "Epoch 8/250\n",
      "7789/7789 [==============================] - 4s 573us/step - loss: 0.5441 - acc: 0.8619 - val_loss: 0.4992 - val_acc: 0.8603\n",
      "Epoch 9/250\n",
      "7789/7789 [==============================] - 4s 551us/step - loss: 0.5017 - acc: 0.8739 - val_loss: 0.4809 - val_acc: 0.8637\n",
      "Epoch 10/250\n",
      "7789/7789 [==============================] - 4s 546us/step - loss: 0.4815 - acc: 0.8816 - val_loss: 0.4745 - val_acc: 0.8718\n",
      "Epoch 11/250\n",
      "7789/7789 [==============================] - 4s 537us/step - loss: 0.4838 - acc: 0.8796 - val_loss: 0.4700 - val_acc: 0.8730\n",
      "Epoch 12/250\n",
      "7789/7789 [==============================] - 4s 528us/step - loss: 0.4346 - acc: 0.8839 - val_loss: 0.4667 - val_acc: 0.8718\n",
      "Epoch 13/250\n",
      "7789/7789 [==============================] - 4s 524us/step - loss: 0.4409 - acc: 0.8880 - val_loss: 0.4643 - val_acc: 0.8741\n",
      "Epoch 14/250\n",
      "7789/7789 [==============================] - 4s 544us/step - loss: 0.4056 - acc: 0.8892 - val_loss: 0.4625 - val_acc: 0.8764\n",
      "Epoch 15/250\n",
      "7789/7789 [==============================] - 4s 546us/step - loss: 0.3861 - acc: 0.8919 - val_loss: 0.4612 - val_acc: 0.8776\n",
      "Epoch 16/250\n",
      "7789/7789 [==============================] - 4s 519us/step - loss: 0.3824 - acc: 0.8956 - val_loss: 0.4601 - val_acc: 0.8799\n",
      "Epoch 17/250\n",
      "7789/7789 [==============================] - 4s 563us/step - loss: 0.3744 - acc: 0.8981 - val_loss: 0.4592 - val_acc: 0.8799\n",
      "Epoch 18/250\n",
      "7789/7789 [==============================] - 4s 508us/step - loss: 0.3663 - acc: 0.8975 - val_loss: 0.4584 - val_acc: 0.8799\n",
      "Epoch 19/250\n",
      "7789/7789 [==============================] - 4s 567us/step - loss: 0.3602 - acc: 0.8979 - val_loss: 0.4380 - val_acc: 0.8799\n",
      "Epoch 20/250\n",
      "7789/7789 [==============================] - 5s 587us/step - loss: 0.3570 - acc: 0.9002 - val_loss: 0.4334 - val_acc: 0.8788\n",
      "Epoch 21/250\n",
      "7789/7789 [==============================] - 4s 514us/step - loss: 0.3423 - acc: 0.9042 - val_loss: 0.4315 - val_acc: 0.8799\n",
      "Epoch 22/250\n",
      "7789/7789 [==============================] - 4s 509us/step - loss: 0.3245 - acc: 0.9049 - val_loss: 0.4303 - val_acc: 0.8811\n",
      "Epoch 23/250\n",
      "7789/7789 [==============================] - 4s 500us/step - loss: 0.3323 - acc: 0.9081 - val_loss: 0.4294 - val_acc: 0.8834\n",
      "Epoch 24/250\n",
      "7789/7789 [==============================] - 4s 502us/step - loss: 0.3086 - acc: 0.9091 - val_loss: 0.4285 - val_acc: 0.8834\n",
      "Epoch 25/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.3056 - acc: 0.9072 - val_loss: 0.4277 - val_acc: 0.8845\n",
      "Epoch 26/250\n",
      "7789/7789 [==============================] - 4s 497us/step - loss: 0.2985 - acc: 0.9103 - val_loss: 0.4268 - val_acc: 0.8868\n",
      "Epoch 27/250\n",
      "7789/7789 [==============================] - 4s 504us/step - loss: 0.2857 - acc: 0.9127 - val_loss: 0.4259 - val_acc: 0.8880\n",
      "Epoch 28/250\n",
      "7789/7789 [==============================] - 4s 518us/step - loss: 0.2844 - acc: 0.9130 - val_loss: 0.4138 - val_acc: 0.8880\n",
      "Epoch 29/250\n",
      "7789/7789 [==============================] - 4s 496us/step - loss: 0.2847 - acc: 0.9133 - val_loss: 0.4120 - val_acc: 0.8880\n",
      "Epoch 30/250\n",
      "7789/7789 [==============================] - 4s 494us/step - loss: 0.2852 - acc: 0.9142 - val_loss: 0.4106 - val_acc: 0.8880\n",
      "Epoch 31/250\n",
      "7789/7789 [==============================] - 4s 502us/step - loss: 0.2783 - acc: 0.9172 - val_loss: 0.4094 - val_acc: 0.8880\n",
      "Epoch 32/250\n",
      "7789/7789 [==============================] - 4s 510us/step - loss: 0.2668 - acc: 0.9210 - val_loss: 0.3981 - val_acc: 0.8880\n",
      "Epoch 33/250\n",
      "7789/7789 [==============================] - 4s 497us/step - loss: 0.2617 - acc: 0.9180 - val_loss: 0.3962 - val_acc: 0.8880\n",
      "Epoch 34/250\n",
      "7789/7789 [==============================] - 4s 496us/step - loss: 0.2616 - acc: 0.9192 - val_loss: 0.3947 - val_acc: 0.8880\n",
      "Epoch 35/250\n",
      "7789/7789 [==============================] - 4s 505us/step - loss: 0.2520 - acc: 0.9235 - val_loss: 0.3933 - val_acc: 0.8891\n",
      "Epoch 36/250\n",
      "7789/7789 [==============================] - 4s 499us/step - loss: 0.2548 - acc: 0.9248 - val_loss: 0.3827 - val_acc: 0.8903\n",
      "Epoch 37/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.2571 - acc: 0.9249 - val_loss: 0.3807 - val_acc: 0.8903\n",
      "Epoch 38/250\n",
      "7789/7789 [==============================] - 4s 493us/step - loss: 0.2534 - acc: 0.9244 - val_loss: 0.3791 - val_acc: 0.8903\n",
      "Epoch 39/250\n",
      "7789/7789 [==============================] - 4s 513us/step - loss: 0.2465 - acc: 0.9287 - val_loss: 0.3778 - val_acc: 0.8903\n",
      "Epoch 40/250\n",
      "7789/7789 [==============================] - 4s 522us/step - loss: 0.2359 - acc: 0.9264 - val_loss: 0.3767 - val_acc: 0.8891\n",
      "Epoch 41/250\n",
      "7789/7789 [==============================] - 4s 494us/step - loss: 0.2436 - acc: 0.9255 - val_loss: 0.3759 - val_acc: 0.8915\n",
      "Epoch 42/250\n",
      "7789/7789 [==============================] - 4s 499us/step - loss: 0.2336 - acc: 0.9290 - val_loss: 0.3842 - val_acc: 0.8926\n",
      "Epoch 43/250\n",
      "7789/7789 [==============================] - 4s 511us/step - loss: 0.2375 - acc: 0.9321 - val_loss: 0.3827 - val_acc: 0.8926\n",
      "Epoch 44/250\n",
      "7789/7789 [==============================] - 4s 506us/step - loss: 0.2292 - acc: 0.9316 - val_loss: 0.3813 - val_acc: 0.8938\n",
      "Epoch 45/250\n",
      "7789/7789 [==============================] - 4s 491us/step - loss: 0.2241 - acc: 0.9332 - val_loss: 0.3800 - val_acc: 0.8938\n",
      "Epoch 46/250\n",
      "7789/7789 [==============================] - 11s 1ms/step - loss: 0.2232 - acc: 0.9345 - val_loss: 0.3787 - val_acc: 0.8938\n",
      "Epoch 47/250\n",
      "7789/7789 [==============================] - 13s 2ms/step - loss: 0.2084 - acc: 0.9354 - val_loss: 0.3774 - val_acc: 0.8938\n",
      "Epoch 48/250\n",
      "7789/7789 [==============================] - 13s 2ms/step - loss: 0.2138 - acc: 0.9336 - val_loss: 0.3761 - val_acc: 0.8938\n",
      "Epoch 49/250\n",
      "7789/7789 [==============================] - 10s 1ms/step - loss: 0.2190 - acc: 0.9368 - val_loss: 0.3749 - val_acc: 0.8949\n",
      "Epoch 50/250\n",
      "7789/7789 [==============================] - 6s 708us/step - loss: 0.2113 - acc: 0.9398 - val_loss: 0.3738 - val_acc: 0.8972\n",
      "Epoch 51/250\n",
      "7789/7789 [==============================] - 6s 727us/step - loss: 0.2107 - acc: 0.9384 - val_loss: 0.3726 - val_acc: 0.8972\n",
      "Epoch 52/250\n",
      "7789/7789 [==============================] - 5s 646us/step - loss: 0.2091 - acc: 0.9399 - val_loss: 0.3714 - val_acc: 0.8984\n",
      "Epoch 53/250\n",
      "7789/7789 [==============================] - 5s 631us/step - loss: 0.2019 - acc: 0.9381 - val_loss: 0.3704 - val_acc: 0.8984\n",
      "Epoch 54/250\n",
      "7789/7789 [==============================] - 5s 667us/step - loss: 0.2017 - acc: 0.9416 - val_loss: 0.3696 - val_acc: 0.8984\n",
      "Epoch 55/250\n",
      "7789/7789 [==============================] - 5s 597us/step - loss: 0.2029 - acc: 0.9395 - val_loss: 0.3690 - val_acc: 0.8995\n",
      "Epoch 56/250\n",
      "7789/7789 [==============================] - 5s 601us/step - loss: 0.1947 - acc: 0.9415 - val_loss: 0.3690 - val_acc: 0.8995\n",
      "Epoch 57/250\n",
      "7789/7789 [==============================] - 4s 562us/step - loss: 0.1978 - acc: 0.9399 - val_loss: 0.3774 - val_acc: 0.9007\n",
      "Epoch 58/250\n",
      "7789/7789 [==============================] - 4s 555us/step - loss: 0.1891 - acc: 0.9427 - val_loss: 0.3866 - val_acc: 0.9018\n",
      "Epoch 59/250\n",
      "7789/7789 [==============================] - 4s 534us/step - loss: 0.1895 - acc: 0.9436 - val_loss: 0.3854 - val_acc: 0.9018\n",
      "Epoch 60/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7789/7789 [==============================] - 4s 530us/step - loss: 0.1905 - acc: 0.9424 - val_loss: 0.3841 - val_acc: 0.9053\n",
      "Epoch 61/250\n",
      "7789/7789 [==============================] - 4s 519us/step - loss: 0.1871 - acc: 0.9436 - val_loss: 0.3829 - val_acc: 0.9053\n",
      "Epoch 62/250\n",
      "7789/7789 [==============================] - 4s 516us/step - loss: 0.1768 - acc: 0.9457 - val_loss: 0.3820 - val_acc: 0.9076\n",
      "Epoch 63/250\n",
      "7789/7789 [==============================] - 4s 515us/step - loss: 0.1806 - acc: 0.9444 - val_loss: 0.3716 - val_acc: 0.9088\n",
      "Epoch 64/250\n",
      "7789/7789 [==============================] - 4s 509us/step - loss: 0.1819 - acc: 0.9451 - val_loss: 0.3695 - val_acc: 0.9088\n",
      "Epoch 65/250\n",
      "7789/7789 [==============================] - 4s 506us/step - loss: 0.1758 - acc: 0.9462 - val_loss: 0.3681 - val_acc: 0.9088\n",
      "Epoch 66/250\n",
      "7789/7789 [==============================] - 4s 498us/step - loss: 0.1739 - acc: 0.9484 - val_loss: 0.3670 - val_acc: 0.9111\n",
      "Epoch 67/250\n",
      "7789/7789 [==============================] - 4s 493us/step - loss: 0.1776 - acc: 0.9462 - val_loss: 0.3659 - val_acc: 0.9122\n",
      "Epoch 68/250\n",
      "7789/7789 [==============================] - 4s 500us/step - loss: 0.1708 - acc: 0.9485 - val_loss: 0.3650 - val_acc: 0.9122\n",
      "Epoch 69/250\n",
      "7789/7789 [==============================] - 4s 499us/step - loss: 0.1666 - acc: 0.9506 - val_loss: 0.3641 - val_acc: 0.9122\n",
      "Epoch 70/250\n",
      "7789/7789 [==============================] - 4s 504us/step - loss: 0.1687 - acc: 0.9490 - val_loss: 0.3634 - val_acc: 0.9122\n",
      "Epoch 71/250\n",
      "7789/7789 [==============================] - 4s 500us/step - loss: 0.1674 - acc: 0.9494 - val_loss: 0.3627 - val_acc: 0.9122\n",
      "Epoch 72/250\n",
      "7789/7789 [==============================] - 4s 512us/step - loss: 0.1677 - acc: 0.9497 - val_loss: 0.3621 - val_acc: 0.9122\n",
      "Epoch 73/250\n",
      "7789/7789 [==============================] - 4s 551us/step - loss: 0.1666 - acc: 0.9519 - val_loss: 0.3616 - val_acc: 0.9122\n",
      "Epoch 74/250\n",
      "7789/7789 [==============================] - 4s 575us/step - loss: 0.1590 - acc: 0.9535 - val_loss: 0.3612 - val_acc: 0.9122\n",
      "Epoch 75/250\n",
      "7789/7789 [==============================] - 4s 554us/step - loss: 0.1601 - acc: 0.9522 - val_loss: 0.3612 - val_acc: 0.9134\n",
      "Epoch 76/250\n",
      "7789/7789 [==============================] - 4s 524us/step - loss: 0.1554 - acc: 0.9549 - val_loss: 0.3623 - val_acc: 0.9134\n",
      "Epoch 77/250\n",
      "7789/7789 [==============================] - 4s 509us/step - loss: 0.1573 - acc: 0.9524 - val_loss: 0.3705 - val_acc: 0.9145\n",
      "Epoch 78/250\n",
      "7789/7789 [==============================] - 4s 535us/step - loss: 0.1556 - acc: 0.9531 - val_loss: 0.3700 - val_acc: 0.9145\n",
      "Epoch 79/250\n",
      "7789/7789 [==============================] - 4s 552us/step - loss: 0.1548 - acc: 0.9542 - val_loss: 0.3697 - val_acc: 0.9145\n",
      "Epoch 80/250\n",
      "7789/7789 [==============================] - 4s 541us/step - loss: 0.1482 - acc: 0.9561 - val_loss: 0.3696 - val_acc: 0.9145\n",
      "Epoch 81/250\n",
      "7789/7789 [==============================] - 4s 531us/step - loss: 0.1490 - acc: 0.9542 - val_loss: 0.3702 - val_acc: 0.9157\n",
      "Epoch 82/250\n",
      "7789/7789 [==============================] - 4s 528us/step - loss: 0.1485 - acc: 0.9552 - val_loss: 0.3788 - val_acc: 0.9157\n",
      "Epoch 83/250\n",
      "7789/7789 [==============================] - 4s 523us/step - loss: 0.1427 - acc: 0.9570 - val_loss: 0.3783 - val_acc: 0.9157\n",
      "Epoch 84/250\n",
      "7789/7789 [==============================] - 4s 525us/step - loss: 0.1393 - acc: 0.9580 - val_loss: 0.3780 - val_acc: 0.9157\n",
      "Epoch 85/250\n",
      "7789/7789 [==============================] - 4s 517us/step - loss: 0.1418 - acc: 0.9579 - val_loss: 0.3777 - val_acc: 0.9157\n",
      "Epoch 86/250\n",
      "7789/7789 [==============================] - 4s 530us/step - loss: 0.1432 - acc: 0.9569 - val_loss: 0.3776 - val_acc: 0.9169\n",
      "Epoch 87/250\n",
      "7789/7789 [==============================] - 4s 534us/step - loss: 0.1379 - acc: 0.9583 - val_loss: 0.3779 - val_acc: 0.9157\n",
      "Epoch 88/250\n",
      "7789/7789 [==============================] - 4s 528us/step - loss: 0.1383 - acc: 0.9567 - val_loss: 0.3876 - val_acc: 0.9169\n",
      "Epoch 89/250\n",
      "7789/7789 [==============================] - 4s 532us/step - loss: 0.1414 - acc: 0.9598 - val_loss: 0.3871 - val_acc: 0.9180\n",
      "Epoch 90/250\n",
      "7789/7789 [==============================] - 4s 530us/step - loss: 0.1313 - acc: 0.9576 - val_loss: 0.3867 - val_acc: 0.9180\n",
      "Epoch 91/250\n",
      "7789/7789 [==============================] - 4s 530us/step - loss: 0.1376 - acc: 0.9623 - val_loss: 0.3863 - val_acc: 0.9157\n",
      "Epoch 92/250\n",
      "7789/7789 [==============================] - 4s 524us/step - loss: 0.1360 - acc: 0.9614 - val_loss: 0.3859 - val_acc: 0.9157\n",
      "Epoch 93/250\n",
      "7789/7789 [==============================] - 4s 520us/step - loss: 0.1272 - acc: 0.9599 - val_loss: 0.3856 - val_acc: 0.9157\n",
      "Epoch 94/250\n",
      "7789/7789 [==============================] - 4s 536us/step - loss: 0.1333 - acc: 0.9614 - val_loss: 0.3854 - val_acc: 0.9169\n",
      "Epoch 95/250\n",
      "7789/7789 [==============================] - 4s 523us/step - loss: 0.1281 - acc: 0.9620 - val_loss: 0.3853 - val_acc: 0.9169\n",
      "Epoch 96/250\n",
      "7789/7789 [==============================] - 4s 528us/step - loss: 0.1283 - acc: 0.9605 - val_loss: 0.3854 - val_acc: 0.9169\n",
      "Epoch 97/250\n",
      "7789/7789 [==============================] - 4s 529us/step - loss: 0.1246 - acc: 0.9620 - val_loss: 0.3856 - val_acc: 0.9169\n",
      "Epoch 98/250\n",
      "7789/7789 [==============================] - 4s 525us/step - loss: 0.1268 - acc: 0.9615 - val_loss: 0.3861 - val_acc: 0.9169\n",
      "Epoch 99/250\n",
      "7789/7789 [==============================] - 4s 532us/step - loss: 0.1270 - acc: 0.9628 - val_loss: 0.3873 - val_acc: 0.9169\n",
      "Epoch 100/250\n",
      "7789/7789 [==============================] - 8s 1ms/step - loss: 0.1228 - acc: 0.9644 - val_loss: 0.3995 - val_acc: 0.9169\n",
      "Epoch 101/250\n",
      "7789/7789 [==============================] - 14s 2ms/step - loss: 0.1194 - acc: 0.9633 - val_loss: 0.4089 - val_acc: 0.9145\n",
      "Epoch 102/250\n",
      "7789/7789 [==============================] - 13s 2ms/step - loss: 0.1221 - acc: 0.9638 - val_loss: 0.4085 - val_acc: 0.9145\n",
      "Epoch 103/250\n",
      "7789/7789 [==============================] - 12s 2ms/step - loss: 0.1189 - acc: 0.9641 - val_loss: 0.4081 - val_acc: 0.9157\n",
      "Epoch 104/250\n",
      "7789/7789 [==============================] - 5s 696us/step - loss: 0.1185 - acc: 0.9647 - val_loss: 0.4078 - val_acc: 0.9157\n",
      "Epoch 105/250\n",
      "7789/7789 [==============================] - 5s 659us/step - loss: 0.1135 - acc: 0.9641 - val_loss: 0.4074 - val_acc: 0.9157\n",
      "Epoch 106/250\n",
      "7789/7789 [==============================] - 5s 634us/step - loss: 0.1169 - acc: 0.9647 - val_loss: 0.4071 - val_acc: 0.9157\n",
      "Epoch 107/250\n",
      "7789/7789 [==============================] - 5s 612us/step - loss: 0.1168 - acc: 0.9652 - val_loss: 0.4068 - val_acc: 0.9145\n",
      "Epoch 108/250\n",
      "7789/7789 [==============================] - 5s 610us/step - loss: 0.1180 - acc: 0.9653 - val_loss: 0.4066 - val_acc: 0.9145\n",
      "Epoch 109/250\n",
      "7789/7789 [==============================] - 5s 615us/step - loss: 0.1114 - acc: 0.9670 - val_loss: 0.4064 - val_acc: 0.9145\n",
      "Epoch 110/250\n",
      "7789/7789 [==============================] - 5s 583us/step - loss: 0.1121 - acc: 0.9660 - val_loss: 0.4062 - val_acc: 0.9145\n",
      "Epoch 111/250\n",
      "7789/7789 [==============================] - 4s 562us/step - loss: 0.1101 - acc: 0.9674 - val_loss: 0.4060 - val_acc: 0.9145\n",
      "Epoch 112/250\n",
      "7789/7789 [==============================] - 4s 553us/step - loss: 0.1059 - acc: 0.9671 - val_loss: 0.4059 - val_acc: 0.9145\n",
      "Epoch 113/250\n",
      "7789/7789 [==============================] - 4s 552us/step - loss: 0.1054 - acc: 0.9680 - val_loss: 0.4057 - val_acc: 0.9145\n",
      "Epoch 114/250\n",
      "7789/7789 [==============================] - 4s 556us/step - loss: 0.1075 - acc: 0.9691 - val_loss: 0.4055 - val_acc: 0.9145\n",
      "Epoch 115/250\n",
      "7789/7789 [==============================] - 4s 530us/step - loss: 0.1034 - acc: 0.9684 - val_loss: 0.4054 - val_acc: 0.9145\n",
      "Epoch 116/250\n",
      "7789/7789 [==============================] - 4s 527us/step - loss: 0.1009 - acc: 0.9688 - val_loss: 0.4054 - val_acc: 0.9145\n",
      "Epoch 117/250\n",
      "7789/7789 [==============================] - 4s 574us/step - loss: 0.1021 - acc: 0.9671 - val_loss: 0.4053 - val_acc: 0.9145\n",
      "Epoch 118/250\n",
      "7789/7789 [==============================] - 4s 570us/step - loss: 0.0972 - acc: 0.9698 - val_loss: 0.4053 - val_acc: 0.9145\n",
      "Epoch 119/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7789/7789 [==============================] - 4s 533us/step - loss: 0.0962 - acc: 0.9711 - val_loss: 0.4053 - val_acc: 0.9145\n",
      "Epoch 120/250\n",
      "7789/7789 [==============================] - 4s 548us/step - loss: 0.1022 - acc: 0.9703 - val_loss: 0.4053 - val_acc: 0.9145\n",
      "Epoch 121/250\n",
      "7789/7789 [==============================] - 4s 524us/step - loss: 0.0988 - acc: 0.9694 - val_loss: 0.4053 - val_acc: 0.9157\n",
      "Epoch 122/250\n",
      "7789/7789 [==============================] - 4s 503us/step - loss: 0.0990 - acc: 0.9712 - val_loss: 0.4054 - val_acc: 0.9169\n",
      "Epoch 123/250\n",
      "7789/7789 [==============================] - 4s 495us/step - loss: 0.0934 - acc: 0.9714 - val_loss: 0.4055 - val_acc: 0.9169\n",
      "Epoch 124/250\n",
      "7789/7789 [==============================] - 4s 495us/step - loss: 0.0969 - acc: 0.9718 - val_loss: 0.4057 - val_acc: 0.9169\n",
      "Epoch 125/250\n",
      "7789/7789 [==============================] - 4s 498us/step - loss: 0.0952 - acc: 0.9709 - val_loss: 0.4059 - val_acc: 0.9169\n",
      "Epoch 00125: early stopping\n"
     ]
    }
   ],
   "source": [
    "Classifier.refine(trainX, trainY)\n",
    "test_predictions = Classifier.predict(testX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.913\n",
      "Test MCC:  0.728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2186,  113],\n",
       "       [ 138,  449]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test Accuracy:  {:.3f}'.format(sklearn.metrics.accuracy_score(testY, test_predictions)))\n",
    "print('Test MCC:  {:.3f}'.format(sklearn.metrics.matthews_corrcoef(testY, test_predictions)))\n",
    "sklearn.metrics.confusion_matrix(testY, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have accuracies of over 90%! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW: 0.895\n",
      "LSTM: 0.837\n",
      "Pre-trained embedding: 0.889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ensembled': 0.913028413028413,\n",
       " 'BoW': 0.8946638946638946,\n",
       " 'LSTM': 0.8374913374913375,\n",
       " 'Glove': 0.8891198891198892}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.21.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
