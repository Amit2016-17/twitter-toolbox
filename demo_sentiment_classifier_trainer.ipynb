{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from twitter_nlp_toolkit.tweet_sentiment_classifier import tweet_sentiment_classifier\n",
    "from twitter_nlp_toolkit.file_fetcher import file_fetcher\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 1 # Fraction of data to train on\n",
    "model_name = 'model_test_05'\n",
    "redownload=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we download pre-trained models and a validation dataset. The models have been trained on the Sentiment140 dataset, taken form here: https://www.kaggle.com/kazanova/sentiment140\n",
    "\n",
    "The validation data is hand-labeled airline customer feedback taken from https://www.figure-eight.com/data-for-everyone/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "if redownload: \n",
    "    downloader = file_fetcher.downloader(using_notebook=True)\n",
    "    # Validation data\n",
    "    downloader.download_file('https://www.dropbox.com/s/440m6x07bjg6c0h/Tweets.zip?dl=1',\"Tweets.zip\")\n",
    "    \n",
    "    # Compressed model\n",
    "    # Note that this model has only been trained on 5% of the training data\n",
    "    # Update when better-trained model is available\n",
    "    downloader.download_file(\"https://www.dropbox.com/s/i88eqlja56xncyx/model_test_05.zip?dl=1\",\"model_test_05.zip\")\n",
    "    \n",
    "    # Extract all the contents of zip file in current directory\n",
    "    with ZipFile(model_name + '.zip', 'r') as zipObj:\n",
    "        zipObj.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation data\n",
    "\n",
    "test_data = pd.read_csv('Tweets.zip', header=0, names=['Index', 'Sentiment', 'Sentiment_confidence',\n",
    "                                                                'Negative_reason', 'Negative_reason_confidence',\n",
    "                                                                'Airline', 'Airline_sentiment_gold', 'Handle',\n",
    "                                                                'Negative_reason_gold', 'Retweet_count', 'Text',\n",
    "                                                                'Tweet_coord', 'Time', 'Location', 'Timezone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unlabeled test data\n",
    "\n",
    "test_data['Labels'] = (test_data['Sentiment'] == 'positive') * 2\n",
    "test_data['Labels'] = test_data['Labels'] + (test_data['Sentiment'] == 'neutral') * 1\n",
    "test_data['Labels'] = test_data['Labels'] / 2\n",
    "\n",
    "test_data.set_index('Labels')\n",
    "test_data = test_data[test_data.Labels != 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW model loaded successfully\n",
      "LSTM model loaded successfully\n",
      "Pre-trained embedding model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Executing this cell takes about 30s on a laptop\n",
    "\n",
    "Classifier = tweet_sentiment_classifier.SentimentAnalyzer()\n",
    "Classifier.load_models(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We santiy check the models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier.predict(['I am happy', 'I am sad', 'I am cheerful', 'I am mad'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing this cell takes several minuites on a laptop\n",
    "\n",
    "predictions = Classifier.predict(test_data['Text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the model on an airline customer feedback dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.785\n",
      "Test MCC:  0.538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[6974, 2204],\n",
       "       [ 273, 2090]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test Accuracy:  {:.3f}'.format(sklearn.metrics.accuracy_score(test_data['Labels'], predictions)))\n",
    "print('Test MCC:  {:.3f}'.format(sklearn.metrics.matthews_corrcoef(test_data['Labels'], predictions)))\n",
    "sklearn.metrics.confusion_matrix(test_data['Labels'], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have accuracy of just under 80%.\n",
    "\n",
    "To improve our accuracy, we can refine the model on our airline data. The early stopping procedure (enabled by default to use 10% of the training data for validation) should prevent overfitting. We withold 20% for our own validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = sklearn.model_selection.train_test_split(test_data['Text'], test_data['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7789 samples, validate on 866 samples\n",
      "Epoch 1/250\n",
      "7789/7789 [==============================] - 3s 443us/step - loss: 0.4227 - acc: 0.8224 - val_loss: 0.2788 - val_acc: 0.8926\n",
      "Epoch 2/250\n",
      "7789/7789 [==============================] - 3s 371us/step - loss: 0.3639 - acc: 0.8533 - val_loss: 0.2387 - val_acc: 0.9111\n",
      "Epoch 3/250\n",
      "7789/7789 [==============================] - 3s 368us/step - loss: 0.3280 - acc: 0.8776 - val_loss: 0.2124 - val_acc: 0.9273\n",
      "Epoch 4/250\n",
      "7789/7789 [==============================] - 3s 364us/step - loss: 0.3128 - acc: 0.8852 - val_loss: 0.2008 - val_acc: 0.9284\n",
      "Epoch 5/250\n",
      "7789/7789 [==============================] - 3s 380us/step - loss: 0.3039 - acc: 0.8907 - val_loss: 0.1998 - val_acc: 0.9249\n",
      "Epoch 6/250\n",
      "7789/7789 [==============================] - 3s 370us/step - loss: 0.3093 - acc: 0.8918 - val_loss: 0.2153 - val_acc: 0.9203\n",
      "Epoch 7/250\n",
      "7789/7789 [==============================] - 3s 370us/step - loss: 0.3379 - acc: 0.8871 - val_loss: 0.2173 - val_acc: 0.9203\n",
      "Epoch 8/250\n",
      "7789/7789 [==============================] - 3s 369us/step - loss: 0.3452 - acc: 0.8896 - val_loss: 0.2139 - val_acc: 0.9215\n",
      "Epoch 9/250\n",
      "7789/7789 [==============================] - 3s 387us/step - loss: 0.3309 - acc: 0.8898 - val_loss: 0.2093 - val_acc: 0.9215\n",
      "Epoch 10/250\n",
      "7789/7789 [==============================] - 3s 374us/step - loss: 0.3152 - acc: 0.8913 - val_loss: 0.1939 - val_acc: 0.9249\n",
      "Epoch 11/250\n",
      "7789/7789 [==============================] - 3s 363us/step - loss: 0.2942 - acc: 0.8931 - val_loss: 0.1903 - val_acc: 0.9284\n",
      "Epoch 12/250\n",
      "7789/7789 [==============================] - 3s 367us/step - loss: 0.2933 - acc: 0.8965 - val_loss: 0.1899 - val_acc: 0.9307\n",
      "Epoch 13/250\n",
      "7789/7789 [==============================] - 3s 371us/step - loss: 0.2807 - acc: 0.8969 - val_loss: 0.1911 - val_acc: 0.9307\n",
      "Epoch 14/250\n",
      "7789/7789 [==============================] - 3s 369us/step - loss: 0.2716 - acc: 0.8968 - val_loss: 0.1926 - val_acc: 0.9307\n",
      "Epoch 15/250\n",
      "7789/7789 [==============================] - 3s 392us/step - loss: 0.2654 - acc: 0.8996 - val_loss: 0.1938 - val_acc: 0.9307\n",
      "Epoch 16/250\n",
      "7789/7789 [==============================] - 3s 367us/step - loss: 0.2662 - acc: 0.9008 - val_loss: 0.1942 - val_acc: 0.9296\n",
      "Epoch 17/250\n",
      "7789/7789 [==============================] - 3s 364us/step - loss: 0.2690 - acc: 0.9014 - val_loss: 0.1936 - val_acc: 0.9330\n",
      "Epoch 18/250\n",
      "7789/7789 [==============================] - 3s 363us/step - loss: 0.2664 - acc: 0.9017 - val_loss: 0.1920 - val_acc: 0.9342\n",
      "Epoch 19/250\n",
      "7789/7789 [==============================] - 3s 354us/step - loss: 0.2667 - acc: 0.9053 - val_loss: 0.1893 - val_acc: 0.9330\n",
      "Epoch 20/250\n",
      "7789/7789 [==============================] - 3s 384us/step - loss: 0.2696 - acc: 0.9036 - val_loss: 0.1858 - val_acc: 0.9319\n",
      "Epoch 21/250\n",
      "7789/7789 [==============================] - 3s 376us/step - loss: 0.2580 - acc: 0.9026 - val_loss: 0.1819 - val_acc: 0.9342\n",
      "Epoch 22/250\n",
      "7789/7789 [==============================] - 3s 369us/step - loss: 0.2590 - acc: 0.9040 - val_loss: 0.1783 - val_acc: 0.9330\n",
      "Epoch 23/250\n",
      "7789/7789 [==============================] - 3s 364us/step - loss: 0.2589 - acc: 0.9032 - val_loss: 0.1744 - val_acc: 0.9319\n",
      "Epoch 24/250\n",
      "7789/7789 [==============================] - 3s 362us/step - loss: 0.2589 - acc: 0.9042 - val_loss: 0.1706 - val_acc: 0.9330\n",
      "Epoch 25/250\n",
      "7789/7789 [==============================] - 3s 364us/step - loss: 0.2503 - acc: 0.9056 - val_loss: 0.1678 - val_acc: 0.9330\n",
      "Epoch 26/250\n",
      "7789/7789 [==============================] - 3s 363us/step - loss: 0.2500 - acc: 0.9091 - val_loss: 0.1658 - val_acc: 0.9342\n",
      "Epoch 27/250\n",
      "7789/7789 [==============================] - 3s 378us/step - loss: 0.2472 - acc: 0.9064 - val_loss: 0.1664 - val_acc: 0.9353\n",
      "Epoch 28/250\n",
      "7789/7789 [==============================] - 3s 378us/step - loss: 0.2398 - acc: 0.9073 - val_loss: 0.1741 - val_acc: 0.9365\n",
      "Epoch 29/250\n",
      "7789/7789 [==============================] - 3s 385us/step - loss: 0.2503 - acc: 0.9092 - val_loss: 0.1728 - val_acc: 0.9365\n",
      "Epoch 30/250\n",
      "7789/7789 [==============================] - 3s 392us/step - loss: 0.2574 - acc: 0.9074 - val_loss: 0.1718 - val_acc: 0.9365\n",
      "Epoch 31/250\n",
      "7789/7789 [==============================] - 3s 377us/step - loss: 0.2516 - acc: 0.9074 - val_loss: 0.1709 - val_acc: 0.9376\n",
      "Epoch 32/250\n",
      "7789/7789 [==============================] - 3s 356us/step - loss: 0.2486 - acc: 0.9095 - val_loss: 0.1701 - val_acc: 0.9388\n",
      "Epoch 33/250\n",
      "7789/7789 [==============================] - 3s 375us/step - loss: 0.2477 - acc: 0.9110 - val_loss: 0.1698 - val_acc: 0.9376\n",
      "Epoch 34/250\n",
      "7789/7789 [==============================] - 3s 372us/step - loss: 0.2444 - acc: 0.9077 - val_loss: 0.1608 - val_acc: 0.9376\n",
      "Epoch 35/250\n",
      "7789/7789 [==============================] - 3s 372us/step - loss: 0.2389 - acc: 0.9094 - val_loss: 0.1598 - val_acc: 0.9376\n",
      "Epoch 36/250\n",
      "7789/7789 [==============================] - 3s 359us/step - loss: 0.2349 - acc: 0.9110 - val_loss: 0.1609 - val_acc: 0.9376\n",
      "Epoch 37/250\n",
      "7789/7789 [==============================] - 3s 364us/step - loss: 0.2350 - acc: 0.9091 - val_loss: 0.1618 - val_acc: 0.9376\n",
      "Epoch 38/250\n",
      "7789/7789 [==============================] - 3s 383us/step - loss: 0.2375 - acc: 0.9094 - val_loss: 0.1625 - val_acc: 0.9376\n",
      "Epoch 39/250\n",
      "7789/7789 [==============================] - 3s 394us/step - loss: 0.2373 - acc: 0.9103 - val_loss: 0.1624 - val_acc: 0.9376\n",
      "Epoch 40/250\n",
      "7789/7789 [==============================] - 3s 359us/step - loss: 0.2337 - acc: 0.9119 - val_loss: 0.1618 - val_acc: 0.9376\n",
      "Epoch 41/250\n",
      "7789/7789 [==============================] - 3s 366us/step - loss: 0.2252 - acc: 0.9159 - val_loss: 0.1607 - val_acc: 0.9376\n",
      "Epoch 42/250\n",
      "7789/7789 [==============================] - 3s 388us/step - loss: 0.2344 - acc: 0.9078 - val_loss: 0.1594 - val_acc: 0.9376\n",
      "Epoch 43/250\n",
      "7789/7789 [==============================] - 3s 377us/step - loss: 0.2305 - acc: 0.9130 - val_loss: 0.1580 - val_acc: 0.9388\n",
      "Epoch 44/250\n",
      "7789/7789 [==============================] - 3s 360us/step - loss: 0.2246 - acc: 0.9169 - val_loss: 0.1567 - val_acc: 0.9388\n",
      "Epoch 45/250\n",
      "7789/7789 [==============================] - 3s 356us/step - loss: 0.2249 - acc: 0.9150 - val_loss: 0.1557 - val_acc: 0.9388\n",
      "Epoch 46/250\n",
      "7789/7789 [==============================] - 3s 367us/step - loss: 0.2243 - acc: 0.9130 - val_loss: 0.1554 - val_acc: 0.9423\n",
      "Epoch 47/250\n",
      "7789/7789 [==============================] - 3s 369us/step - loss: 0.2234 - acc: 0.9146 - val_loss: 0.1577 - val_acc: 0.9423\n",
      "Epoch 48/250\n",
      "7789/7789 [==============================] - 3s 378us/step - loss: 0.2277 - acc: 0.9178 - val_loss: 0.1668 - val_acc: 0.9423\n",
      "Epoch 49/250\n",
      "7789/7789 [==============================] - 3s 367us/step - loss: 0.2297 - acc: 0.9154 - val_loss: 0.1677 - val_acc: 0.9423\n",
      "Epoch 50/250\n",
      "7789/7789 [==============================] - 3s 356us/step - loss: 0.2294 - acc: 0.9113 - val_loss: 0.1769 - val_acc: 0.9423\n",
      "Epoch 51/250\n",
      "7789/7789 [==============================] - 3s 374us/step - loss: 0.2241 - acc: 0.9160 - val_loss: 0.1765 - val_acc: 0.9423\n",
      "Epoch 52/250\n",
      "7789/7789 [==============================] - 3s 365us/step - loss: 0.2210 - acc: 0.9154 - val_loss: 0.1760 - val_acc: 0.9423\n",
      "Epoch 53/250\n",
      "7789/7789 [==============================] - 3s 366us/step - loss: 0.2267 - acc: 0.9153 - val_loss: 0.1755 - val_acc: 0.9411\n",
      "Epoch 54/250\n",
      "7789/7789 [==============================] - 3s 364us/step - loss: 0.2194 - acc: 0.9151 - val_loss: 0.1751 - val_acc: 0.9423\n",
      "Epoch 55/250\n",
      "7789/7789 [==============================] - 3s 367us/step - loss: 0.2349 - acc: 0.9153 - val_loss: 0.1637 - val_acc: 0.9411\n",
      "Epoch 56/250\n",
      "7789/7789 [==============================] - 3s 374us/step - loss: 0.2233 - acc: 0.9174 - val_loss: 0.1557 - val_acc: 0.9400\n",
      "Epoch 57/250\n",
      "7789/7789 [==============================] - 3s 369us/step - loss: 0.2175 - acc: 0.9171 - val_loss: 0.1520 - val_acc: 0.9411\n",
      "Epoch 58/250\n",
      "7789/7789 [==============================] - 3s 369us/step - loss: 0.2179 - acc: 0.9205 - val_loss: 0.1512 - val_acc: 0.9411\n",
      "Epoch 59/250\n",
      "7789/7789 [==============================] - 3s 368us/step - loss: 0.2106 - acc: 0.9162 - val_loss: 0.1529 - val_acc: 0.9411\n",
      "Epoch 60/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7789/7789 [==============================] - 3s 369us/step - loss: 0.2191 - acc: 0.9167 - val_loss: 0.1575 - val_acc: 0.9434\n",
      "Epoch 61/250\n",
      "7789/7789 [==============================] - 3s 385us/step - loss: 0.2188 - acc: 0.9168 - val_loss: 0.1627 - val_acc: 0.9434\n",
      "Epoch 62/250\n",
      "7789/7789 [==============================] - 3s 371us/step - loss: 0.2256 - acc: 0.9171 - val_loss: 0.1677 - val_acc: 0.9434\n",
      "Epoch 63/250\n",
      "7789/7789 [==============================] - 3s 420us/step - loss: 0.2251 - acc: 0.9177 - val_loss: 0.1720 - val_acc: 0.9423\n",
      "Epoch 64/250\n",
      "7789/7789 [==============================] - 3s 391us/step - loss: 0.2265 - acc: 0.9153 - val_loss: 0.1753 - val_acc: 0.9411\n",
      "Epoch 65/250\n",
      "7789/7789 [==============================] - 3s 375us/step - loss: 0.2289 - acc: 0.9191 - val_loss: 0.1777 - val_acc: 0.9434\n",
      "Epoch 66/250\n",
      "7789/7789 [==============================] - 3s 377us/step - loss: 0.2313 - acc: 0.9162 - val_loss: 0.1792 - val_acc: 0.9457\n",
      "Epoch 67/250\n",
      "7789/7789 [==============================] - 3s 381us/step - loss: 0.2400 - acc: 0.9141 - val_loss: 0.1800 - val_acc: 0.9469\n",
      "Epoch 68/250\n",
      "7789/7789 [==============================] - 3s 381us/step - loss: 0.2349 - acc: 0.9123 - val_loss: 0.1801 - val_acc: 0.9469\n",
      "Epoch 69/250\n",
      "7789/7789 [==============================] - 3s 383us/step - loss: 0.2306 - acc: 0.9200 - val_loss: 0.1798 - val_acc: 0.9469\n",
      "Epoch 70/250\n",
      "7789/7789 [==============================] - 3s 386us/step - loss: 0.2300 - acc: 0.9217 - val_loss: 0.1792 - val_acc: 0.9457\n",
      "Epoch 71/250\n",
      "7789/7789 [==============================] - 3s 384us/step - loss: 0.2294 - acc: 0.9198 - val_loss: 0.1783 - val_acc: 0.9434\n",
      "Epoch 72/250\n",
      "7789/7789 [==============================] - 3s 376us/step - loss: 0.2261 - acc: 0.9198 - val_loss: 0.1775 - val_acc: 0.9423\n",
      "Epoch 73/250\n",
      "7789/7789 [==============================] - 3s 358us/step - loss: 0.2289 - acc: 0.9169 - val_loss: 0.1765 - val_acc: 0.9400\n",
      "Epoch 74/250\n",
      "7789/7789 [==============================] - 3s 359us/step - loss: 0.2232 - acc: 0.9198 - val_loss: 0.1756 - val_acc: 0.9400\n",
      "Epoch 75/250\n",
      "7789/7789 [==============================] - 3s 373us/step - loss: 0.2223 - acc: 0.9186 - val_loss: 0.1747 - val_acc: 0.9376\n",
      "Epoch 76/250\n",
      "7789/7789 [==============================] - 3s 400us/step - loss: 0.2222 - acc: 0.9182 - val_loss: 0.1739 - val_acc: 0.9388\n",
      "Epoch 77/250\n",
      "7789/7789 [==============================] - 3s 371us/step - loss: 0.2220 - acc: 0.9180 - val_loss: 0.1732 - val_acc: 0.9388\n",
      "Epoch 78/250\n",
      "7789/7789 [==============================] - 3s 362us/step - loss: 0.2184 - acc: 0.9172 - val_loss: 0.1727 - val_acc: 0.9388\n",
      "Epoch 79/250\n",
      "7789/7789 [==============================] - 3s 369us/step - loss: 0.2214 - acc: 0.9146 - val_loss: 0.1730 - val_acc: 0.9365\n",
      "Epoch 80/250\n",
      "7789/7789 [==============================] - 3s 357us/step - loss: 0.2187 - acc: 0.9163 - val_loss: 0.1824 - val_acc: 0.9365\n",
      "Epoch 81/250\n",
      "7789/7789 [==============================] - 3s 356us/step - loss: 0.2222 - acc: 0.9157 - val_loss: 0.1813 - val_acc: 0.9365\n",
      "Epoch 82/250\n",
      "7789/7789 [==============================] - 3s 359us/step - loss: 0.2210 - acc: 0.9139 - val_loss: 0.1800 - val_acc: 0.9376\n",
      "Epoch 83/250\n",
      "7789/7789 [==============================] - 3s 354us/step - loss: 0.2145 - acc: 0.9153 - val_loss: 0.1788 - val_acc: 0.9376\n",
      "Epoch 84/250\n",
      "7789/7789 [==============================] - 3s 371us/step - loss: 0.2154 - acc: 0.9187 - val_loss: 0.1775 - val_acc: 0.9388\n",
      "Epoch 85/250\n",
      "7789/7789 [==============================] - 3s 357us/step - loss: 0.2132 - acc: 0.9190 - val_loss: 0.1762 - val_acc: 0.9376\n",
      "Epoch 86/250\n",
      "7789/7789 [==============================] - 3s 365us/step - loss: 0.2168 - acc: 0.9159 - val_loss: 0.1749 - val_acc: 0.9388\n",
      "Epoch 87/250\n",
      "7789/7789 [==============================] - 3s 366us/step - loss: 0.2108 - acc: 0.9146 - val_loss: 0.1736 - val_acc: 0.9400\n",
      "Epoch 88/250\n",
      "7789/7789 [==============================] - 3s 381us/step - loss: 0.2201 - acc: 0.9135 - val_loss: 0.1724 - val_acc: 0.9400\n",
      "Epoch 89/250\n",
      "7789/7789 [==============================] - 3s 392us/step - loss: 0.2195 - acc: 0.9167 - val_loss: 0.1713 - val_acc: 0.9388\n",
      "Epoch 90/250\n",
      "7789/7789 [==============================] - 3s 369us/step - loss: 0.2148 - acc: 0.9210 - val_loss: 0.1703 - val_acc: 0.9423\n",
      "Epoch 91/250\n",
      "7789/7789 [==============================] - 3s 364us/step - loss: 0.2222 - acc: 0.9173 - val_loss: 0.1695 - val_acc: 0.9423\n",
      "Epoch 92/250\n",
      "7789/7789 [==============================] - 3s 388us/step - loss: 0.2117 - acc: 0.9191 - val_loss: 0.1687 - val_acc: 0.9446\n",
      "Epoch 93/250\n",
      "7789/7789 [==============================] - 3s 367us/step - loss: 0.2160 - acc: 0.9187 - val_loss: 0.1680 - val_acc: 0.9446\n",
      "Epoch 94/250\n",
      "7789/7789 [==============================] - 3s 370us/step - loss: 0.2106 - acc: 0.9232 - val_loss: 0.1674 - val_acc: 0.9446\n",
      "Epoch 95/250\n",
      "7789/7789 [==============================] - 3s 364us/step - loss: 0.2140 - acc: 0.9182 - val_loss: 0.1669 - val_acc: 0.9434\n",
      "Epoch 96/250\n",
      "7789/7789 [==============================] - 3s 374us/step - loss: 0.2104 - acc: 0.9196 - val_loss: 0.1663 - val_acc: 0.9423\n",
      "Epoch 97/250\n",
      "7789/7789 [==============================] - 3s 362us/step - loss: 0.2149 - acc: 0.9165 - val_loss: 0.1661 - val_acc: 0.9423\n",
      "Epoch 98/250\n",
      "7789/7789 [==============================] - 3s 355us/step - loss: 0.2016 - acc: 0.9199 - val_loss: 0.1655 - val_acc: 0.9434\n",
      "Epoch 99/250\n",
      "7789/7789 [==============================] - 3s 357us/step - loss: 0.2135 - acc: 0.9212 - val_loss: 0.1648 - val_acc: 0.9423\n",
      "Epoch 100/250\n",
      "7789/7789 [==============================] - 3s 362us/step - loss: 0.2102 - acc: 0.9221 - val_loss: 0.1640 - val_acc: 0.9457\n",
      "Epoch 101/250\n",
      "7789/7789 [==============================] - 3s 358us/step - loss: 0.2107 - acc: 0.9226 - val_loss: 0.1634 - val_acc: 0.9457\n",
      "Epoch 102/250\n",
      "7789/7789 [==============================] - 3s 357us/step - loss: 0.2087 - acc: 0.9218 - val_loss: 0.1630 - val_acc: 0.9434\n",
      "Epoch 103/250\n",
      "7789/7789 [==============================] - 3s 355us/step - loss: 0.2080 - acc: 0.9213 - val_loss: 0.1627 - val_acc: 0.9446\n",
      "Epoch 104/250\n",
      "7789/7789 [==============================] - 3s 357us/step - loss: 0.2077 - acc: 0.9222 - val_loss: 0.1624 - val_acc: 0.9434\n",
      "Epoch 105/250\n",
      "7789/7789 [==============================] - 3s 359us/step - loss: 0.2058 - acc: 0.9208 - val_loss: 0.1620 - val_acc: 0.9434\n",
      "Epoch 106/250\n",
      "7789/7789 [==============================] - 3s 356us/step - loss: 0.2042 - acc: 0.9207 - val_loss: 0.1617 - val_acc: 0.9434\n",
      "Epoch 107/250\n",
      "7789/7789 [==============================] - 3s 364us/step - loss: 0.2048 - acc: 0.9209 - val_loss: 0.1613 - val_acc: 0.9434\n",
      "Epoch 108/250\n",
      "7789/7789 [==============================] - 3s 360us/step - loss: 0.2096 - acc: 0.9207 - val_loss: 0.1610 - val_acc: 0.9434\n",
      "Epoch 00108: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\strix\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7789 samples, validate on 866 samples\n",
      "Epoch 1/250\n",
      "7789/7789 [==============================] - 5s 696us/step - loss: 1.0570 - acc: 0.7828 - val_loss: 0.8318 - val_acc: 0.8279\n",
      "Epoch 2/250\n",
      "7789/7789 [==============================] - 4s 504us/step - loss: 0.8984 - acc: 0.8079 - val_loss: 0.7253 - val_acc: 0.8395\n",
      "Epoch 3/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.7773 - acc: 0.8236 - val_loss: 0.6544 - val_acc: 0.8510\n",
      "Epoch 4/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.7096 - acc: 0.8377 - val_loss: 0.5386 - val_acc: 0.8591\n",
      "Epoch 5/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.6605 - acc: 0.8491 - val_loss: 0.4996 - val_acc: 0.8707\n",
      "Epoch 6/250\n",
      "7789/7789 [==============================] - 4s 497us/step - loss: 0.5961 - acc: 0.8579 - val_loss: 0.4592 - val_acc: 0.8741\n",
      "Epoch 7/250\n",
      "7789/7789 [==============================] - 4s 499us/step - loss: 0.5596 - acc: 0.8643 - val_loss: 0.4453 - val_acc: 0.8822\n",
      "Epoch 8/250\n",
      "7789/7789 [==============================] - 4s 504us/step - loss: 0.5317 - acc: 0.8676 - val_loss: 0.4247 - val_acc: 0.8903\n",
      "Epoch 9/250\n",
      "7789/7789 [==============================] - 4s 503us/step - loss: 0.5281 - acc: 0.8788 - val_loss: 0.4058 - val_acc: 0.8938\n",
      "Epoch 10/250\n",
      "7789/7789 [==============================] - 4s 502us/step - loss: 0.4707 - acc: 0.8801 - val_loss: 0.3994 - val_acc: 0.9018\n",
      "Epoch 11/250\n",
      "7789/7789 [==============================] - 4s 503us/step - loss: 0.4600 - acc: 0.8810 - val_loss: 0.3831 - val_acc: 0.9007\n",
      "Epoch 12/250\n",
      "7789/7789 [==============================] - 4s 504us/step - loss: 0.4635 - acc: 0.8857 - val_loss: 0.3788 - val_acc: 0.9042\n",
      "Epoch 13/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.4121 - acc: 0.8874 - val_loss: 0.3758 - val_acc: 0.9076\n",
      "Epoch 14/250\n",
      "7789/7789 [==============================] - 4s 505us/step - loss: 0.4193 - acc: 0.8892 - val_loss: 0.3517 - val_acc: 0.9099\n",
      "Epoch 15/250\n",
      "7789/7789 [==============================] - 4s 544us/step - loss: 0.4089 - acc: 0.8896 - val_loss: 0.3471 - val_acc: 0.9111\n",
      "Epoch 16/250\n",
      "7789/7789 [==============================] - 4s 533us/step - loss: 0.3912 - acc: 0.8934 - val_loss: 0.3348 - val_acc: 0.9088\n",
      "Epoch 17/250\n",
      "7789/7789 [==============================] - 4s 521us/step - loss: 0.3788 - acc: 0.8972 - val_loss: 0.3320 - val_acc: 0.9088\n",
      "Epoch 18/250\n",
      "7789/7789 [==============================] - 4s 544us/step - loss: 0.3730 - acc: 0.8958 - val_loss: 0.3300 - val_acc: 0.9099\n",
      "Epoch 19/250\n",
      "7789/7789 [==============================] - 4s 523us/step - loss: 0.3569 - acc: 0.9011 - val_loss: 0.3284 - val_acc: 0.9099\n",
      "Epoch 20/250\n",
      "7789/7789 [==============================] - 4s 500us/step - loss: 0.3410 - acc: 0.9035 - val_loss: 0.3272 - val_acc: 0.9111\n",
      "Epoch 21/250\n",
      "7789/7789 [==============================] - 4s 518us/step - loss: 0.3300 - acc: 0.9044 - val_loss: 0.3155 - val_acc: 0.9111\n",
      "Epoch 22/250\n",
      "7789/7789 [==============================] - 4s 507us/step - loss: 0.3202 - acc: 0.9010 - val_loss: 0.3133 - val_acc: 0.9111\n",
      "Epoch 23/250\n",
      "7789/7789 [==============================] - 4s 504us/step - loss: 0.3202 - acc: 0.9051 - val_loss: 0.3021 - val_acc: 0.9122\n",
      "Epoch 24/250\n",
      "7789/7789 [==============================] - 4s 502us/step - loss: 0.3059 - acc: 0.9097 - val_loss: 0.2993 - val_acc: 0.9122\n",
      "Epoch 25/250\n",
      "7789/7789 [==============================] - 4s 502us/step - loss: 0.3086 - acc: 0.9077 - val_loss: 0.2980 - val_acc: 0.9122\n",
      "Epoch 26/250\n",
      "7789/7789 [==============================] - 4s 505us/step - loss: 0.3053 - acc: 0.9096 - val_loss: 0.2973 - val_acc: 0.9122\n",
      "Epoch 27/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.2851 - acc: 0.9121 - val_loss: 0.2967 - val_acc: 0.9122\n",
      "Epoch 28/250\n",
      "7789/7789 [==============================] - 4s 506us/step - loss: 0.2800 - acc: 0.9118 - val_loss: 0.2962 - val_acc: 0.9122\n",
      "Epoch 29/250\n",
      "7789/7789 [==============================] - 4s 497us/step - loss: 0.2835 - acc: 0.9118 - val_loss: 0.2956 - val_acc: 0.9134\n",
      "Epoch 30/250\n",
      "7789/7789 [==============================] - 4s 503us/step - loss: 0.2775 - acc: 0.9153 - val_loss: 0.2950 - val_acc: 0.9145\n",
      "Epoch 31/250\n",
      "7789/7789 [==============================] - 4s 498us/step - loss: 0.2885 - acc: 0.9168 - val_loss: 0.2944 - val_acc: 0.9134\n",
      "Epoch 32/250\n",
      "7789/7789 [==============================] - 4s 512us/step - loss: 0.2736 - acc: 0.9183 - val_loss: 0.2937 - val_acc: 0.9134\n",
      "Epoch 33/250\n",
      "7789/7789 [==============================] - 4s 509us/step - loss: 0.2768 - acc: 0.9167 - val_loss: 0.2930 - val_acc: 0.9134\n",
      "Epoch 34/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.2676 - acc: 0.9185 - val_loss: 0.2834 - val_acc: 0.9099\n",
      "Epoch 35/250\n",
      "7789/7789 [==============================] - 4s 503us/step - loss: 0.2575 - acc: 0.9225 - val_loss: 0.2831 - val_acc: 0.9088\n",
      "Epoch 36/250\n",
      "7789/7789 [==============================] - 4s 509us/step - loss: 0.2575 - acc: 0.9223 - val_loss: 0.2835 - val_acc: 0.9088\n",
      "Epoch 37/250\n",
      "7789/7789 [==============================] - 4s 509us/step - loss: 0.2535 - acc: 0.9236 - val_loss: 0.2839 - val_acc: 0.9076\n",
      "Epoch 38/250\n",
      "7789/7789 [==============================] - 4s 521us/step - loss: 0.2552 - acc: 0.9250 - val_loss: 0.2842 - val_acc: 0.9065\n",
      "Epoch 39/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.2547 - acc: 0.9236 - val_loss: 0.2843 - val_acc: 0.9065\n",
      "Epoch 40/250\n",
      "7789/7789 [==============================] - 4s 503us/step - loss: 0.2484 - acc: 0.9273 - val_loss: 0.2843 - val_acc: 0.9053\n",
      "Epoch 41/250\n",
      "7789/7789 [==============================] - 4s 502us/step - loss: 0.2421 - acc: 0.9271 - val_loss: 0.2842 - val_acc: 0.9053\n",
      "Epoch 42/250\n",
      "7789/7789 [==============================] - 4s 499us/step - loss: 0.2455 - acc: 0.9263 - val_loss: 0.2838 - val_acc: 0.9053\n",
      "Epoch 43/250\n",
      "7789/7789 [==============================] - 4s 499us/step - loss: 0.2411 - acc: 0.9326 - val_loss: 0.2834 - val_acc: 0.9053\n",
      "Epoch 44/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.2369 - acc: 0.9321 - val_loss: 0.2829 - val_acc: 0.9053\n",
      "Epoch 45/250\n",
      "7789/7789 [==============================] - 4s 503us/step - loss: 0.2350 - acc: 0.9326 - val_loss: 0.2823 - val_acc: 0.9053\n",
      "Epoch 46/250\n",
      "7789/7789 [==============================] - 4s 494us/step - loss: 0.2308 - acc: 0.9308 - val_loss: 0.2816 - val_acc: 0.9076\n",
      "Epoch 47/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.2253 - acc: 0.9326 - val_loss: 0.2808 - val_acc: 0.9076\n",
      "Epoch 48/250\n",
      "7789/7789 [==============================] - 4s 500us/step - loss: 0.2270 - acc: 0.9332 - val_loss: 0.2799 - val_acc: 0.9076\n",
      "Epoch 49/250\n",
      "7789/7789 [==============================] - 4s 499us/step - loss: 0.2224 - acc: 0.9341 - val_loss: 0.2788 - val_acc: 0.9076\n",
      "Epoch 50/250\n",
      "7789/7789 [==============================] - 4s 508us/step - loss: 0.2199 - acc: 0.9347 - val_loss: 0.2777 - val_acc: 0.9088\n",
      "Epoch 51/250\n",
      "7789/7789 [==============================] - 4s 506us/step - loss: 0.2225 - acc: 0.9375 - val_loss: 0.2766 - val_acc: 0.9088\n",
      "Epoch 52/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.2150 - acc: 0.9368 - val_loss: 0.2754 - val_acc: 0.9099\n",
      "Epoch 53/250\n",
      "7789/7789 [==============================] - 4s 503us/step - loss: 0.2134 - acc: 0.9376 - val_loss: 0.2742 - val_acc: 0.9099\n",
      "Epoch 54/250\n",
      "7789/7789 [==============================] - 4s 505us/step - loss: 0.2093 - acc: 0.9394 - val_loss: 0.2729 - val_acc: 0.9099\n",
      "Epoch 55/250\n",
      "7789/7789 [==============================] - 4s 498us/step - loss: 0.2131 - acc: 0.9381 - val_loss: 0.2717 - val_acc: 0.9111\n",
      "Epoch 56/250\n",
      "7789/7789 [==============================] - 4s 518us/step - loss: 0.2037 - acc: 0.9394 - val_loss: 0.2706 - val_acc: 0.9122\n",
      "Epoch 57/250\n",
      "7789/7789 [==============================] - 4s 518us/step - loss: 0.2043 - acc: 0.9380 - val_loss: 0.2695 - val_acc: 0.9134\n",
      "Epoch 58/250\n",
      "7789/7789 [==============================] - 4s 506us/step - loss: 0.2000 - acc: 0.9413 - val_loss: 0.2686 - val_acc: 0.9134\n",
      "Epoch 59/250\n",
      "7789/7789 [==============================] - 4s 499us/step - loss: 0.1977 - acc: 0.9411 - val_loss: 0.2685 - val_acc: 0.9134\n",
      "Epoch 60/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7789/7789 [==============================] - 4s 508us/step - loss: 0.1990 - acc: 0.9398 - val_loss: 0.2777 - val_acc: 0.9134\n",
      "Epoch 61/250\n",
      "7789/7789 [==============================] - 4s 508us/step - loss: 0.1940 - acc: 0.9404 - val_loss: 0.2764 - val_acc: 0.9145\n",
      "Epoch 62/250\n",
      "7789/7789 [==============================] - 4s 524us/step - loss: 0.1907 - acc: 0.9415 - val_loss: 0.2752 - val_acc: 0.9157\n",
      "Epoch 63/250\n",
      "7789/7789 [==============================] - 4s 533us/step - loss: 0.1902 - acc: 0.9429 - val_loss: 0.2741 - val_acc: 0.9157\n",
      "Epoch 64/250\n",
      "7789/7789 [==============================] - 4s 546us/step - loss: 0.1852 - acc: 0.9424 - val_loss: 0.2732 - val_acc: 0.9157\n",
      "Epoch 65/250\n",
      "7789/7789 [==============================] - 4s 536us/step - loss: 0.1826 - acc: 0.9453 - val_loss: 0.2726 - val_acc: 0.9169\n",
      "Epoch 66/250\n",
      "7789/7789 [==============================] - 4s 532us/step - loss: 0.1785 - acc: 0.9449 - val_loss: 0.2734 - val_acc: 0.9180\n",
      "Epoch 67/250\n",
      "7789/7789 [==============================] - 4s 529us/step - loss: 0.1785 - acc: 0.9439 - val_loss: 0.2827 - val_acc: 0.9180\n",
      "Epoch 68/250\n",
      "7789/7789 [==============================] - 4s 553us/step - loss: 0.1760 - acc: 0.9452 - val_loss: 0.2906 - val_acc: 0.9203\n",
      "Epoch 69/250\n",
      "7789/7789 [==============================] - 4s 558us/step - loss: 0.1751 - acc: 0.9466 - val_loss: 0.2890 - val_acc: 0.9203\n",
      "Epoch 70/250\n",
      "7789/7789 [==============================] - 4s 539us/step - loss: 0.1691 - acc: 0.9471 - val_loss: 0.2875 - val_acc: 0.9203\n",
      "Epoch 71/250\n",
      "7789/7789 [==============================] - 4s 517us/step - loss: 0.1715 - acc: 0.9492 - val_loss: 0.2860 - val_acc: 0.9249\n",
      "Epoch 72/250\n",
      "7789/7789 [==============================] - 4s 511us/step - loss: 0.1646 - acc: 0.9477 - val_loss: 0.2846 - val_acc: 0.9249\n",
      "Epoch 73/250\n",
      "7789/7789 [==============================] - 4s 504us/step - loss: 0.1683 - acc: 0.9486 - val_loss: 0.2832 - val_acc: 0.9249\n",
      "Epoch 74/250\n",
      "7789/7789 [==============================] - 4s 502us/step - loss: 0.1660 - acc: 0.9506 - val_loss: 0.2818 - val_acc: 0.9249\n",
      "Epoch 75/250\n",
      "7789/7789 [==============================] - 4s 509us/step - loss: 0.1602 - acc: 0.9504 - val_loss: 0.2807 - val_acc: 0.9261\n",
      "Epoch 76/250\n",
      "7789/7789 [==============================] - 4s 516us/step - loss: 0.1553 - acc: 0.9534 - val_loss: 0.2796 - val_acc: 0.9261\n",
      "Epoch 77/250\n",
      "7789/7789 [==============================] - 4s 518us/step - loss: 0.1632 - acc: 0.9503 - val_loss: 0.2786 - val_acc: 0.9261\n",
      "Epoch 78/250\n",
      "7789/7789 [==============================] - 4s 514us/step - loss: 0.1544 - acc: 0.9508 - val_loss: 0.2776 - val_acc: 0.9273\n",
      "Epoch 79/250\n",
      "7789/7789 [==============================] - 4s 505us/step - loss: 0.1537 - acc: 0.9528 - val_loss: 0.2767 - val_acc: 0.9273\n",
      "Epoch 80/250\n",
      "7789/7789 [==============================] - 4s 507us/step - loss: 0.1521 - acc: 0.9516 - val_loss: 0.2758 - val_acc: 0.9273\n",
      "Epoch 81/250\n",
      "7789/7789 [==============================] - 4s 508us/step - loss: 0.1514 - acc: 0.9538 - val_loss: 0.2749 - val_acc: 0.9273\n",
      "Epoch 82/250\n",
      "7789/7789 [==============================] - 4s 510us/step - loss: 0.1464 - acc: 0.9553 - val_loss: 0.2742 - val_acc: 0.9284\n",
      "Epoch 83/250\n",
      "7789/7789 [==============================] - 4s 516us/step - loss: 0.1441 - acc: 0.9539 - val_loss: 0.2734 - val_acc: 0.9307\n",
      "Epoch 84/250\n",
      "7789/7789 [==============================] - 4s 518us/step - loss: 0.1481 - acc: 0.9542 - val_loss: 0.2728 - val_acc: 0.9307\n",
      "Epoch 85/250\n",
      "7789/7789 [==============================] - 4s 511us/step - loss: 0.1410 - acc: 0.9542 - val_loss: 0.2725 - val_acc: 0.9296\n",
      "Epoch 86/250\n",
      "7789/7789 [==============================] - 4s 519us/step - loss: 0.1422 - acc: 0.9549 - val_loss: 0.2728 - val_acc: 0.9296\n",
      "Epoch 87/250\n",
      "7789/7789 [==============================] - 4s 552us/step - loss: 0.1415 - acc: 0.9558 - val_loss: 0.2812 - val_acc: 0.9296\n",
      "Epoch 88/250\n",
      "7789/7789 [==============================] - 4s 536us/step - loss: 0.1396 - acc: 0.9566 - val_loss: 0.2804 - val_acc: 0.9296\n",
      "Epoch 89/250\n",
      "7789/7789 [==============================] - 4s 507us/step - loss: 0.1364 - acc: 0.9570 - val_loss: 0.2796 - val_acc: 0.9296\n",
      "Epoch 90/250\n",
      "7789/7789 [==============================] - 4s 511us/step - loss: 0.1350 - acc: 0.9590 - val_loss: 0.2789 - val_acc: 0.9296\n",
      "Epoch 91/250\n",
      "7789/7789 [==============================] - 4s 506us/step - loss: 0.1320 - acc: 0.9589 - val_loss: 0.2782 - val_acc: 0.9307\n",
      "Epoch 92/250\n",
      "7789/7789 [==============================] - 4s 536us/step - loss: 0.1347 - acc: 0.9596 - val_loss: 0.2776 - val_acc: 0.9319\n",
      "Epoch 93/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.1310 - acc: 0.9583 - val_loss: 0.2771 - val_acc: 0.9319\n",
      "Epoch 94/250\n",
      "7789/7789 [==============================] - 4s 518us/step - loss: 0.1301 - acc: 0.9596 - val_loss: 0.2765 - val_acc: 0.9319\n",
      "Epoch 95/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.1290 - acc: 0.9593 - val_loss: 0.2760 - val_acc: 0.9319\n",
      "Epoch 96/250\n",
      "7789/7789 [==============================] - 4s 506us/step - loss: 0.1304 - acc: 0.9579 - val_loss: 0.2755 - val_acc: 0.9319\n",
      "Epoch 97/250\n",
      "7789/7789 [==============================] - 4s 528us/step - loss: 0.1267 - acc: 0.9602 - val_loss: 0.2750 - val_acc: 0.9319\n",
      "Epoch 98/250\n",
      "7789/7789 [==============================] - 4s 523us/step - loss: 0.1239 - acc: 0.9597 - val_loss: 0.2745 - val_acc: 0.9319\n",
      "Epoch 99/250\n",
      "7789/7789 [==============================] - 4s 517us/step - loss: 0.1212 - acc: 0.9602 - val_loss: 0.2741 - val_acc: 0.9319\n",
      "Epoch 100/250\n",
      "7789/7789 [==============================] - 4s 516us/step - loss: 0.1175 - acc: 0.9614 - val_loss: 0.2738 - val_acc: 0.9319\n",
      "Epoch 101/250\n",
      "7789/7789 [==============================] - 4s 502us/step - loss: 0.1209 - acc: 0.9620 - val_loss: 0.2735 - val_acc: 0.9319\n",
      "Epoch 102/250\n",
      "7789/7789 [==============================] - 4s 506us/step - loss: 0.1193 - acc: 0.9633 - val_loss: 0.2734 - val_acc: 0.9319\n",
      "Epoch 103/250\n",
      "7789/7789 [==============================] - 4s 501us/step - loss: 0.1171 - acc: 0.9616 - val_loss: 0.2735 - val_acc: 0.9330\n",
      "Epoch 104/250\n",
      "7789/7789 [==============================] - 4s 527us/step - loss: 0.1150 - acc: 0.9647 - val_loss: 0.2744 - val_acc: 0.9330\n",
      "Epoch 105/250\n",
      "7789/7789 [==============================] - 4s 537us/step - loss: 0.1188 - acc: 0.9630 - val_loss: 0.2832 - val_acc: 0.9330\n",
      "Epoch 106/250\n",
      "7789/7789 [==============================] - 4s 530us/step - loss: 0.1129 - acc: 0.9646 - val_loss: 0.2828 - val_acc: 0.9342\n",
      "Epoch 107/250\n",
      "7789/7789 [==============================] - 4s 551us/step - loss: 0.1104 - acc: 0.9660 - val_loss: 0.2825 - val_acc: 0.9342\n",
      "Epoch 108/250\n",
      "7789/7789 [==============================] - 4s 538us/step - loss: 0.1076 - acc: 0.9656 - val_loss: 0.2822 - val_acc: 0.9342\n",
      "Epoch 109/250\n",
      "7789/7789 [==============================] - 4s 562us/step - loss: 0.1116 - acc: 0.9662 - val_loss: 0.2819 - val_acc: 0.9342\n",
      "Epoch 00109: early stopping\n"
     ]
    }
   ],
   "source": [
    "Classifier.refine(trainX, trainY)\n",
    "test_predictions = Classifier.predict(testX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.913\n",
      "Test MCC:  0.727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2184,  119],\n",
       "       [ 133,  450]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test Accuracy:  {:.3f}'.format(sklearn.metrics.accuracy_score(testY, test_predictions)))\n",
    "print('Test MCC:  {:.3f}'.format(sklearn.metrics.matthews_corrcoef(testY, test_predictions)))\n",
    "sklearn.metrics.confusion_matrix(testY, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have accuracies of over 90%! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW: 0.899\n",
      "LSTM: 0.832\n",
      "Pre-trained embedding: 0.878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ensembled': 0.9126819126819127,\n",
       " 'BoW': 0.8988218988218988,\n",
       " 'LSTM': 0.8316008316008316,\n",
       " 'Glove': 0.8776853776853777}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classifier.predict(['I dont know'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.21.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
